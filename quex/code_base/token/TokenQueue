/* -*- C++ -*- vim: set syntax=cpp: 
 * (C) 2004-2009 Frank-Rene Schaefer                               */
#ifndef __QUEX_INCLUDE_GUARD__TOKEN__TOKEN_QUEUE
#define __QUEX_INCLUDE_GUARD__TOKEN__TOKEN_QUEUE

#ifndef QUEX_TYPE_TOKEN_WITH_NAMESPACE
#   error "QUEX_TYPE_TOKEN_WITH_NAMESPACE has not been defined before the inclusion of this file."
#endif


#include <quex/code_base/definitions>
#include <quex/code_base/asserts>
#include <quex/code_base/MemoryManager>

#include <quex/code_base/temporary_macros_on>

QUEX_NAMESPACE_COMPONENTS_OPEN

#define QuexTokenQueue_construct  QUEX_FIX(TOKEN_QUEUE, _construct)
#define QuexTokenQueue_destruct   QUEX_FIX(TOKEN_QUEUE, _destruct)

    typedef struct {

        QUEX_TYPE_TOKEN_WITH_NAMESPACE*   begin;
        QUEX_TYPE_TOKEN_WITH_NAMESPACE*   read_iterator;    // pointer to next token to be read
        QUEX_TYPE_TOKEN_WITH_NAMESPACE*   write_iterator;   // pointer to next token to be written
        QUEX_TYPE_TOKEN_WITH_NAMESPACE*   end_minus_safety_border;
        QUEX_TYPE_TOKEN_WITH_NAMESPACE*   end;
        /* A token might be 'N' times repeated. This is the only case where a token
         * queue overflow might occur. When the token queue is full and there are still
         * 'N' tokens to be repeated, then the remaining 'N' are stored in the following
         * variable.                                                                      */
        size_t     remaining_repetitions_of_last_token_n;

    } QUEX_TYPE_TOKEN_WITH_NAMESPACE_QUEUE;

#   define QuexTokenQueue_init(me, Memory, MemoryEnd, SafetyBorder) \
          do {                                                                \
             (me).begin                   = Memory;                           \
             (me).end                     = MemoryEnd;                        \
             (me).end_minus_safety_border = MemoryEnd - SafetyBorder;         \
             QuexTokenQueue_reset(me);                                        \
          } while(0)
 
#   define QuexTokenQueue_reset(me)                                \
           do {                                                    \
               (me).read_iterator  = (QUEX_TYPE_TOKEN_WITH_NAMESPACE*)(me).begin; \
               (me).write_iterator = (QUEX_TYPE_TOKEN_WITH_NAMESPACE*)(me).begin; \
               (me).remaining_repetitions_of_last_token_n = 0;     \
           } while(0)

    QUEX_INLINE void
    QuexTokenQueue_construct(QuexTokenQueue* me, const size_t N)
    {
        if( N == 0 ) {
            QuexTokenQueue_init(*me, 0x0, 0x0, 0); 
        } else {
            __quex_assert(N > QUEX_SETTING_TOKEN_QUEUE_SAFETY_BORDER);

            QUEX_TYPE_TOKEN_WITH_NAMESPACE*  chunk     = QUEX_FIX3(MemoryManager_, QUEX_TYPE_STR_TOKEN_COMPLETE, _allocate)(N);
            QUEX_TYPE_TOKEN_WITH_NAMESPACE*  chunk_end = chunk + N;

            /* Call placement new (plain constructor) for all tokens in chunk. */
            for(QUEX_TYPE_TOKEN_WITH_NAMESPACE* iterator = chunk; iterator != chunk_end; ++iterator)
                new ((void*)iterator) QUEX_TYPE_TOKEN_WITH_NAMESPACE;  
            QuexTokenQueue_init(*me, chunk, chunk_end, QUEX_SETTING_TOKEN_QUEUE_SAFETY_BORDER); 
        }
    }

    QUEX_INLINE void
    QuexTokenQueue_destruct(QuexTokenQueue* me)
    {
        /* Call explicit destructors for all tokens in array */
        for(QUEX_TYPE_TOKEN_WITH_NAMESPACE* iterator = me->begin; iterator != me->end; ++iterator)
             iterator->QUEX_TYPE_TOKEN_WITH_NAMESPACE::~QUEX_TYPE_TOKEN();  

        QUEX_FIX3(MemoryManager_, QUEX_TYPE_STR_TOKEN_COMPLETE, _free)(me->begin);
    }

#   define QuexTokenQueue_is_full(me)      ((me).write_iterator >= (me).end_minus_safety_border) 
#   define QuexTokenQueue_is_empty(me)     ((me).read_iterator == (me).write_iterator)
#   define QuexTokenQueue_pop(me)          ((me).read_iterator++)
#   define QuexTokenQueue_begin(me)        ((me).begin)
#   define QuexTokenQueue_back(me)         ((me).end - 1)
#   define QuexTokenQueue_available_n(me)  ((me).end - (me).write_iterator)

#   ifdef QUEX_OPTION_ASSERTS
    QUEX_INLINE void  
    QUEX_TOKEN_QUEUE_ASSERT(QuexTokenQueue* me)
    {
        __quex_assert(me->begin != 0x0);
        __quex_assert(me->read_iterator  >= me->begin);
        __quex_assert(me->write_iterator >= me->read_iterator);
        /* If the following breaks, it means that the given queue size was to small */
        __quex_assert(me->end_minus_safety_border >= me->begin + 1);
        if( me->write_iterator > me->end ) { 
            QUEX_ERROR_EXIT("Error: Token queue overflow. This happens if too many tokens are sent\n"
                            "       as a reaction to one single pattern match. Use quex's command line\n"
                            "       option --token-queue-safety-border, or define the macro\n"
                            "       QUEX_SETTING_TOKEN_QUEUE_SAFETY_BORDER with a greater value.\n"); 
        }
    }
#   else
#      define QUEX_TOKEN_QUEUE_ASSERT(me) /* empty */
#   endif

    typedef struct {
        QUEX_TYPE_TOKEN_WITH_NAMESPACE*    token_list;
        size_t              size;
    } QuexTokenQueueRemainder;

#if 1
    QUEX_INLINE void
    QuexTokenQueueRemainder_save(QuexTokenQueueRemainder* me, QuexTokenQueue* token_queue)
    {
        QUEX_TOKEN_QUEUE_ASSERT(token_queue);
        /* State of the token queue at the entry of this function:
         *
         *                           [A0] [B0]   [A1] [B1]   [A2] [B2]
         *                            |    |      |    |      |   | 
         *    |    |      |    |      |    |      |    |      |   | 
         *  [ token 1  ][ token 2  ][ token 3  ][ token 4  ][ token 5  ][ ....
         *                          |                                   |
         *                          read_iterator                       write_iterator
         *                                          
         *
         * 1. Step: Allocate a plain chunk of memory, to carry the remaining tokens:
         *
         *                           [ store 1  ][ store 2  ][ store 3  ]
         *
         *          The elements of this plain chunk of memory are neither subject
         *          to constructor nor destructor calls.
         *
         * 2. Step: Make a plain copy of the tokens of the remainder (from read_iterator
         *          to write_iterator.
         *
         *                        [A0] [B0]   [A1] [B1]   [A2] [B2]
         *                         |    |      |    |      |   | 
         *                         |    |      |    |      |   | 
         *                       [ store 1  ][ store 2  ][ store 3  ]
         *
         *      As a consequence, the objects to which the original tokens referred
         *      are now referred by the stored tokens. However, at the time of 'restore'
         *      the content is copied at the beginning of the queue. 
         *
         *      !! Thus, the following scenerio is conceivable:
         *      !!
         *      !!    [A0] [B0]   [A1] [B1]   [A2] [B2]   [A1] [B1]   [A2] [B2]
         *      !!     |    |      |    |      |    |      |    |      |   | 
         *      !!     |    |      |    |      |    |      |    |      |   | 
         *      !!   [ token 1  ][ token 2  ][ token 3  ][ token 4  ][ token 5  ][ ....
         *      !!   |                                   |
         *      !!   begin                               |
         *      !!   |<--------- store size ------------>|
         *      !!
         *      !! If this was happening, then the destructor for the objects A1, B1, ... 
         *      !! would be called twice at the destruction time of the token queue!       
         *      !!
         *      !! PREVENTION: See next step.
         *
         * 3. Step: Calling placement new on token objects that are saved:
         *          Resulting original token queue:
         *
         *                           [X1] [X1]   [Y2] [Y2]   [Z0] [Z0]   
         *                            |    |      |    |      |   | 
         *    |    |      |    |      |    |      |    |      |   | 
         *  [ token 1  ][ token 2  ][ token 3  ][ token 4  ][ token 5  ][ ....
         *                          |                                   |
         *                          read_iterator                       write_iterator
         *
         *  Note, that token 3 originally not subject to 'double occurence'. However,
         *  it may be overwritten by filling the queue, and then references to objects
         *  would get lost.                                                         */
        me->size = token_queue->write_iterator - token_queue->read_iterator;
        if( me->size != 0 ) {
            
            /* Step 1: allocate plain chunk of memory.                              */
            me->token_list = QUEX_FIX3(MemoryManager_, QUEX_TYPE_STR_TOKEN_COMPLETE, _allocate)(me->size);
            if( me->token_list == 0x0 ) {
                QUEX_ERROR_EXIT("Memory allocation error on request for token array.");
            }

            /* Step 2: copy plain chunk of memory                                   */
            memcpy(me->token_list, token_queue->read_iterator, sizeof(QUEX_TYPE_TOKEN_WITH_NAMESPACE) * me->size);

            /* Step 3: Call cleaning placement new on objects which are subject to
             *         potential double deletion.                                   */
            for(QUEX_TYPE_TOKEN_WITH_NAMESPACE* iterator = token_queue->read_iterator; 
                iterator != token_queue->write_iterator; ++iterator) {
                /* Clean-up by placement new */
                new ((void*)iterator) QUEX_TYPE_TOKEN_WITH_NAMESPACE;
            }
        }
        QuexTokenQueue_reset(*token_queue);

        QUEX_TOKEN_QUEUE_ASSERT(token_queue);
    }

    QUEX_INLINE void
    QuexTokenQueueRemainder_restore(QuexTokenQueueRemainder* me, QuexTokenQueue* token_queue)
    {
        /* NOTE: When a token queue remainder is restored, this happens as a result
         *       of 'return from included file'. The return from an included file
         *       is triggered by a TERMINATION token. By definition, the TERMINATION
         *       is the last token to be sent. When the user detects a TERMINATION
         *       token, the read_iterator == write_iterator, which means that the
         *       token queue is empty. => Thus, the 'refill' can start from the beginning.  
         *       THIS IS TRUE WHEN THE INLCUDE_PUSH, INCLUDE_POP HAPPENS FROM OUTSIDE
         *       THE LEXICAL ANALYZER ENGINE.                                            */
        if( ! QuexTokenQueue_is_empty(*token_queue) ) {
            QUEX_ERROR_EXIT("Token queue not empty on return from included file. This can\n"
                            "only happen if include handling was done from inside analyzer\n"
                            "actions. Please, consider directory demo/005 for an example to\n"
                            "handle file inclusion.\n");
        }
        QUEX_TOKEN_QUEUE_ASSERT(token_queue);

        if( me->size != 0 ) {
            /* Step 1: Call explicit destructors for token objects that are overwritten  */
            for(QUEX_TYPE_TOKEN_WITH_NAMESPACE* iterator = token_queue->begin; 
                iterator != token_queue->begin + me->size; ++iterator) {
                iterator->~QUEX_TYPE_TOKEN();
            }
            /* Step 2: Plain copy of objects stored in the 'remainder store'             */
            memcpy(token_queue->begin, me->token_list, sizeof(QUEX_TYPE_TOKEN_WITH_NAMESPACE) * me->size);

            /* Step 3: De-Allocate the remainder objects                                 
             *         NO explicit destructor calls, since the referred objects are now
             *         referred from inside the 'real' token queue.                      */
            QUEX_FIX3(MemoryManager_, QUEX_TYPE_STR_TOKEN_COMPLETE, _free)(me->token_list);
        }
        /* Reset the read and write iterators */
        token_queue->read_iterator  = token_queue->begin;
        token_queue->write_iterator = token_queue->begin + me->size;
        token_queue->remaining_repetitions_of_last_token_n = 0;

        QUEX_TOKEN_QUEUE_ASSERT(token_queue);
    }
#endif

#undef QuexTokenQueue_construct  
#undef QuexTokenQueue_destruct  

QUEX_NAMESPACE_COMPONENTS_CLOSE

#include <quex/code_base/temporary_macros_off>

#endif /* __QUEX_INCLUDE_GUARD__TOKEN__TOKENQUEUE */
