\documentclass[12pt,a4paper]{scrartcl}

\usepackage{amsmath, amsthm, amssymb}
\usepackage{mathtools}  
\usepackage{graphicx}   % need for figures
\usepackage{verbatim}   % useful for program listings
\usepackage{color}      % use if color is used in text
\usepackage{subfigure}  % use for side-by-side figures
\usepackage{hyperref}   % use for hypertext links, including those to external documents and R_{uni}Ls

% don't need the following. simply use defaults
\setlength{\baselineskip}{16.0pt}    % 16 pt usual spacing between lines

\setlength{\parskip}{3pt plus 2pt}
\setlength{\parindent}{20pt}
\setlength{\oddsidemargin}{0.5cm}
\setlength{\evensidemargin}{0.5cm}
\setlength{\marginparsep}{0.75cm}
\setlength{\marginparwidth}{2.5cm}
\setlength{\marginparpush}{1.0cm}
\setlength{\textwidth}{150mm}

\newtheorem{definition}{Definition}
\newtheorem{statement}{Statement}
\newtheorem{condition}{Condition}

\begin{comment}
\pagestyle{empty} % use if page numbers not wanted
\end{comment}

% above is the preamble

\begin{document}

\begin{center}
{\large State Machine Optimization by Recipes} \\ 
\copyright 2015 by Frank-Rene Schaefer         \\
January, 2015
\end{center}


%==============================================================================
%
%==============================================================================
\section{Abstract}

This document describes a procedure to transform a state machine. The original
state machine develops values along transitions from state to state. The
resulting state machine develops the same values solely through operations at
the exit of the state machine or at states which require run-time storage of
values. From an outside view, i.e. at entry and exit, both state machines
behave identical. However, the internal structure of the resulting state
machine requires less operations and is therefore more time and space efficient
than the original state machine.  The analysis exploits deterministic behavior
of operations along state transitions. 


%==============================================================================
%
%==============================================================================
\section{The Setup}

Figure \ref{fig:two-state-machines} shows a very simple state machine
consisting of four states.  The dotted lines indicate 'exit', i.e. a path that
is taken to exit the state machine.  In the original state machine, as shown in
figure \ref{fig:two-state-machines}.a, the content of $x$ is incremented upon
each transition. When the state machine is left in state 3, for example, three
such increments must have taken place. In figure \ref{fig:two-state-machines}.b
an optimized representation of the state machine is shown.  There, value of $x$
is only determined upon exit.  No increments happen during transitions. Only
upon exit $x$ is assigned the predetermined value. The balance on computational
effort is obvious.

\begin{figure}[htbp] \leavevmode \label{fig:two-state-machines}
a)
\begin{verbatim}
                     x=x+1        x=x+1        x=x+1
              ( 0 )------->( 1 )------->( 2 )------->( 3 )
                : exit       : exit       : exit       : exit
                :            :            :            :
\end{verbatim}
    
b)
\begin{verbatim}
              ( 0 )------->( 1 )------->( 2 )------->( 3 )
                : exit       : exit       : exit       : exit
                :            :            :            :
               x=0          x=1          x=2          x=3
    
\end{verbatim}
\caption{Original and optimized state machine.}
\end{figure}
                 
State machines operate on variables. Let $V_c$ name the specification of the
set of variables which are associated with an investigated behavior.  $V_c$ may
be any type of formal description such as 'all variables related to input
position storage' where the number of variables remains arbitrary.  As a
consequence of transitions, a state machine changes the content of variables.
However, not all variables of the $V_c$ are necessarily relevant for all
states. 

Let $op(i)$ name the operations applied on the variables $V_c$ upon entry into
the state machine, independent from where the state is entered. Let $op_E(i,k)$
name operations appliend upon entry, depending on the state from which they are
entered.

The original state machine must be composed of 'single-entry states'. That is,
upon entry into a state $i$ the same operations $op(i)$ are on $V_c$
independently from which the state it is entered or through which transition.
A single-entry state is shown in figure \ref{fig:se-vs-me}.a. The optimization
transforms the single-entry state machine into a 'multi-entry state machine'.
That is, the operations $op_E(i,k)$ which applied on $V_c$ upon entry into a
state may dependent on the transition from which the state is entered. A
multi-entry state in shown in figure \ref{fig:se-vs-me}.b.

\begin{figure}[htbp] \leavevmode \label{fig:se-vs-me}
a)

\begin{verbatim}
                  .---.  
           ...   ( k_0 )------.
                  '---'        \                  .-.
           ...   ( k_1 )--------+---[ op(i) ]----( i )----->   
                  '---'        /                  '-'
           ...   ( k_3 )------'       
                  '---'
\end{verbatim}
     
b)
     
\begin{verbatim}
                  .---.
           ...   ( k_0 )------[ op_E(1, k_0) ]----.
                  '---'                            \         .-.
           ...   ( k_1 )------[ op_E(1, k_1) ]------+-------( i )----->  
                  '---'                            /         '-'
           ...   ( k_3 )------[ op_E(1, k_2) ]----'       
                  '---'
\end{verbatim}
\caption{Two approaches of state modelling: a) Single entry state. 
b) Multi-entry state.}
\end{figure}

Let \textit{init state} denote the state where the state machine is entered.
Let $Pred(i)$ and $Succ(i)$ indicate the set of immediate predecessor and
successor states of state $i$. Let $Pred^*(i)$ indicate all states that lie on
a path from the init state to state $i$ \textit{but not} state $i$
itself. Let $Succ^*(i)$ indicate all states that are reachable from state $i$
\textit{together with} the state $i$ itself.


%==============================================================================
%
%==============================================================================
\section{Basic Terminology}

Along the transitions of a state machine many different operations may occur
which do not necessarily share the same subject. Some operations determine the
last accepted pattern, the input position to be restored upon acceptance, the
line and column numbers, the checksum value of a lexeme, or the sum of grapheme
widths of the lexeme's characters, and so on. The term 'investigated behavior'
is defined to specify a focus of analysis.  Let the setting of required
variables be defined as

\begin{definition}
$V(i)$ -- Set of Required Variables

$V(i)$ defines the variables which are required in state $i$ and their setting.
The variables in $V(i)$ must be sufficient

\begin{itemize}
\item to implement the nominal behavior upon exit and
\item to develop the required variables $V(k)\,\forall\,k\,\in\,Succ^*(i)$. 
\end{itemize}
\end{definition}

In contrast to $V_c$, the set of variables in $V(i)$ must be concrete.  Instead
of the loose statement such as 'all variables related to input position
storage', the specific variables with name and/or index must be specified.  The
configuration of $V(i)$ can be determined by \textit{back-propagation} of
needs. A state which requires a specific variable tags all of its predecessor
states with this requirement. That is, for a variable named $v$, it holds

\begin{equation}
    v\,\in\,V(i)\,\Rightarrow\,\forall\,k\,\in\,Pred^*(i):\,v\,\in\,V(k)
\end{equation}

Assume for example, that the lexeme length is not required in a terminal. Then
any operation contributing to the computation of the lexeme length is
redundant.  No state on a path to this terminal is required to perform lexeme
length related operations, except that another successor state requires it.  
With $V(h)$ as the setting before entry into a state $i$ and $V(i)$ as the
setting in state $i$ the operation $op(i)$ describes the modification by 
\begin{equation}
\label{eq:operation}
                         V(i) = op(i)(V(h))
\end{equation}
With the aforementioned definitions, the investigated behavior can be defined
precisely.

\begin{definition}
Investigated Behavior 

The investigated behavior determines the scope of analysis. It is
specified by a description of concerned variables $V_c$, the required
variables $V(i)$ for each state $i$, the related operations $op(i)$ and
their nominal behavior.
\end{definition}
    
A nominal behavior defines what needs to happen during the state machine
transitions.  For example, the nominal behavior for line number counting is
that the line number variable should be increased upon newline and remain the
same upon the occurrence of any other character. 


%==============================================================================
%
%==============================================================================
\section{Linear States and Mouth States}

Two central concepts are required for the further discussion: 'linear states' and 'mouth
states'.  They are defined in the paragraphs to follow. 

\begin{definition}
Linear State

A state $i$ is a linear state, if the number of immediate predecessor states is
1, i.e. 

\begin{equation}
                           size(Pred(i))\,=\,1
\end{equation}

The number of immediate successor states is arbitrary, i.e.
$size(Succ(i))\,\ge\,0$.

\end{definition}

The concept of a linear state is shown in figure 3. The operation $op(i)$ takes
the variable settings $V(k)$ of the previous state $k$ and derives $V(i)$, i.e.
the setting of variables in the current state. This can be expressed as 

\begin{equation} \label{eq:accumulation}
            V(i) = op(i)(V(k))                                         
\end{equation}

with $k$ as the one and only predecessor state. If $V(k)$ is determined, then
$V(i)$ is determined purely from the consideration of the state machine. Such a
deterministic mapping is not possible for so called 'mouth states'.

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                                                      .---> 
                                                     /
                                                   .-.
                      --------[ op(i) ]---------->( i )---> 
                         V(k)              V(i)    '-'

\end{verbatim}
\caption{The concept of a linear state in a single-entry state machine.}
\end{figure}

\begin{definition}
Mouth State

A mouth state is a state that is entered from more than one predecessor 
state, i.e.
\begin{equation}
                           size(Pred(i))\,>\,1
\end{equation}
The number of immediate successor states is arbitrary, i.e.
$size(Succ(i))\,\ge\,0$.

\end{definition}
    
\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                  ------>--.  
                 V(a)       \ 
                             \                       .-.
                  ------>-----+---[ op(i) ]---------( i )---> 
                 V(b)        /                 V(i)  '-'
                            /
                  ------>--'
                 V(c)

\end{verbatim}
\caption{The concept of a mouth state in a single-entry state machine.}
\end{figure}

Figure 4 displays the concept of a mouth state and the development of the
$V(i)$ based on the $V(a),\,V(b)$ and $V(c)$, of the predecessor states. In
a mouth state $V(i)$ depends on the path taken at run-time of the state machine.
$V(i)$ is determined as follows.

\begin{equation} \label{eq:interference}
    V(i) = \begin{dcases*}
            op(i)(V(k_0)) & if entry from state $k_0$ \\
            op(i)(V(k_1)) & if entry from state $k_1$ \\
            \ldots \\
            op(i)(V(k_n)) & if entry from state $k_n$ \\
            \end{dcases*}
\end{equation}


%==============================================================================
%
%==============================================================================
\section{Recipes}

The procedure to be described shall exploit deterministic characteristics
inside a state machine. Once they are found many operations along transitions
may be omitted. Only when exiting the state machine, or at mouth states,
operations shall be implemented. The key concept for the underlying
analysis is the 'recipe'. The definition of a recipe, however, requires
the term 'auxiliary variables' to be specified.

\begin{definition} $A$, $A(v)$ -- Auxiliary Variables

The term auxiliary variable $A(v)$ specifies a variable that may store the
a 'snapshot' of a variable $v$-s content upon entry into a mouth state. 
   
Let $A$ name the set of all auxiliary variables.
\end{definition}

So called 'hidden variables' are variables inside the state machine other than
the current state.  For example, a lexical analyzer state machine has the
lexeme start position, the buffer limits, the stream position, etc. as hidden
variable. 

\begin{definition} $R_E(i,k),\,R(i)$ -- Recipe 

For a given state $i$, let $R(i)$ signify a procedure that is able to compute
$V(i)$ solely from the state machine's hidden variables and the auxiliary variables.
In particular there is no direct dependency upon a transition operation $op(i)$.
It performs the mapping

\begin{equation} \label{eq:recipe-procedure}
    (h, A) \rightarrow V(i)                                             
\end{equation}

Let $R_E(i,k)$ names the recipe upon entry into a state $i$ from a predecessor
state $k$. It corresponds to the concatenation of state $k$'s output recipe
$R(k)$ and state $i$'s operation $op(i)$, that is
\begin{equation} \label{eq:entry-recipe-concatenated}
    R_E(i,k) \,=\, op(i)(R(k))
\end{equation}

Let $R^v(i,k)$ and $R^v(i)$ signify the components of $R(i,k)$ which produces
$v\,\in\,V(i)$.  
\end{definition}

The fundamental difference between $R(i)$ and $V(i)$ is that the former
describes a procedure and the latter represents the values which are produced.
With the concepts of this section, the overall goal can be formulated. The
analysis transforms the given single-entry state machine based on operations
into a multi-entry state machine based on recipes. Observing only the entry and
exit, the changes to $V_c$ must comply to the nominal behavior. 


%==============================================================================
%
%==============================================================================
\section{Accumulation and Interference}

Linear states change variables in a deterministic way. There is only one entry
into such a state $i$. If the predecessor state $k$'s recipe $R(k)$ is
determined, then the states recipe by equation \eqref{eq:entry-recipe-concatenated} 
is determined straight-forward.
\begin{equation} \label{eq:linear-state-recipe}
    R(i) \,=\,R_E(i,k) \,=\, op(i)(R(k))
\end{equation}
The above equation shows that recipes can be developed along linear states by
plain concatenation of operations.  For a mouth state, the development of the
state's recipe is not so deterministic.  Instead, it depends on the path by
which the state is entered.  From equation \eqref{eq:entry-recipe-concatenated}
and \label{eq:interference}, it follows directly
\begin{equation} \label{eq:mouth-state-recipe}
    R(i) = \begin{dcases*}
             R_E(i,k_0) & if entry from state $k_0$ \\
             R_E(i,k_1) & if entry from state $k_1$ \\
             \ldots \\
             R_E(i,k_n) & if entry from state $k_n$ \\
            \end{dcases*}
\end{equation}
For the general case, this shows that recipes may not be developped accross
mouth states, except if auxiliary variables are computed. That is, if there
are entry operations in place which assign a value to an auxiliary variable $A(v)$
\begin{equation}
    A(v) :=  \begin{dcases*}
             R^v_E(i,k_0) & if entry from state $k_0$ \\
             R^v_E(i,k_1) & if entry from state $k_1$ \\
             \ldots \\
             R^v_E(i,k_n) & if entry from state $k_n$ \\
            \end{dcases*}
            \,\forall\v\,\in\,V(i)
\end{equation}
Then, the output recipe $R(i)$ is determined by
\begin{equation}
    R^v(i) \,=\, \{ v = A(v) \}\,\forall\,v\,\in\,V(i)
\end{equation}
and can be used for further development of recipes. If all recipes $R^v_E(i,k)$
with $k\,\in\,Pred(i)$ are the same, then the recipe can be overtaken into
$R^v(i)$. That is,
\begin{equation}
    R^v(i) \,=\, R^v_E(i,k)\,\mbox{if $v$ is homogeneous}.
\end{equation}
Let the expression '$v$ is homogeneous/inhomogeneous' be precisely defined.
\begin{definition} Homogeneity/Inhomogeneity

    The expression '$v$ is homogeneous' at the entry into a mouth state $i$
    means, that all entry recipes are equal, i.e.
    \begin{equation}
        \begin{aligned}
        \forall\,p,\,q\,\in\,Pred(i):\,R_E^v(i,p)\,=\,R_E^v(i,q) 
        \end{aligned}
    \end{equation}
    The expression '$v$ is inhomogeneous' means the contrary.
\end{definition}

As soon as a recipe relies on a value in an auxiliary variable, it depends on
the state where the snapshot has been taken.  
\begin{definition} $S_m(X)$,
    $S(X)$ -- Snapshot Map, Snapshot States.

    The snapshot map $S_m(X)$ related to an operation $X$ maps from all
    variables that are restored from auxiliary variables to the state index
    where the snapshot $A(v)=v$ has been taken.
    
    \begin{equation}
        \label{eq:snapshot-map}
        S_m(X):  v\,\rightarrow\,\mbox{state}\,i,\,\mbox{where}\,A(v)\,=\,v\,\mbox{was applied.}.
    \end{equation}

    The set of snapshot states $S(X)$ is the set of all states mentioned in
    $S_m(X)$.

\end{definition}
The state in which an auxiliary variable takes a 'snapshot' is crucial when
comparing two recipes. Two recipes may contain the same procedure, but if they rely on
stored values from different state, then they cannot be equal in general.
\begin{statement}
   If the snapshot maps of two recipes are unequal, then the two recipes
   are unequal, that is
   \begin{equation} \label{eq:snapshot-map-difference}
       S_m(R(i)) \neq S_m(R(i)) \Rightarrow R(i) \neq R(k)
   \end{equation}
   Since, the set of related states cannot be different without differring 
   snapshot maps, it follows without restricting generality
   \begin{equation} \label{eq:snapshot-map-difference2}
       S(R(i)) \neq S(R(i)) \Rightarrow R(i) \neq R(k)
   \end{equation}
\end{statement}
With the aforementioned concepts of entry operations $op_E(i,k)$, auxiliary
variables $A(v)$, homogeneity and inhomogeneity, as well as snapshot maps,
it is now possible to specify a procudure that develops recipes accross
mouth states.

\begin{definition} Interference

The process of 'interference' develops a recipe $R(i)$ for a mouth state $i$
based on entry recipes $R_E(i,k) = op(i)(R(k))\,\mbox{with}\,k\,\in\,Pred(i)$.
The output recipe $R(i)$ depends on the homogeneity of $v$, i.e. 
\begin{equation}
    R^v(i) = \begin{dcases*}
              R_E^v(i,k) & if $v$ is homogeneous.\\
              A(v)       & else
             \end{dcases*}
\end{equation}
for an arbitrary $k\,\in\,Pred(k)$. Whenever $v$ is inhomogeneous, entry
operation $op_E(i,k)$ must be implemented in the resulting state machine that
stores the computed value of $v$ in $A(v)$, i.e.
\begin{equation}
    op_E^v(i,k) \,=\, \{ A(v) \,=\, R^v_E(i,k) \} \,\mbox{if $v$ is homogeneous}.
\end{equation}
for an arbitrary $k\,\in\,Pred(k)$. In case of $v$ is homogeneous, the snapshot maps
are remain. For the snapshot maps it holds
\begin{equation}
    S^v_m(R(i)) = \begin{dcases*}
                  S^v_m(R(k))    & if $v$ is homogeneous.\\
                  v \leftarrow i & else
                  \end{dcases*}
\end{equation}
for an arbitrary $k\,\in\,Pred(k)$. A prerequisite for interference is that 
all $R_E(i,k)\,k\,\in\,Pred(i)$ are determined.
\end{definition}

Applying interference to linear states ends up again with equation 
\eqref{eq:linear-state-recipe}, because there is only one entry recipe
which is naturally homogeneous on all $v\,\in\,V(i)$. This guides to 
a procedure to develop recipes accross linear states.

\begin{definition} Accumulation

Given a state $i$, its predecessor state $k$, the entry operation $op(i)$
the predecessor's recipe $R(k)$, the recipe $R(i,k)$ is given by
\begin{equation}
       R(i)\,=\,op(i)(R(k)
\end{equation}
If auxiliary variables $A$ are involved, then the snapshot maps do not change. 
\begin{equation} \label{eq:accumulation-aux}
    S_m(R(i))\,=\,S_m(R(k))
\end{equation}
A prerequisite for accumulation is that $R(k)$ of the predecessor is 
determined.
\end{definition}

Accumulation and interference describe how recipes are developed from recipes.
But, where does the first recipe come from?  Let operation $op^v(i)$ that
assigns a constant to $v$ be called a $constant operation$. It is something
special. The behavior of the concatenation $op^v(i)(R(k))$ is independent of
$R(k)$. 
\begin{definition} Spring

    A spring is a state $i$ where all operations $op^v(i)\,\forall\,v\in\,V(i)$
    are constant. 
    
\end{definition}
A spring can be the starting point of analysis, because it can derive a recipe
without knowing the predecessor's recipe. 

--------------------------------------------

In the case of inhomogeneous entry recipes $A(v)$ requires that entry
operations are performed.  It is the existence of the entry operations
$op_E(i,k)$ that induces the necessity of multi-entry states.  Before
interference can be performed, all entry recipes must be determined.  As long
as this is not the case, $R(i)$ cannot be determined. In consequence, no
successor state's recipe can be determined through accumulation. In other
words,  a mouth state blocks any propagation of recipes as long as not all
predecessor recipes are determined. 

The development of recipes along linear states is straight-forward. However,
the recipe for a mouth state may be optimized in some cases. 

A recipe for one state is the basis for the development of the recipe of its
successor state. For a linear state, equation \eqref{eq:operation} described
how $V(i)$ is determined from the predecessor's $V(k)$ and the entry operation
$op(i)$. If $V(k)$ can be determined by a recipe $R(k)$, then $V(i)$ becomes

\begin{equation} \label{eq:accumulation2}
           V(i) = op(i)(R(k))                                     
\end{equation}

The recipe for $V(i)$ becomes nothing else than the expression that determines
it. That is,

\begin{equation} \label{eq:accumulation3}
           R(i)\,=\,\{ op(i)(R(k)) \}                                 
\end{equation}
                 
In equation \eqref{eq:accumulation3} it is demonstrated how a recipe $R(i)$ is
derived from a predecessor's recipe $R(k)$ and a state $i$-s operation $op(i)$.
This procedure is defined here as 'accumulation'.

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                  op(b)=        op(c) =      op(d) =
                    x=x+1         x=x+1         x=x+1        
            ( a )-------->( b )-------->( c )-------->( d )--------> ...


\end{verbatim}
\caption{A sequence of linear states.}
\end{figure}

\subsection{Example}

Figure 6 displays an example with a single variable $x$. The operations $op(i)$
upon transition are $x=x+1$ for all states. That is $x$ is incremented by 1 at
each step. Let the $A(x,a)$ signify $A(x)$ as it was assigned upon entry into
state $a$. This notation combines the recipe's procedure with its snapshot map.
In the above example, the recipe in state $a$ solely restores what has been
stored.

\begin{equation}
\label{eq:}
               R(a) = { x := A(x,a) }                                     
\end{equation}

The recipe 'R(b,a)' must be equivalent to the concatenated execution of 'op(b)'
and 'R(a)', i.e.

\begin{eqnarray}
    { x & := & A(x,a) } \\
    { x & := & x + 1 }
\end{eqnarray}
So, 
\begin{eqnarray}
    R(b)  =  \{ x := A(x,a) + 1 \}                                 
\end{eqnarray}

This rule applied repeatedly for the states 'c' and 'd' leads to

\begin{eqnarray}
    R(c) & = & \{ x := A(x,a) + 2 \} \\
    R(d) & = & \{ x := A(x,a) + 3 \}                                 
\end{eqnarray}

If the state machine exits at $a$, $b$, $c$, or $d$ the content of $x$ can be
determined without relying on the intermediate operations $\{ x:=x+1 \}$. This
is shown in figure 7.
 
\begin{figure}[htbp] \leavevmode
\begin{verbatim}
          ( a )-------->( b )-------->( c )-------->( d )--------> ...
                          :             :             :
                        x=A(x,a)+1    x=A(x,a)+2    x=A(x,a)+3


\end{verbatim}
\caption{Recipes upon exit replace transition operations.}
\end{figure}

The repeated accumulation of recipes along linear states comes to an end at
mouth states.  Equation \eqref{eq:interference} described the development of
$V(i)$ in mouth state. Using the concept of a recipe, the equation can be
rewritten as

\begin{eqnarray}
    V(i)  =  \begin{dcases*}
               R(i,k_0) &  if entry from state $k_0$ \\
               R(i,k_1) &  if entry from state $k_1$ \\
               \dots                                 \\
               R(i,k_n) &  if entry from state $k_n$
            \end{dcases*}
\end{eqnarray}

The applied recipe depends on the origin state of the transition which is only
determined at run-time.  For each variable $v$ in $V(i)$ there are two
possibilities:


As mentioned in equation \label{eq:snapshot-map-difference}, two recipes are
different if their snapshot maps differ. In other words, two recipe procedures
may rely in the same way on a stored value $A(v)$, but if it has been stored
stored in different states, they are still not the same.

If a variable $v$ is determined homogeneously, then the part of the recipes
that determines it can be overtaken into $R(i)$. Otherwise, the value must be
computed upon entry and stored in an $A(v)$. The recipe $R(i)$ must then rely
on $A(v)$. Let this process be defined as 'interference'.


The next section treats the recursive propagation of recipes by accumulation.
It is conceivable, however, that at the begin of analysis all mouth states are
undetermined. Even the initial state may be an undetermined mouth state--so
there are no springs. In that case, the analysis directly starts with a so
called 'dead-lock analysis'. This is the subject of the next section but one.


%==============================================================================
Any operation that relies on auxliary variables has an implicit dependency
on the state where the variable has been stored. Let this information be
called a 'snapshot map'.

%==============================================================================
%
%==============================================================================
\section{Propagation By Recursive Accumulation}

The recipes for states are determined by a 'walk' along linear states. While
linear states have only one entry, they may have transitions to more than one
state. So, the walk along linear states is a recursive 'tree-walk'. If the
entry to a linear state $i$ is determined, then by accumulation, the output
recipe $R(i)$ can be determined. This recipe may then be applied to all
immediate successor states $Succ(i)$. Each of those produces its recipe by
accumulation, and so on. The termination criteria for the walk along linear
states is defined as follows.

\begin{definition}
Termination criteria for walk along linear states.

A recursive walk along linear states does not enter the state ahead, if 

\begin{itemize}
    \item there is no state ahead (i.e. the current state is a terminal).
    \item the state ahead is a mouth state.
    \item the state ahead is a spring.
\end{itemize}
\end{definition}

The first condition comes natural. The second condition exists, because recipes
cannot be accumulated beyond mouth states. As a direct consequence, the walk
can never go along loops, since a loop requires a state with more than one
entry. The third condition tells that the walk stops where another walk begins
or began.  With the ideas of a spring, linear states, accumulation and the
given termination criteria, an algorithm for the determination of recipes can
be defined.

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
          (*) Start.
          (1) springs = initial springs of state machine.
   .----->(2) recursive accumulation along linear states starting from springs.
   |          --> determine R(i) along linear states until terminal,
   |              mouth, or springs.
   |          --> entries of mouth states receive entry recipes.
   |      (3) interference in mouth states with complete sets of entry
   |          recipes.
   |      (4) springs = determined mouth states
   '- no -(5) springs empty?
          (*) Stop.
\end{verbatim}

\caption{Determination of recipes.}
\end{figure}

When this algorithm comes to an end, there might be still mouth states with
undetermined entries.  To this point in time, all behavior of the state machine
was investigated off-line. The following section discusses a solution for the
remaining states where the deterministic propagation of recipes could not
provide a solution.

%==============================================================================
%
%==============================================================================
\section{Dead-Lock States}

Interference can only be performed, if all entry recipes of a mouth state are
determined. Loops in the state machine graph, however, may cause
\textit{circular dependencies} and undetermined undetermined mouth states.
Figure 8 shows an example, where the two states 1 and 2 mutually block each
other. The recipe $R(1)$ for state 1 cannot be determined because it requires
$R(2)$ which is undetermined. However, before $R(2)$ from state 2 can be
determined, $R(1)$ must be present. None of the states 1 and 2 is suitable for
interference, because they are missing an entry recipe.  Circular dependencies
as an origin of dead-lock states are intuitive. The precise proof is provided
in the subsequent paragraphs. What follows describes a procedure to determine
the behavior of those dead-lock states and their dependent states.

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                                       R(1)
                          R(0)     .---->----.
                    ( 0 )------>( 1 )       ( 2 )
                                   '----<----'
                                       R(2)

\end{verbatim}
\caption{A dead-lock in mouth states 1 and 2.}
\end{figure}

\begin{definition} $U$ -- The Set of Dead-Lock States

A dead-lock state $i\,\in\,U$ is a mouth state that, after algorithm 1 has
ended, is still undetermined. It has at least one undetermined entry which
prevents it from performing interference. $U$ is the set of all dead-lock
states.

\end{definition}

Linear states do not contribute to the discussion of determinacy. A linear state's
output recipe is determined through accumulation if and only if its predecessor
is determined. On the other hand, if the predecessor is undetermined, then the 
state itself cannot be determined. Indeterminacy originates from interference 
that cannot be performed in mouth states. Thus, the strings of linear states
in between the mouth states can be omitted from consideration of determinacy.

An undetermined mouth state $i \in U$ must have at least one undetermined entry
recipe. Either the state from which it is entered is an undetermined mouth state, 
or the string of linear states backwards guides to an undetermined mouth state. 
Let the fact that a mouth state $i_0$ is undetermined because of another
undetermined mouth state $i_1$ be noted as $i_0 \vartriangleleft i_1$. Their might
be more than one dependency, but considering one is enough for this proof. Each
undetermined mouth state has at least one undetermined mouth state that feeds
an undetermined entry. Thus, the sequence 

\begin{equation}
    i_0\,\vartriangleleft\,i_1\,\vartriangleleft\,i_2\,\vartriangleleft\,\ldots
\end{equation}

has no end. But the set of undetermined states $U$ is finite. Thus, there must
be states appearing repeatedly in the sequence. Since the dependencies relate to
transition paths, this proves that loops must be involved. Also, it proves that
the reason for the existence of dead-lock states are circular dependencies of
undetermined mouth states.

\begin{definition}
Horizon

Let the term 'horizon' $H$ indicate the subset of dead-lock states $\{
i\,\in\,U \}$ that have at least one determined entry.  
\end{definition}

The name 'horizon' is chosen because it defines the border of determination.
Beyond that begins the realm of dead-locks. Figure 9 shows a horizon state
which contains one determined entry and another undetermined entry.  The
process of propagation of recipes ended with dead-lock states. In order to
understand the nature of dead-lock states better, it makes sense to briefly
review this process. 

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                         R(a) -->--.
                                    \
                                     +---[ op(i) ]---( i )----> R(i)
                                    /
                     R(b) = ? -->--'

\end{verbatim}
\caption{A mouth state with a determined entry recipe $R(a)$ and 
an undetermined entry recipe $R(b)$.}
\end{figure}

The init state is the first state that is entered. It has at least one recipe
$R(outside)$, i.e. the recipe to be applied when coming from $outside$ the
state machine. If it has another entry that is undetermined, then the init
state becomes a horizon state. If the init state has no other entry, then it is
a spring and determined recipes are propagated through accumulation.
Accumulation ends with the determination of an entry into a mouth state. If the
reached mouth state ends up with determined entries, then a determined recipe
is propagated until a terminal or another mouth state is reached. If a mouth
state is reached where not all entries are determined, then its output recipe
is undetermined. Since by reaching it at least one entry is determined and,
thus,the state is a horizon state. The output recipe is undetermined and no
successor state is further reached with determined recipes. Consequently, all
successor states of that state are undetermined.  With the aforementioned
discussion, an important conclusion can be drawn.  Determined mouth states 
performed interference, and therefore must have all their entries determined. 
None of their entries can directly originate in a dead-lock mouth state.

\begin{statement} \label{stm:dead-lock-horizon}
A dead-lock state can only reached by a path that guides through a horizon
state.  Paths from dead-lock states to non-dead-lock mouth states must contain
a spring.  
\end{statement}

At this point a type of interference is introduced that delivers a correct
output recipe, even though not all entry recipes are determined.

\begin{definition}
Run-Time Dependent Interference

The process of 'run-time dependent interference' develops a recipe $R(i)$ for a
horizon state $i\,\in\,H$.  From the homogeneity requirement it follows that
the output recipe $R(i)$ is determined by 
          
\begin{equation}
    R^v(i) = \begin{dcases*}
              op^v(i) & if $op^v(i)$ is constant \\
              A(v)    & else
             \end{dcases*}
\end{equation}

For each $v$ where $A(v)$ is used an entry operation $op_E(i,k)$ is required,
but the entry recipes $R_E^v(i,k)$ are not yet determined. So the entries are
'marked' by $F_E^v(i,k)$ to indicate that the value of $v$ needs to be
stored in $A(v)$.

\begin{equation}
    F_E^v(i,k) = \begin{dcases*}
                     false & if $op^v(i)$ is constant \\
                     true  & else
                 \end{dcases*}
\end{equation}

\end{definition}

As soon as entry recipes are found, the entries for which $F_E^v(i,k)$ is
true need to store $A(v)=R_E^v(i,k)$. The correctness of this approach is now
considered. First, it can be determined that no dependency on stored values 
from before a horizon state remain at the output recipe, that is for a horizon
state $i$'s recipe $R(i)$ after run-time interference it holds

\begin{equation}
                      S(R(i))\,\subseteq\,\{\,i\,\}
\end{equation}

That is, either it relies on snapshot values taken at the horizon state, or it
does not depend on any stored value at all. The later is only true, if every
$op^v(i)$ is constant. For all states of the horizon it follows that

\begin{equation}
                \bigcap_{i \in H}S(R(i))\,\subseteq\,H
\end{equation}
and in particular
\begin{equation}
    \bigcup_{i \in H}S(R(i))\,\cap\,\bigcap_{i \in H}\,Pred(i)\,=\,\emptyset
\end{equation}

From statement \ref{stm:dead-lock-horizon} it can be derived that only such
recipes are propagated to entries of dead-lock states which come from horizon
states, or springs.  Equation \eqref{eq:spring-no-aux} shows that for a spring
state $s$ it holds that $S(R(s)))=\emptyset$, because it only depends on
constants not on operations on previous values. All dead-lock states can only
rely on snapshots at the horizon states or states from inside the dead-lock
group, i.e.

\begin{equation} \label{eq:snapshot-in-dead-locks}
    S(R(p))\,\subseteq\,U
\end{equation}

Let the following two predecessor recipes of a horizon state be defined: $R^v_d$
is the prototype of a determined predecessor recipe and $R^v_u$ is the prototype
of an undetermined predecessor recipe. For the determined entry, it holds that
the path to it does not include a dead-lock state. Thus,

\begin{equation}
        S(R^v_d)\,\cap\,U\,=\,\emptyset
\end{equation}

An undetermined recipe must originate in a dead-lock state, thus according to
equation \eqref{eq:snapshot-in-dead-lock} and the rule for snapshot maps during
accumulation \eqref{eq:accumulation-aux}, it holds that
$S(R^v_u)\,\subseteq\,U$.  Thus, the condition for homogeneity in a horizon
state

\begin{equation} \label{eq:homogeneity-horizon-state}
    R^v_u\,=\,R^v_d
\end{equation}

can only be true if $S(R^v_u)=S(R^v_d)=\emptyset$, that is all entry recipes
result in a constant for $v$. This result is very important, because it states
that even from the recipes coming through the undetermined entries (represented
by $R_u$) it is impossible that $S(R(i))$ at a horizon state will ever contain
a reference to a state from the realm of dead-lock states behind the horizon,
i.e.

\begin{equation}
    S(R(i))\,\cap\,U\,=\,\{\,i\,\}
\end{equation}

That means nothing less, than that the run-time interference approach
$R^v(i)=A(v)$ with $S(R^v(i))\,\subseteq\,\{\,i\,\}$ is a general solution.
The output recipes can be used for propagation of recipes until other dead-lock
states receive at least one determined entry. The horizon moves, makes the
set of dead-lock states smaller and a new cycle begins. This continues until
not dead-lock state is left. 

Then all entry recipes are determined. It is now possible that those entries
which are flagged with $F_E^v(i,k)=true$ implement the entry operation
$op_E^v(i)=R_E^v(i,k)$. But, wait! There might be some fine-tuning coming up.


%==============================================================================
%
%==============================================================================
\section{Fine Tuning of Dead-Lock States}

As mentioned in the previous section, the condition of homogeneity in the
entry recipes can be maintained, if they are constant, i.e.

\begin{equation}
     S(R^v_u)\,=\,S(R^v_d)\,=\,\emptyset   
\end{equation}

For run-time interference, before, only $op^v(i)$ has been overtaken to the
output recipe $R^v(i)$ if it was constant independently of the predecessor
recipe. Now, that all entry recipes are determined, homogeneity can be achieved
if the concatenation of $op^v(i)$ and the precessors recipes $R(k)$ for all
$k\,\in\,Pred(i)$ is constant--the same constant, to be precise.  Consider the
example of 

\begin{equation}
                       op^v(i) = \{ v = v + 1 \}
\end{equation}

The operation is clearly dependent on the previous value of $v$--thus not
constant. However, if the predecessors recipe $R(p)$ assigns a constant $5$ to
$v$, then the concatenation becomes

\begin{equation}
                       op(i)(R(p)) = \{ v = 6 \}
\end{equation}

which does not depend on any auxiliary variable. If all entry recipes result in
the same constant assignment, then the entry recipes for $v$ are homogeneous.
The same constant may appear in the output recipe. Since no storing and restoring
is now required for $v$, the 'entry operation implementation flag' can be turned
of, that is

\begin{equation}
    F_E^v(i,k)\,=\,false\,\mbox{if}\,op^v(i)(R(k))\,=\,C\,\forall\,k\,\in\,Pred(i)
\end{equation}

A recipe $R(i)$ that replaces some components by constants can now again be
propagated through accumulation. An entry is only constant if it is totally
independent of its predecessor states. The output of a successor mouth state
will only become constant, if all of its inputs are constant. Thus, constant
components are only propagated beyond mouth states if all entries are constant.
If all entries are constants they are all independent of their precessors.
Thus, also the mouth's output recipe remains constant. It follows that through
constant propagation, recipes become constant but never change their value
further.  In particular, it is impossible that they become non-constant.

The repeated propagation of recipes may be applied with the difference of the
following termination criteria.

\begin{condition}
Condition for interference during dead-lock fine-tuning.

The result of interference is only to be taken into account, if the size of the
new recipe's snapshot map is smaller than the size of the old recipe's snapshot
map.  
\end{condition}

With the mentioned requirement a mouth state $i$ can be passed at maximum a
restricted $N$ number of times, where $N$ is the number of variables in
$V(i)$. Since, number of states is restricted in general, the total number of
propagations is restricted. At that point, no new constant entry recipes could
be determined. Thus the fine-tuning has reached its optimum.

Once, fine tuning is done the remaining entry operations $op_E^v(i)$ for which
$F_E^v(i,k)=true$ must be implemented according to $R_E^v(i,k)$.

\end{document}

