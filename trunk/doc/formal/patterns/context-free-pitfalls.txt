The most dangerous pitfall is related to precedence and length. Note, that a 
pattern that is defined {\it before} another pattern has a higher
precedence. Also, if a pattern can match a longer chain of characters it wins.
Thus, if there are for example two patterns

[cpp]
source~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     [A-Z]+     => TKN_IDENTIFIER(Lexeme);
     "PRINT"    => TKN_KEYWORD_PRINT;
source~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

then the keyword `PRINT` will never be matched. This is so, because
`[A-Z]` matches also the character chain `PRINT` and has
a higher precedence, because it is defined first. To illustrate the
danger of 'greedy matching', i.e. the fact that length matters, let
two patterns be defined as:

[cpp]
source~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     "Else"             => TKN_KEYWORD_ELSE;
     "Else\tAugenstein" => TKN_SWABIAN_LADY(Lexeme);
source~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Now, the `Else` statement may be matched, but only if it is not
followed by tabulator and `Augenstein`. On the first glance, this
case does not seem to be very probable. Sometimes it may be necessary,
     though, to define delimiters to avoid such confusion. In the very large majority of
     cases 'greedy matching' is a convienient blessing. Imagine the problem with 
     identifiers, i.e. any chain of alphabetic characters, and a keyword '`for`'.
     If there was no greedy matching (longest match), then any variable starting
     with `for` could not propperly be detected, since the first three letters
     would result in the `for`-keyword token.

As for version 0.10.0, quex has a deficiency which is due to the parsing algorithm
of the mode definition parts. Until then, it was not possible to define spaces '\kern 1ex' 
directly directly inside mode definitions, i.e.

[cpp]
source~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
mode {
    [ \t\n]    {
	// ... reaction on whitespace ...
    }
}
source~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

However, this issue has been solved from version 0.15.1 on. One has to be
cautious, though using newlines and tabs.  You can in certain circumstances
define a newline or a tab trigger as directly 'as is', i.e. as a line break and
a tabulator.  This is perfectly coherent with the regular expression grammar.
However, for clarity it is better to use the `\t` and `\n` 
expressions. Note, that a whitespace as a lonestanding character
    ends the regular expression. Using 'real' newlines and tabulators may cause problems when lonestanding
    characters are parsed in groups. With the backslashed expressions there is
    no danger and things are clear.
