Include Stack
=============

.. note:: 

   The API for include stack handling is likely to change until V 0.39.1. 
   When using this API earlier, keep in mind to get back here to ensure
   that you update your interface.

A useful feature of many programming languages is the feature to *include*
files into a file. It has the effect that the content of the included file is
treated as if it is pasted into the including file. For example, let ``my_header.h``
be a 'C' file with the content

.. code-block:: cpp

   #define TEXT_WIDTH 80
   typedef short      my_size_t;

Then, a C-file ``main.c`` containing

.. code-block:: cpp
   
   /* (C) 2009 Someone */
   #include "my_header.h"
   int main(int argc, char** argv)
   {
       ...
   }

produces the same token sequence as the following code fragment where
``my_header.h`` is pasted into ``main.c`` 

.. code-block:: cpp

   /* (C) 2009 Someone */
   #define WIDTH 80
   typedef short my_size_t;

   int main(int argc, char** argv)
   {
       ...
   }

What happens internally is that the following:

   1. An ``#include`` statement is found.
   2. The analyzer switches to the included file
   3. Analyzis continues in the included file until 'End of File'.
   4. The analyzer switches back to the including file and continues
      the analyzes after the ``#include`` statement.

This simple procedure prevents users from writing the same code multiple times.
Moreover, it supports centralized organization of the code. Scripts or
configurations that are referred to in many files can be put into a central
place that is maintained by trustworthy personal ensuring robustness of the
overall configuration. The advantages of the simple ``include`` feature are
many. In this section it is described how quex supports the inclusion of
files.

.. _fig-include-stack-example:

.. figure:: ../figures/include-stack-sdedit.*

   Inclusion of content from other files.

Figure :ref:`fig-include-stack-example` shows what happens behind the scenes.
The lexical analyzer first reads the file ``main.c`` until it hits on an
include statement. This statement tells it to read the content of file
``my_header.h`` and then continue again with the remainder of ``main.c``. In
order to do this the lexical analyzer needs to store his state-relevant [#f1]_
in a so called *memento* [#f2]_. When the analysis of ``my_header.h``
terminates on 'end of file' the memento can be unpacked and the old state
revived. The analyzis can continue in the file ``main.c``. 

.. _fig-include-stack-N-example:

.. figure:: ../figures/include-stack-N-sdedit.*

   Recursive inclusion of files.

If an included file includes another file, then the memento needs to know that
there is some 'parent'. Thus the chain of mementos acts like a stack where the
last memento put onto it is the first to be popped from it. An example is shown
in figure :ref:`fig-include-stack-N-example` where a file A includes a file B
which includes a file C which includes a file D. Whenever a file returns the correct
memento is unpacked and the lexical analyzer can continue in the including file.
The mementos are lined up as a list linked by 'parent' pointers as shown
in :ref:`List of Mementos <fig-memento-queue>`. The parent pointers are required
to find the state of the including file on return from the included file.

.. _fig-memento-queue:

.. figure:: ../figures/memento-queue.*

   List of Mementos implementing the Include Stack.

.. note::

   The memento class always carries the name of the lexical analyzer plus the
   string ``Memento``. If for example an analyzer is called ``Tester``, then
   the memento is called ``TesterMemento``. The name of this class might be
   needed when iterating over mementos, see :ref:`Infinite Recursion Protection
   <sec-infinite-recursion>`.

Using the include stack handler all revolves around the following member functions
of the lexical analyzer:

.. cfunction:: void  include_push(input_handle, ...) 

   By means of this function the current lexical analyzer state is packed into
   a memento and the analysis of the new file is initialized. This function
   is usually called whenever an ``include``-like token is found.

   .. data:: input_handle

      Must have the type for which the analyzer was instantiated (e.g. ``FILE*``, ``istream*``, or so.).
      By means of this handle the content of the included file is accessed.

   .. data:: mode (optional)

      Start mode in which the include file shall be analyzed. Defaultwise the 
      initial mode is used.

   .. data:: BufferFillerType (optional)

      Must be a constant defined in the enum ``QuexBufferFillerTypeEnum``, e.g. ``QUEX_PLAIN``, 
      ``QUEX_CONVERTER``, etc.. By default the same filler type is used as in the current
      file.

   .. data:: CharacterCodingName (optional)

      Character encoding name for the converter. By default the same encoding is
      used as in the current file.
        
.. cfunction:: bool  include_pop()

   This function unpacks a memento from the stack and puts the analyzer in the state in
   which it was before the inclusion. This function must be called when an 'end of file'
   is reached. Return values are

   .. data:: true

      if there was a memento and the old state was restored.

   .. data:: false

      if there was no memento. The analyzer is in the root of all files. The most appropriate
      reaction to this return value is to stop analyzis--at least for the given file.

The Token Queue and The Include Stack
-------------------------------------

There are two basic ways to handle the inclusion of files during analyzis.
First, files can be included from within analyzer actions, i.e. as consequence
of a pattern match or an event. Second, they can be included from outside when
the ``.receive(...)`` function returns some user define ``INCLUDE`` token.  As
long as the token policy ``users_token`` is used there is no problem and the
functions ``include_push(...)`` and ``include_pop(...)`` as described above can
be used without precaution. When a queue token policy is used, though, the
possibilities of handling become plenty and varry in terms of performance and
memory usage. Therefore, the token queues are not subject to the automatic
include handling. This section outlines the process and explains how to
implement ones own strategy easily.

Let us review the two possibilities to handle the inclusion of files:

  #. The file is included from inside pattern actions. The code fragment
     displays how this can be done for the example of a pattern ``\input``
     triggers the inclusion of a file.

     .. code-block:: cpp

         mode NORMAL : 
              E_O_F 
         { 
             ...
             "\\input" => GOSUB(READ_INCLUDED_FILENAME);
             ...
         }
         ...
         mode READ_INCLUDED_FILENAME : 
              E_O_F 
         {
             [a-bA-Z_0-9]".txt" { 
                 /* open the file to be included    */
                 FILE*   fh = fopen(Lexeme, "r");
                 /* push the lexical analyzer state */
                 self.include_push(fh);
                 /* return to the NORMAL mode       */
                 self.enter_mode(NORMAL);
                 /* IMPORTANT */
                 return;
             }

             . { 
                 my_error_message("Missing file name after '\\input'");
             }
         }

     When an included file returns from the analyzer state must be restored. The
     end of an inclusion is triggered by end of stream. Both modes need to support
     the same this behavior so they inherit from a common base mode ``E_O_F``. It
     is defined as 
            
     .. code-block:: cpp

         mode E_O_F {
             <<EOF>> { 
                 /* If there was no state to restore, then we are in the root file
                  * and return the TERMINATION token, we are totally done.          */
                 if( self.include_pop() == false ) {
                     self.send(QUEX_TKN_TERMINATION);
                     return;
                 }
                 /* The include_pop(...) has reset the state of the analyzer. 
                  * Nothing to be done.                                             */
             }
         } 

   The user is basically isolated from the processes behind the scenes. The consistency
   is even maintained in cases where a queue token policy is used, i.e. policy 
   ``queue``, or ``users_queue``. Remainders of token queues are packed together with 
   the memento, and unpacked when the memento is unpacked. 

   Since the function ``include_pop()`` is supposed to be called upon 'end of file'
   it is assumed that this 'end of file' is the last token and no tokens remain
   in the queue of the included file.

   If a queue token policy is used and the token queue is not empty when 
   ``include_pop()`` is called, the analyzer aborts. There is simply no token
   to come after an 'end of file'!

Memento Extensions
------------------

As shown in :ref:`sec-basics-sections` the ``body`` section allows for the 
definition of new members in the analyzer class. Imagine a scenario where
new variables are defined in the analyzer class and those variables 
are file specific and are state relevant. In order to avoid to 
distort the data with the results of an included file, the variables
have to be packed with the memento. Vice versa, the variable need to 
be restored when the memento gets unpacked. 

In the quex source files the memento behavior can be influenced by the 
sections ``memento``, ``memento_pack``, and ``memento_unpack``. The following
implicit variables are available in ``memento_pack`` and ``memento_unpack``:

.. describe:: self

   Reference to the lexical analyzer.

.. describe:: memento

   Pointer to the memento object.

.. describe:: InputH

   *Only for* ``memento_pack``.

   Input handle that was passed to ``include_push(...)``. It may be stored
   in an memento in order to be able to close it as soon as the included
   file is analyzed.

This is explained in an example: For some purpose the user wants to 
count the number of whitespace characters and the occurencies of the 
word 'bug' in each of the analyzed files. For this purpose he adds
some members to the analyzer class:

.. code-block:: cpp

   body {
        /* Code to be added to the class' body */
        size_t     whitespace_count;
        size_t     bug_count;
   }
   ...
   init {
       /* Code to be added to the constructor */
       whitespace_count = 0;
       bug_count        = 0;
   }
   ...
   mode A : {
        ...
        [ \t\n]+  { self.whitespace_count += strlen(Lexeme); }
        bug|Bug   { self.bug_count        += 1;              }
        ...
   }
    
Since these variables are file specific, they need to be stored away on file
inclusion. The ``memento``-section allows extend the memento class.  The class
needs to contain variables that can store the saved information from the
analyzer:

.. code-block:: cpp

   memento { 
       size_t  __whitespace_count;
       size_t  __bug_count;
   }

The content of the ``memento_pack``-section extends the actions to be taken when a lexical
analyzer is packed into a memento. We use the section to store away the variables for
whitespace and bug counting:

.. code-block:: cpp

   memento_pack {
       memento->__whitespace_count = self.whitespace_count;
       memento->__bug_count        = self.bug_count;
       /* initialize variables */
       self.whitespace_count = 0;
       self.bug_count        = 0;
   }

Note, that the variable ``memento`` provides access to the memento object. With
the ``memento_unpack``-section the actions of unpacking may be extended. Before
the new file is being analyzed the member variables need to be re-initialized.
When the file analyzis is terminated we need to ensure that the saved variables
are restored:

.. code-block:: cpp

   memento_unpack {
        self.whitespace_count = memento->__whitespace_count;
        self.bug_count        = memento->__bug_count;
   }

This is all that needs to be specified for including other files. The directory
``demo/005`` contains an example handling include stacks.  Providing a language
with such the 'include' feature is a key to propper code organization. By means
of the above mechanisms quex tries to facilitate this task as much as possible.
There is, however, a pitfall that needs to be considered. This will be the 
subject of the following section.


Closing Included Files
----------------------

For a file to be closed its handle must be available. Since streams and files
are handled uniformly inside the quex handling there is a problem: not every
stream provides a 'close' function. Further, it might not always be desired to
close the stream as soon as a file inclusion is terminated.  Ownership lucidity
enforces that the one who opens a file must be the one who closes it. Here is
what might be the most consistent approach.

First, the memento must contain a member to carry a file handle

.. code-block::cpp

   memento {
       ...
       FILE*   included_file_handle;
       ...
   }


Then, the ``memento_pack`` and ``memento_unpack`` sections come into play.  The
implicit argument ``InputH`` can be used to store the file handle in the
``memento_pack`` section. On return the file handle can then be closed, i.e.

.. code-block::cpp

    memento_pack {
        ...
        memento->included_file_handle = InputH;
    }

    memento_unpack {
        ...
        fclose(memento->included_file_handle);
    }

Note, that the root file of analyzis must still be closed. If the first
file was opened with a filename, the lexical analyzer knows that it's 
his responsibility to close it and does so at destruction time. If a
stream handle was passed to the constructor, then it's considered the
user's responsibility to close the stream.


Infinite Recursion Protection
-----------------------------

When a file is included, this happens from the beginning of the file. But, what
happens if a file includes itself? The answer is that the lexical analyzer
keeps including this file over and over again, i.e. in hangs in an *infinite
recursion*. If there is no terminating condition specified by the implementer,
then at some point in time the system on which it executes runs out of
resources and terminates after its fancy.

The case that a file includes itself is easily detectable. But the same 
mentioned scenario evolves if some file in the include chain is included 
twice, e.g. file A includes B which includes C which includes D which includes E
which includes F which includes G which includes C. In this case the analyzer
would loop over the files C, D, E, F, G over and over again.

Quex does not make any assumptions about what is actually included. It may be a
file in the file system accessed by a ``FILE`` pointer or ``ifstream`` object,
or it may be a stream coming from a specific port. Nevertheless, the
solution to the above problem is fairly simple: Detect whether the current
thing to be included is in the chain that includes it. This can be done by
iteration over the memento chain. The member ``stream_id`` in figure
:ref:`fig-memento-queue` is a placeholder for something that identifies an
input stream. For example let it be a filename. Then, the memento class
extension must contain its definition

.. code-block:: cpp

   memento {
       ...
       std::string   file_name; // ... is more intuitive than 'stream_id'
       ...
   }

The lexical analyzer needs to contain the filename of the root
file, thus the analyzer's class body must be extended.

.. code-block:: cpp

    body {
        ...
        std::string   file_name;
        ...
    }

Then, at each inclusion it must be iterated over all including files, i.e.
the preceeding mementos. The first memento, i.e. the root file has a
parent pointer of ``0x0`` which provides the loop termination condition.

.. code-block:: cpp

    ...
    MyLexer  my_lexer("example.txt");
    my_lexer.file_name = "example.txt";
    ...
    const std::string   Filename = Token.text();
    /* Detect infinite recursion */
    for(MyLexerMemento* iterator = my_analyzer._memento_parent;
        iterator != 0x0;
        iterator = iterator->parent ) {
        /* Check wether the current file name already appears in the chain */
        if( Filename == iterator->file_name ) {
            REACTION_ON_INFINITE_RECURSION(Filename);
        }
    }
    /* Open the file and include */
    FILE*  fh = open(Filename.c_str(), "rb");
    if( fh == NULL ) REACTION_ON_FILE_NOT_FOUNT(Filename);
    my_analyzer.include_push(fh);
    /* Set the file name **after** the include_push() ! */
    my_analyzer.file_name = Filename;
    ...

Once, the check is done, the file can be included as usual. But the 
``memento_pack`` must be extended.

.. code-block:: cpp

   memento_pack {
       ...
       memento->file_name = self.file_name;
       ...
   }

   memento_unpack {
       ...
       self.file_name = memento->file_name;
       ...
   }

.. rubric:: Footnotes

.. [#f1] There are also variables that describe structure and which are not
         concerned with the current file being analyzed. For example the 
         set of lexer modes does not change from file to file. Thus, it makes
         sense to pack relevant state data into some smaller object. 


.. [#f2] The name memento shall pinpoint that what is implemented
         here is the so called 'Memento Pattern'. See also 
         <<cite: DesignPatterns>>.
