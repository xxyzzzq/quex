\documentclass[12pt,a4paper]{scrartcl}

\usepackage{amsmath, amsthm, amssymb}
\usepackage{mathtools}  
\usepackage{graphicx}   % need for figures
\usepackage{verbatim}   % useful for program listings
\usepackage{color}      % use if color is used in text
\usepackage{subfigure}  % use for side-by-side figures
\usepackage{hyperref}   % use for hypertext links, including those to external documents and R_{uni}Ls

% don't need the following. simply use defaults
\setlength{\baselineskip}{16.0pt}    % 16 pt usual spacing between lines

\setlength{\parskip}{3pt plus 2pt}
\setlength{\parindent}{20pt}
\setlength{\oddsidemargin}{0.5cm}
\setlength{\evensidemargin}{0.5cm}
\setlength{\marginparsep}{0.75cm}
\setlength{\marginparwidth}{2.5cm}
\setlength{\marginparpush}{1.0cm}
\setlength{\textwidth}{150mm}

\newtheorem{definition}{Definition}
\newtheorem{statement}{Statement}
\newtheorem{condition}{Condition}

\begin{comment}
\pagestyle{empty} % use if page numbers not wanted
\end{comment}

% above is the preamble

\begin{document}

\begin{center}
{\large State Machine Optimization by Recipes} \\ 
\copyright 2015 by Frank-Rene Schaefer         \\
January, 2015
\end{center}

%==============================================================================
%
%==============================================================================
\section{Abstract}

This document describes a procedure to transform a state machine. The original
state machine develops values along transitions from state to state. The
resulting state machine develops the same values solely through operations at
the exit of the state machine or at states which require run-time storage of
values. From an outside view, i.e. at entry and exit, both state machines
behave identical. However, the internal structure of the resulting state
machine requires less operations and is therefore more time and space efficient
than the original state machine.  The analysis exploits deterministic behavior
of operations along state transitions. 

\section{The Setup}

Figure 1 shows a very simple state machine consisting of four states.  The
dotted lines indicate 'drop-out', i.e. a path that is taken to exit the state
machine.  In the original state machine, as shown in figure 1.a, the content of
$x$ is increment upon each transition. When the state machine is left in state
3, for example, three such increments must have taken place. In figure 1.b an
optimized representation of the state machine is shown.  There, value of $x$ is
only determined upon exit.  No increments happen during transitions. Only upon
exit $x$ is assigned the predetermined value. The balance on computational
effort is obvious.

\begin{figure}[htbp] \leavevmode
a)
\begin{verbatim}
                     x=x+1        x=x+1        x=x+1
              ( 0 )------->( 1 )------->( 2 )------->( 3 )
                : exit       : exit       : exit       : exit
                :            :            :            :
\end{verbatim}
    
b)
\begin{verbatim}
              ( 0 )------->( 1 )------->( 2 )------->( 3 )
                : exit       : exit       : exit       : exit
                :            :            :            :
               x=0          x=1          x=2          x=3
    
\end{verbatim}
\caption{Original and optimized state machine.}
\end{figure}
                 
The original state machine must be composed of 'single-entry states'. That is,
upon entry into a state the same operations are executed independently from
which the state it is entered or through which transition.  A single-entry
state is shown in figure 2.a. The optimization transforms the single-entry
state machine into a 'multi-entry state machine'.  That is, the operations
applied upon entry into a state may differ dependent on the transition through
which the state is entered. A multi-entry state in shown in figure 2.b.

\begin{figure}[htbp] \leavevmode
a)

\begin{verbatim}
     
                  ---------.
                            \                       .-----.
                  -----------+---[ operations ]----( state )----->   
                            /                       '-----'
                  ---------'       
\end{verbatim}
     
b)
     
\begin{verbatim}
                  ---[ operations 0 ]----.
                                          \         .-----.
                  ---[ operations 1 ]------+-------( state )----->  
                                          /         '-----'
                  ---[ operations 2 ]----'       

\end{verbatim}
\caption{Two approaches of state modelling: a) Single entry state. 
b) Multi-entry state.}
\end{figure}


This is done by compensating them through a single operation or by
postponing them to a state as late as possible.  Operations are preferably
postponed, because earlier states are passed more often than later states.

%==============================================================================
%
%==============================================================================
\section{Basic Terminology}

Along the transitions of a state machine many different operations may occur
which do not necessarily share the same subject. Some operations determine the
last accepted pattern, the input position to be restored upon acceptance, the
line and column numbers, the checksum value of a lexeme, or the sum of grapheme
widths of the lexeme's characters, and so on. The term 'investigated behavior'
is defined to specify a focus of analysis.  Let the sets of variables which are
associated with an investigated behavior be called $V_c$.

Let \textit{init state} denote the state where the state machine is entered.
Let $Pred(i)$ and $Succ(i)$ indicate the set of immediate predecessor and
successor states of state $i$. Let $Pred^*(i)$ indicate all states that lie on
a path from the init state to state $i$ \textit{together with} state $i$
itself. Let $Succ^*(i)$ indicate all states that are reachable from state $i$
\textit{together with} the state $i$ itself.

\begin{definition}
$V_c$ -- Description of Concerned Variables

The $V_c$ of an investigated behavior describes the set of variables which
are of concern. 
\end{definition}

A $V_c$ may be any type of formal description such as 'all variables related to
input position storage' where the number of variables is open.  As a
consequence of transitions, a state machine changes the content of variables.
However, not all variables of the $V_c$ are necessarily relevant for all
states. Let the set of required variables be defined as

\begin{definition}
$V(i)$ -- Set of Required Variables

$V(i)$ defines the variables which are required in state $i$. The
variables must be sufficient
\begin{itemize}
\item to implement the nominal behavior upon drop-out and
\item to develop the required variables $V(k)\,\forall\,k\,\in\,Succ^*(i)$. 
\end{itemize}
\end{definition}

In contrast to $V_c$, the set of variables in $V(i)$ must be concrete.
Instead of the loose statement 'all variables related to input position
storage', the specific variables with name and/or index must be specified. 

The configuration of $V(i)$ can be determined by \textit{back-propagation} of
needs. A state which requires a specific variable tags all of its predecessor
states with this requirement. That is, for a variable named $x$, it holds

\begin{equation}
    x\,\in\,V(i)\,\Rightarrow\,\forall\,k\,\in\,\Pred^*(i):\,x\,\in\,V(k)
\end{equation}

Assume for example, that the lexeme length is not required in a terminal. Then
any operation contributing to the computation of the lexeme length is
redundant.  No state on a path to this terminal is required to perform lexeme
length related operations, except that another successor state requires it.  An
elementary unit that modifies the content of a variables is called an
'operation', as defined here:

\begin{definition}
$op(i)$ -- Operation 

An operation $op(i)$ signifies all modification to $V(i)$ upon entry into a
state $i$ in the original single-entry state machine.

An operation $op^v(i)$ signifies the component of $op(i)$ which produces 
the variable $v\,\in\,V(i)$.
\end{definition}
    
With $V(h)$ as the setting before entry into a state $i$ and $V(i)$ as the
setting in state $i$ the operation $op(i)$ describes the modification by 

\begin{equation}
\label{eq:operation}
                         V(i) = op(i)(V(h))
\end{equation}

With the aforementioned definitions, the investigated behavior can be defined
precisely.

\begin{definition}
Investigated Behavior 

The investigated behavior determines the scope of analysis. It is
specified by a description of concerned variables $V_c$, the required
variables $V(i)$ for each state $i$, the related operations $op(i)$ and
their nominal behavior.
\end{definition}
    
A nominal behavior defines what needs to happen during the state machine
transitions.  For example, the nominal behavior for line number counting is
that the line number variable should be increased upon newline and remain the
same upon the occurrence of any other character. 

%==============================================================================
%
%==============================================================================
\section{Linear States and Mouth States}

Two central concepts are required for the further discussion: 'linear states' and 'mouth
states'.  They are defined in the paragraphs to follow. 

\begin{definition}
Linear State

A state $i$ is a linear state, if the number of immediate predecessor states is
1, i.e. 

\begin{equation}
                           size(Pred(i))\,=\,1
\end{equation}

The number of immediate successor states is arbitrary, i.e.
$size(Succ(i))\,\ge\,0$.

\end{definition}

The concept of a linear state is shown in figure 3. The operation $op(i)$ takes
the variable settings $V(k)$ of the previous state $k$ and derives $V(i)$, i.e.
the setting of variables in the current state. This can be expressed as 

\begin{equation} \label{eq:accumulation}
            V(i) = op(i)(V(k))                                         
\end{equation}

with $k$ as the one and only predecessor state. If $V(k)$ is determined, then
$V(i)$ is determined purely from the consideration of the state machine. Such a
deterministic mapping is not possible for so called 'mouth states'.

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                                                      .---> 
                                                     /
                                                   .-.
                      --------[ op(i) ]---------->( i )---> 
                         V(k)              V(i)    '-'

\end{verbatim}
\caption{The concept of a linear state.}
\end{figure}

\begin{definition}
Mouth State

A mouth state is a state that is entered from more than one predecessor 
state, i.e.
\begin{equation}
                           size(Pred(i))\,>\,1
\end{equation}
The number of immediate successor states is arbitrary, i.e. $size(Succ(i))\,\ge\,0$.

\end{definition}
    
\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                  ------>--.  
                 V(a)       \ 
                             \                       .-.
                  ------>-----+---[ op(i) ]---------( i )---> 
                 V(b)        /                 V(i)  '-'
                            /
                  ------>--'
                 V(c)

\end{verbatim}
\caption{The concept of a mouth state.}
\end{figure}

Figure 4 displays the concept of a mouth state and the development of the
$V(i)$ based on the $V(a),\,V(b)$ and $V(c)$, of the predecessor states. In
a mouth state $V(i)$ depends on the path taken at run-time of the state machine.
$V(i)$ is determined as follows.

\begin{equation} \label{eq:interference}
    V(i) = \begin{dcases*}
            op(i)(V(k_0)) & if entry from state $k_0$ \\
            op(i)(V(k_1)) & if entry from state $k_1$ \\
            \ldots \\
            op(i)(V(k_n)) & if entry from state $k_n$ \\
            \end{dcases*}
\end{equation}

The only way to handle this is in general is to compute the value of each $v\,\in\,V(i)$,
store it in an auxiliary variable, and let the output recipe restore what
has been stored.

\begin{definition}
$A$, $A(v)$ -- Auxiliary Variables

The term auxiliary variable $A(v)$ specifies a variable that may store the
a 'snapshot' of a variable $v$-s content upon entry into a mouth state. 
   
Let $A$ name the set of all auxiliary variables.
\end{definition}

Any operation that relies on auxliary variables has an implicit dependency
on the state where the variable has been stored. Let this information be
called a 'snapshot map'.

\begin{definition} $S_m(X)$, $S(X)$ -- Snapshot Map, Snapshot States.

    The snapshot map $S_m(X)$ related to an operation $X$ maps from all
    variables that are restored from auxiliary variables to the state index
    where the snapshot $A(v)=v$ has been taken.
    
    \begin{equation}
        \label{eq:snapshot-map}
        S_m(X):  v \rightarrow \mbox{state} i, \mbox{where} A(v) = v \mbox{was applied.}.
    \end{equation}

    The set of snapshot states $S(X)$ is the set of all states mentioned in
    $S_m(X)$.

\end{definition}

With the concept of linear states, mouth states, and auxiliary variables the
goal is now to find procedures that compute $V(i)$ while completely ridding
of the transition operations $op(i)$. Such procedures are called 'recipes'
and are defined as below.

\begin{definition}
    $R(i,k),\,R(i),\,R^v(i,k),\,R^v(i)$ -- Recipe 

Let $R(i,k)$ names the 'recipe' to determine $V(i)$ upon entry into a state
$i$ from a predecessor state $k$. It corresponds to the concatenation of
state $k$'s output recipe $R(k)$ and state $i$'s operation $op(i)$, that is

\begin{equation}
    R(i,k) \,=\, op(i)(R(k))
\end{equation}
A recipe, in general, performs the mapping
\begin{equation} \label{eq:recipe-procedure}
    (h, A) \rightarrow V(i)                                             
\end{equation}
That is, it solely depends on $h$, signifying the hidden variables of state machine,
and $A$, i.e. the set of auxiliary variables.  

Let $R(i)$ indicate the recipe which appears to the successor states of
state $i$.  Let $R^v(i,k)$ signify the component of $R(i,k)$ which produces
$v\,\in\,V(i)$.  Respectively, $R^v(i)$ is the component of $R(i)$ that
produces $v\,\in\,V(i)$.

\end{definition}

Hidden variables are all variables of the state machine other than the 'state'.
A lexical analyzer state machine has, for example the lexeme start position,
the buffer limits, the stream position, etc. as hidden variable. The state
in which an auxiliary variable takes a 'snapshot' is crucial when comparing
two recipes. Even if they provide the same procedure, if they rely on stored
values from different places, then they cannot be equal in general.

\begin{statement}
   If the snapshot maps of two recipes are unequal, then the two recipes
   are unequal, that is
   \begin{equation} \label{eq:snapshot-map-difference}
       S_m(R(i)) \neq S_m(R(i)) \Rightarrow R(i) \neq R(k)
   \end{equation}
   Since, the set of related states cannot be different without differring 
   snapshot maps, it follows without restricting generality
   \begin{equation} \label{eq:snapshot-map-difference2}
       S(R(i)) \neq S(R(i)) \Rightarrow R(i) \neq R(k)
   \end{equation}
\end{statement}

The fundamental difference between $R(i)$ and $V(i)$ is that the former
describes a procedure and the latter represents the values which are produced.
With the concepts of this section, the overall goal can be formulated. The
analysis transforms the given single-entry state machine based on operations
into a multi-entry state machine based on recipes. Observing only the entry and
exit, the changes to $V_c$ must comply to the nominal behavior. 

%==============================================================================
%
%==============================================================================
\section{Recipes}

A recipe for one state is the basis for the development of the recipe of its
successor state. For a linear state, equation \eqref{eq:operation} described
how $V(i)$ is determined from the predecessor's $V(k)$ and the entry operation
$op(i)$. If $V(k)$ can be determined by a recipe $R(k)$, then $V(i)$ becomes

\begin{equation} \label{eq:accumulation2}
                     V(i) = op(i)(R(k))                                     
\end{equation}

The recipe for $V(i)$ becomes nothing else than the expression that determines
it. That is,

\begin{equation} \label{eq:accumulation3}
                     R(i)\,=\,\{ op(i)(R(k)) \}                                 
\end{equation}
                 
The above definition tells that recipes can only come from recipes. An
important step towards the answer where the first recipe comes from is the
concept of a 'spring'. This is introduced as follows. 

The components $op^v(i)(R(k))$ may perform a special type of operation: they
may assign a \textit{constant} to $v$. If for all $v\in V(i)$ the operation
$op^v(i)(R(k))$ results in a constant \textit{independently} of the recipe
$R(k)$, then such a state may be considered the starting point of analysis. 

\begin{definition}
Spring

A spring is a state $i$ where all required variables $v\in V(i)$ can be
determined by $op^v(i)$ alone and ignoring the incoming recipe. That is,
\end{definition}

In equation \eqref{eq:accumulation3} it is demonstrated how a recipe $R(i)$ is
derived from a predecessor's recipe $R(k)$ and a state $i$-s operation $op(i)$.
This procedure is defined here as 'accumulation'.

\begin{definition}
Accumulation

Given a state $i$, its predecessor state $k$, the entry operation $op(i)$
the predecessor's recipe $R(k)$, the recipe $R(i,k)$ is equivalent
to the concatenated operations of $op(i)$ and $R(k)$.

The snapshot map of $S_m(R(i))$ is equal to the snapshot map of $R(k)$.

A prerequisite for accumulation is that $R(k)$ of the predecessor is 
determined.
\end{definition}

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                  op(b)=        op(c) =      op(d) =
                    x=x+1         x=x+1         x=x+1        
            ( a )-------->( b )-------->( c )-------->( d )--------> ...


\end{verbatim}
\caption{A sequence of linear states.}
\end{figure}

\subsection{Example}

Figure 6 displays an example with a single variable $x$. The operations $op(i)$
upon transition are $x=x+1$ for all states. That is $x$ is incremented by 1 at
each step. Let the $A(x,a)$ signify $A(x)$ as it was assigned upon entry into
state $a$. This notation combines the recipe's procedure with its snapshot map.
In the above example, the recipe in state $a$ solely restores what has been
stored.

\begin{equation}
\label{eq:}
               R(a) = { x := A(x,a) }                                     
\end{equation}

The recipe 'R(b,a)' must be equivalent to the concatenated execution of 'op(b)'
and 'R(a)', i.e.

\begin{eqnarray}
    { x  :=  A(x,a) } \\
    { x  :=  x + 1 }
\end{eqnarray}
So, 
\begin{eqnarray}
    R(b)  =  \{ x := A(x,a) + 1 \}                                 
\end{eqnarray}

This rule applied repeatedly for the states 'c' and 'd' leads to

\begin{eqnarray}
    R(c)  =  \{ x := A(x,a) + 2 \} \\
    R(d)  =  \{ x := A(x,a) + 3 \}                                 
\end{eqnarray}

If the state machine exits at $a$, $b$, $c$, or $d$ the content of $x$ can be
determined without relying on the intermediate operations $\{ x:=x+1 \}$. This
is shown in figure 7.
 
\begin{figure}[htbp] \leavevmode
\begin{verbatim}
          ( a )-------->( b )-------->( c )-------->( d )--------> ...
                          :             :             :
                        x=A(x,a)+1    x=A(x,a)+2    x=A(x,a)+3


\end{verbatim}
\caption{Recipes upon exit replace transition operations.}
\end{figure}

The repeated accumulation of recipes along linear states comes to an end at
mouth states.  Equation \eqref{eq:interference} described the development of
$V(i)$ in mouth state. Using the concept of a recipe, the equation can be
rewritten as

\begin{eqnarray}
    V(i)  =  \begin{dcases*}
               R(i,k_0) &  if entry from state $k_0$ \\
               R(i,k_1) &  if entry from state $k_1$ \\
               \dots                                 \\
               R(i,k_n) &  if entry from state $k_n$
            \end{dcases*}
\end{eqnarray}

The applied recipe depends on the origin state of the transition which is only
determined at run-time.  For each variable $v$ in $V(i)$ there are two
possibilities:

\begin{description}
    \item[Homogeneity] All entry recipes apply the exact same process to
                       determine the variable's content. That is

    \begin{equation}
        \begin{aligned}
        \mbox{The computation of}\,v\,\mbox{is \textit{homogeneous} at entry to state $i$}\\
        \Leftrightarrow\,\forall\,q,\,e\,\in\,Pred(i):\,R^v(i,p)\,=\,R^v(i,q) 
        \end{aligned}
    \end{equation}

    \item[Inhomogeneity] Two or more entry recipes apply a different process
                         to determine the variable's content. That is
    \begin{equation}
        \begin{aligned}
        \mbox{The computation of}\,v\,\mbox{is \textit{inhomogeneous} at entry to state $i$}\\
        \Leftrightarrow\,\exists\,p,\,q\,\in\,Pred(i):\,R^v(i,p)\,\neq\,R^v(i,q)
        \end{aligned}
    \end{equation}
\end{description}

As mentioned in equation \label{eq:snapshot-map-difference}, two recipes are
different if their snapshot maps differ. In other words, two recipe procedures
may rely in the same way on a stored value $A(v)$, but if it has been stored
stored in different states, they are still not the same.

If a variable $v$ is determined homogeneously, then the part of the recipes
that determines it can be overtaken into $R(i)$. Otherwise, the value must be
computed upon entry and stored in an $A(v)$. The recipe $R(i)$ must then rely
on $A(v)$. Let this process be defined as 'interference'.

\begin{definition}
Interference

The process of 'interference' develops a recipe $R(i)$ for a mouth state
$i$ based on entry recipes 

\begin{equation}
    R_E(i) = { op(i)(R(k)): k = 1...N }. 
\end{equation}
              
Let the entry recipe $R(i,k)$ signify the concatenation of $op(i)(R(k))$
where $R(k)$ is the output recipe of predecessor state $k$. The output
recipe $R(i)$ depends on the determinacy of $v$, i.e. 
          
\begin{equation}
    R^v(i) = \begin{dcases*}
              R^v(i,p) & $R^v(i,p)$ is homogeneous \\
              A(v)     & else
             \end{dcases*}
\end{equation}

where $Pred(i)$ is the set of predecessor states of $i$. For each $v$ where
$A(v)$ is used an entry operation $eop(i,k)$ is required that stores the current
value of $v$ in $A(v)$, i.e.

\begin{equation}
    eop(i,k) = { \forall\,k\,\mbox{with}\,R^v(i,k)\,\mbox{is inhomogeneous}: A(v)\,=\,R^v(i,k) }
\end{equation}

\end{definition}

In the case of inhomogeneous entry recipes $A(v)$ requires that entry
operations are performed.  That is upon entry from each $k$ into $i$ the
computed value of $v$ is stored in $A(v)$.  It is the existence of the entry
operations $eop(i,k)$ that induces the necessity of multi-entry states.  

Before interference can be performed, all entry recipes must be determined.  As
long as this is not the case, $R(i)$ cannot be determined. In consequence, no
successor state's recipe can be determined through accumulation. In other
words,  a mouth state blocks any propagation of recipes as long as not all
entry recipes are determined. 

The next section treats the recursive propagation of recipes by accumulation.
It is conceivable, however, that at the begin of analysis all mouth states are
undetermined. Even the initial state may be an undetermined mouth state--so
there are no springs. In that case, the analysis directly starts with a so
called 'dead-lock analysis'. This is the subject of the next section but one.

%==============================================================================
%
%==============================================================================
\section{Propagation By Recursive Accumulation}

The recipes for states are determined by a 'walk' along linear states. While
linear states have only one entry, they may have transitions to more than one
state. So, the walk along linear states is a recursive 'tree-walk'. If the
entry to a linear state $i$ is determined, then by accumulation, the output
recipe $R(i)$ can be determined. This recipe may then be applied to all
immediate successor states $Succ(i)$. Each of those produces its recipe by
accumulation, and so on. The termination criteria for the walk along linear
states is defined as follows.

\begin{definition}
Termination criteria for walk along linear states.

A recursive walk along linear states does not enter the state ahead, if 

\begin{itemize}
    \item there is no state ahead (i.e. the current state is a terminal).
    \item the state ahead is a mouth state.
    \item the state ahead is a spring.
\end{itemize}
\end{definition}

The first condition comes natural. The second condition exists, because recipes
cannot be accumulated beyond mouth states. As a direct consequence, the walk
can never go along loops, since a loop requires a state with more than one
entry. The third condition tells that the walk stops where another walk begins
or began.  With the ideas of a spring, linear states, accumulation and the
given termination criteria, an algorithm for the determination of recipes can
be defined.

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
          (*) Start.
          (1) springs = initial springs of state machine.
   .----->(2) recursive accumulation along linear states starting from springs.
   |          --> determine R(i) along linear states until terminal,
   |              mouth, or springs.
   |          --> entries of mouth states receive entry recipes.
   |      (3) interference in mouth states with complete sets of entry
   |          recipes.
   |      (4) springs = determined mouth states
   '- no -(5) springs empty?
          (*) Stop.
\end{verbatim}

\caption{Determination of recipes.}
\end{figure}

When this algorithm comes to an end, there might be still mouth states with
undetermined entries.  To this point in time, all behavior of the state machine
was investigated off-line. The following section discusses a solution for the
remaining states where the deterministic propagation of recipes could not
provide a solution.

%==============================================================================
%
%==============================================================================
\section{Dead-Lock States}

Interference can only be performed, if all entry recipes of a mouth state are
determined. Loops in the state machine graph, however, may cause
\textit{circular dependencies} and undetermined undetermined mouth states.
Figure 8 shows an example, where the two states 1 and 2 mutually block each
other. The recipe $R(1)$ for state 1 cannot be determined because it requires
$R(2)$ which is undetermined. However, before $R(2)$ from state 2 can be
determined, $R(1)$ must be present. None of the states 1 and 2 is suitable for
interference, because they are missing an entry recipe.  Circular dependencies
as an origin of dead-lock states are intuitive. The precise proof is provided
in the subsequent paragraphs. What follows describes a procedure to determine
the behavior of those dead-lock states and their dependent states.

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                                       R(1)
                          R(0)     .---->----.
                    ( 0 )------>( 1 )       ( 2 )
                                   '----<----'
                                       R(2)

\end{verbatim}
\caption{A dead-lock in mouth states 1 and 2.}
\end{figure}

\begin{definition} $U$ -- The Set of Dead-Lock States

A dead-lock state $i\,\in\,U$ is a mouth state that, after algorithm 1 has
ended, is still undetermined. It has at least one undetermined entry which
prevents it from performing interference. $U$ is the set of all dead-lock
states.

\end{definition}

Linear states do not contribute to the discussion of determinacy. A linear state's
output recipe is determined through accumulation if and only if its predecessor
is determined. On the other hand, if the predecessor is undetermined, then the 
state itself cannot be determined. Indeterminacy originates from interference 
that cannot be performed in mouth states. Thus, the strings of linear states
in between the mouth states can be omitted from consideration of determinacy.

An undetermined mouth state $i \in U$ must have at least one undetermined entry
recipe. Either the state from which it is entered is an undetermined mouth state, 
or the string of linear states backwards guides to an undetermined mouth state. 
Let the fact that a mouth state $i_0$ is undetermined because of another
undetermined mouth state $i_1$ be noted as $i_0 \vartriangleleft i_1$. Their might
be more than one dependency, but considering one is enough for this proof. Each
undetermined mouth state has at least one undetermined mouth state that feeds
an undetermined entry. Thus, the sequence 

\begin{equation}
    i_0\,\vartriangleleft\,i_1\,\vartriangleleft\,i_2\,\vartriangleleft\,\ldots
\end{equation}

has no end. But the set of undetermined states $U$ is finite. Thus, there must
be states appearing repeatedly in the sequence. Since the dependencies relate to
transition paths, this proves that loops must be involved. Also, it proves that
the reason for the existence of dead-lock states are circular dependencies of
undetermined mouth states.

\begin{definition}
Horizon

Let the term 'horizon' $H$ indicate the subset of dead-lock states $\{ i\,\in\,U \}$
that have at least one determined entry.
\end{definition}

The name 'horizon' is chosen because it defines the border of determination.
Beyond that begins the realm of dead-locks. Figure 9 shows a horizon state
which contains one determined entry and another undetermined entry.  The
process of propagation of recipes ended with dead-lock states. In order to
understand the nature of dead-lock states better, it makes sense to briefly
review this process. 

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                         R(a) -->--.
                                    \
                                     +---[ op(i) ]---( i )----> R(i)
                                    /
                     R(b) = ? -->--'

\end{verbatim}
\caption{A mouth state with a determined entry recipe $R(a)$ and 
an undetermined entry recipe $R(b)$.}
\end{figure}

The init state is the first state that is entered. It has at least one recipe
$R(outside)$, i.e. the recipe to be applied when coming from $outside$ the
state machine. If it has another entry that is undetermined, then the init
state becomes a horizon state. If the init state has no other entry, then it is
a spring and determined recipes are propagated through accumulation.
Accumulation ends with the determination of an entry into a mouth state. If the
reached mouth state ends up with determined entries, then a determined recipe
is propagated until a terminal or another mouth state is reached. If a mouth
state is reached where not all entries are determined, then its output recipe
is undetermined. Since by reaching it at least one entry is determined and,
thus,the state is a horizon state. The output recipe is undetermined and no
successor state is further reached with determined recipes. Consequently, all
successor states of that state are undetermined.  With the aforementioned
discussion, an important conclusion can be drawn.  Determined mouth states 
performed interference, and therefore must have all their entries determined. 
None of their entries can directly originate in a dead-lock mouth state.

\begin{statement} 
A dead-lock state can only reached by a path that guides through a horizon
state.  Paths from dead-lock states to non-dead-lock mouth states must contain
a spring.  
\end{statement}
   
In equation \eqref{eq:snapshot-map-difference2} it has been stated, that two
recipes are unequal if the set of variables in the snapshot maps differ.  This
will now be used to proof, that an entry from inside the dead-lock states can
never be homogeneous with determined entries.  The last statement allows to
conclude, already, that for a given determined entry into a horizon state no
state from behind the horizon has been reached, i.e.

\begin{equation}
    S(i) \cap Succ(i) \neq \emptyset
\end{equation}

If a state $k$ at the entry into a horizon state $i$ is undetermined, then
$k$ originates in a dead-lock state. into a horizon states originates in a dead-lock state. 
Thus, its If at another entry appears a recipe $R(k)$ with an $S(k)$ and 

\begin{equation}
              S(k) \cap Succ(i) \neq \emptyset
\end{equation}

then \(S(i) \neq S(k)\) and consequently \(R(i) \neq R(k)\). Thus, if an the entry of
the horizon state a recipe depends on entry operations in one of the successor
states of $i$, it is inhomogeneous with the already determined entry recipe
$R(i)$ and therefore translates into a 'store/restore' procedure. The output
recipe will rely on $A(v)$ with a snapshot map that associates $v$ with the
state $i$ itself. That is, even if the input to state $i$ depends on later
operations, the to compute $v$ upon entry, store it in $A(v)$ and restore it in
the output recipe is always correct. Now, even for an undetermined mouth state
$i$, a recipe $R(i)$ can be propagated.  A feed-back influence on the entry
states does not require an alteration of $R(i)$.

A further simplification is possible. If the entry operation $op(i)$ dominates
the setting of a variable $v$ by setting it to a constant.  It will also be the
same whatever the other entries contribute, since it is executed after any
entry recipe. Thus the entry recipes are then automatically homogeneous for
that $v$. In this particular case the $R^v(i)$' can be set to $op^v(i)$.  The
universally correct output recipe of a horizon state becomes 

\begin{equation}
    R_{uni}(i) = \begin{dcases*}
                 R^v(i) & $S_m(i,k))\,=\,\emptyset\,\forall\,k\,\in\,Pred(i)$ \\
                 A(v)   & $else$
                 \end{dcases*}
\end{equation}

In the case, that $A(v)$ is used a storing entry operation is required, that is
the snapshot map $S_m(i)$ maps $v$ to the state $i$. It follows the definition of
'run-time interference'.

\begin{definition}
Run-Time Dependent Interference

The process of 'run-time dependent interference' develops a recipe $R(i)$
for a mouth state $i$ in the presence of undetermined entry recipes. The
set of entry recipes becomes

\begin{equation}
    R_E(i) = \begin{dcases*}
            op(i)(R(k)) & $\forall\,k$ with $R(k)$ is determined \\
            R_{uni}(i)  & $\forall\,k$ with $R(k)$ is not determined
        \end{dcases*}
\end{equation}

Based on this specification of the entry recipes $R_E(i)$ the interference
procedure as defined before is performed. For any snapshot map entry
containing $i$, the value $v$ must be stored in $A(v)$.
\end{definition}

The resulting output recipe $R(i)$ can now be used for propagation. Through
repeated accumulation, previously undetermined mouth state entries become
determined. With a determined entry they become a new horizon state. Other
mouth state may get all their entries determined--thus they are no longer
horizon states. This way, the horizon moves forward until all mouth states are
determined. 

%==============================================================================
%
%==============================================================================
\section{Fine Tuning of Dead-Lock States}

Can there be a better recipe than the one developed by run-time dependent
interference? If so, it should be possible that after propagation of the
run-time dependent recipes, at the entries of the state new entry recipes
appear which are homogeneous with the determined entry. It is clearly
impossible for components $R^v(p)$ with $p \in Pred(i)$ that rely on
$A(v)$ since in that case the interfered recipe stores and restores, such that
the snapshot map for $v$ contains the horizon state $i$. The determined entry,
though can only contain sets of snapshot states that come before $i$. Thus,
there snapshot maps differ and can never produce a homogeneous output. They
always remain on storing and restoring from $A(v)$.

If the components $R^v(p)$ with $p \in Pred(i)$ are assignments of
constants, then a new homogeneous interference is possible. During run-time
interference the operation $op(i)$ was requested to be constant in order to
propagate into the output recipe. At this point, a more relaxed condition
requires $op(i)(R(p))$ needs to result in a constant assignment. Consider the
example of 

\begin{equation}
                       op(i) = \{ x = x + 1 \}
\end{equation}

The operation is clearly not dependent on the previous value of $x$--thus not
constant. However, if the predecessors recipe $R(p)$ assigns a constant $5$ to
$x$, then the concatenation becomes

\begin{equation}
                       op(i)(R(p)) = \{ x = 6 \}
\end{equation}

which does not depend on any auxiliary variable. If all entry recipes result in
the same constant assignment the recipe can be used as output recipe. Again,
propagation of this recipe by accumulation may improve other recipes. The process
of fine-tuning is notably the same as the normal propagation of recipes, with 
the exception of the termination criteria.

It has been shown, that from the correctness point of view, there is no need to
modify the output recipe of a mouth state. Thus, the result of interference
does not need to be assigned to the output recipe. The following condition 
on interference ensures that the fine-tuning does not continue forever.

\begin{condition}
Condition for interference during dead-lock fine-tuning.

The result of interference is only to be taken into account, if the size of the
new recipe's snapshot map is smaller than the size of the old recipe's snapshot
map.  
\end{condition}

A recipes component $R^v(i)$' that is constant cannot become dependent on
$A(v)$ because this happens only during inhomogeneous interference. Thus, the
set of variables in the new recipe's snapshot map is a subset of the variables
of the old recipe's snapshot map.

With the mentioned requirement a mouth state $i$ can be passed at maximum a
restricted $N$ number of times, where $N$ is the number of variables in
$V(i)$. Since, number of states is restricted in general, the total number of
propagations is restricted. At that point, no new constant entry recipes could
be determined. Thus the fine-tuning has reached its optimum.

\end{document}

