\documentclass[12pt,a4paper]{scrartcl}

\usepackage{amsmath, amsthm, amssymb}
\usepackage{mathtools}  
\usepackage{graphicx}   % need for figures
\usepackage{verbatim}   % useful for program listings
\usepackage{color}      % use if color is used in text
\usepackage{subfigure}  % use for side-by-side figures
\usepackage{hyperref}   % use for hypertext links, including those to external documents and R_{uni}Ls

% don't need the following. simply use defaults
\setlength{\baselineskip}{16.0pt}    % 16 pt usual spacing between lines

\setlength{\parskip}{3pt plus 2pt}
\setlength{\parindent}{20pt}
\setlength{\oddsidemargin}{0.5cm}
\setlength{\evensidemargin}{0.5cm}
\setlength{\marginparsep}{0.75cm}
\setlength{\marginparwidth}{2.5cm}
\setlength{\marginparpush}{1.0cm}
\setlength{\textwidth}{150mm}

\newtheorem{definition}{Definition}
\newtheorem{statement}{Statement}
\newtheorem{condition}{Condition}

\begin{comment}
\pagestyle{empty} % use if page numbers not wanted
\end{comment}

% above is the preamble

\begin{document}

\begin{center}
{\large State Machine Optimization by Recipes} \\ 
\copyright 2015 by Frank-Rene Schaefer         \\
January, 2015
\end{center}

%==============================================================================
%
%==============================================================================
\section{Abstract}

This document describes a procedure to transform a state machine. The original
state machine develops values along transitions from state to state. The
resulting state machine develops the same values solely through operations at
the exit of the state machine or at states which require run-time storage of
values. From an outside view, i.e. at entry and exit, both state machines
behave identical. However, the internal structure of the resulting state
machine requires less operations and is therefore more time and space efficient
than the original state machine.  The analysis exploits deterministic behavior
of operations along state transitions. 

\section{The Setup}

Figure 1 shows a very simple state machine consisting of four states.  The
dotted lines indicate 'drop-out', i.e. a path that is taken to exit the state
machine.  In the original state machine, as shown in figure 1.a, the content of
$x$ is increment upon each transition. When the state machine is left in state
3, for example, three such increments must have taken place. In figure 1.b an
optimized representation of the state machine is shown.  There, value of $x$ is
only determined upon exit.  No increments happen during transitions. Only upon
exit $x$ is assigned the predetermined value. The balance on computational
effort is obvious.

\begin{figure}[htbp] \leavevmode
a)
\begin{verbatim}
                     x=x+1        x=x+1        x=x+1
              ( 0 )------->( 1 )------->( 2 )------->( 3 )
                : exit       : exit       : exit       : exit
                :            :            :            :
\end{verbatim}
    
b)
\begin{verbatim}
              ( 0 )------->( 1 )------->( 2 )------->( 3 )
                : exit       : exit       : exit       : exit
                :            :            :            :
               x=0          x=1          x=2          x=3
    
\end{verbatim}
\caption{Original and optimized state machine.}
\end{figure}
                 
The original state machine must be composed of 'single-entry states'. That is,
upon entry into a state the same operations are executed independently from
which the state it is entered or through which transition.  A single-entry
state is shown in figure 2.a. The optimization transforms the single-entry
state machine into a 'multi-entry state machine'.  That is, the operations
applied upon entry into a state may differ dependent on the transition through
which the state is entered. A multi-entry state in shown in figure 2.b.

\begin{figure}[htbp] \leavevmode
a)

\begin{verbatim}
     
                  ---------.
                            \                       .-----.
                  -----------+---[ operations ]----( state )----->   
                            /                       '-----'
                  ---------'       
\end{verbatim}
     
b)
     
\begin{verbatim}
                  ---[ operations 0 ]----.
                                          \         .-----.
                  ---[ operations 1 ]------+-------( state )----->  
                                          /         '-----'
                  ---[ operations 2 ]----'       

\end{verbatim}
\caption{Two approaches of state modelling: a) Single entry state. 
b) Multi-entry state.}
\end{figure}


This is done by compensating them through a single operation or by
postponing them to a state as late as possible.  Operations are preferably
postponed, because earlier states are passed more often than later states.

%==============================================================================
%
%==============================================================================
\section{Basic Terminology}

Along the transitions of a state machine many different operations may occur
which do not necessarily share the same subject. Some operations determine the
last accepted pattern, the input position to be restored upon acceptance, the
line and column numbers, the checksum value of a lexeme, or the sum of grapheme
widths of the lexeme's characters, and so on. The term 'investigated behavior'
is defined to specify a focus of analysis.  Let the sets of variables which are
associated with an investigated behavior be called $V_c$.

Let \textit{init state} denote the state where the state machine is entered.
Let $Pred(i)$ and $Succ(i)$ indicate the set of immediate predecessor and
successor states of state $i$. Let $Pred^*(i)$ indicate all states that lie on
a path from the init state to state $i$ \textit{together with} state $i$
itself. Let $Succ^*(i)$ indicate all states that are reachable from state $i$
\textit{together with} the state $i$ itself.

\begin{definition}
$V_c$ -- Description of Concerned Variables

The $V_c$ of an investigated behavior describes the set of variables which
are of concern. 
\end{definition}

A $V_c$ may be any type of formal description such as 'all variables related to
input position storage' where the number of variables is open.  As a
consequence of transitions, a state machine changes the content of variables.
However, not all variables of the $V_c$ are necessarily relevant for all
states. Let the set of required variables be defined as

\begin{definition}
$V_r(i)$ -- Set of Required Variables

$V_r(i)$ defines the variables which are required in state $i$. The
variables must be sufficient

\begin{enumerate}
\item to implement the nominal behavior upon drop-out and
\item to develop the required variables $V_r(k)\,\forall\,k\,\in\,Succ^*(i)$. 
\end{enumerate}
\end{definition}

In contrast to $V_c$, the set of variables in $V_r(i)$ must be concrete.
Instead of the loose statement 'all variables related to input position
storage', the specific variables with name and/or index must be specified. 

$V_r(i)$ can be determined by \textit{back-propagation} of needs. A state which
requires a specific variable tags all of its predecessor states with this
requirement. That is, for a variable named $x$, it holds

\begin{equation}
    x\,\in\,V_r(i)\,\Rightarrow\,\forall\,k\,\in\,\Pred^*(i):\,x\,\in\,V_r(k)
\end{equation}

Assume for example, that the lexeme length is not required in a terminal. Then
any operation contributing to the computation of the lexeme length is
redundant.  No state on a path to this terminal is required to perform lexeme
length related operations, except that another successor state requires it.
Let setting of required variables be defined as follows.

\begin{definition}
$V(i)$ -- Setting of $V_r(i)$

The term $V(i)$ represents the settings of all required variables $V_r(i)$
after a state $i$ is entered and before it transits further. 
\end{definition}
    
An elementary unit that modifies the content of a variables is called an
'operation', as defined here:

\begin{definition}
$op(i)$ -- Operation 

An operation $op(i)$ signifies all modification to $V_r(i)$ upon entry into a
state $i$ in the original single-entry state machine.

An operation $op^v(i)$ signifies the component of $op(i)$ which produces 
the variable $v\,\in\,V_r(i)$.
\end{definition}
    
With $V(h)$ as the setting before entry into a state $i$ and $V(i)$ as the
setting in state $i$ the operation $op(i)$ describes the modification by 

\begin{equation}
\label{eq:operation}
                         V(i) = op(i)(V(h))
\end{equation}

With the aforementioned definitions, the investigated behavior can be defined
precisely.

\begin{definition}
Investigated Behavior 

The investigated behavior determines the scope of analysis. It is
specified by a description of concerned variables $V_c$, the required
variables $V_r(i)$ for each state $i$, the related operations $op(i)$ and
their nominal behavior.
\end{definition}
    
A nominal behavior defines what needs to happen during the state machine
transitions.  For example, the nominal behavior for line number counting is
that the line number variable should be increased upon newline and remain the
same upon the occurrence of any other character. 

%==============================================================================
%
%==============================================================================
\section{Linear States and Mouth States}

Two central concepts are required for the further discussion: 'linear states' and 'mouth
states'.  They are defined in the paragraphs to follow. 

\begin{definition}
Linear State

A linear state is a state that is entered only from one predecessor state.
\end{definition}

The concept of a linear state is shown in figure 3. The operation $op(i)$ works
on the $V(k)$ before entry and produces $V(i)$. Note, that a linear state may
have transitions to multiple successor states, but only on predecessor state.

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                                                      .---> 
                                                     /
                                                   .-.
                      --------[ op(i) ]---------->( i )---> 
                         V(k)              V(i)    '-'

\end{verbatim}
\caption{The concept of a linear state.}
\end{figure}

\begin{definition}
Mouth State

A mouth state is a state that is entered from more than one predecessor 
state. 
\end{definition}
    
Figure 4 displays the concept of a mouth state and the development of the
$V(i)$ based on the $V_c$s of predecessor states.

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                  ------>--.  
                 V(a)       \ 
                             \                       .-.
                  ------>-----+---[ op(i) ]---------( i )---> 
                 V(b)        /                 V(i)  '-'
                            /
                 ...       :
                  ------>--'
                 V(z)

\end{verbatim}
\caption{The concept of a mouth state.}
\end{figure}

In a linear state the $V(i)$ can be determined based on the predecessor's
$V_c$ and the $op(i)$

\begin{equation} \label{eq:accumulation}
            V(i) = op(i)(V(k))                                         
\end{equation}

with $k$ as the one and only predecessor state. If $V(k)$ is known, then
$V(i)$ of a linear state is known off-line purely from the consideration of
the state machine.  In a mouth state $V(i)$ is be determined depending on the
state from where the transition originates.

\begin{equation} \label{eq:interference}
    V(i) = \begin{dcases*}
            op(i)(V(a)) & if entry from state a \\
            op(i)(V(b)) & if entry from state b \\
            \ldots \\
            op(i)(V(n)) & if entry from state n \\
            \end{dcases*}
\end{equation}

Later procedures rely on stored reference copies of variables. Those values
are stored in so called 'auxiliary variables' as defined below.

\begin{definition}
$A$, $A(v)$ -- Auxiliary Variables

The term auxiliary variable $A(v)$ specifies a variable that may store the
a 'snapshot' of a variable $v$-s content upon entry into a mouth state. 
   
$A$ names the set of all auxiliary variables.
\end{definition}

Let 'recipe' be the procedure to determine the $V_c$ in a state without
considering any previous operation. That is, if for all states all recipes are
known, then all operations along the state machine transitions can be removed.
Let the term recipe be defined as follows.

\begin{definition}
    $R(i,k),\,R^v(i,k),\,R(i),\,R^v(i)$ -- Recipe 

Let $R(i,k)$ indicates the 'recipe' to determine $V(i)$ upon entry into a state
$i$ from a predecessor state $k$.  A recipe consists of two components: A
procedure to determine $V(i)$ and a snapshot map $S_m(i,k)$, respectively
$S_m(i)$.

The \textit{procedure} tells how to compute the variables of $V_r(i)$ which is derived
from the operation $op(i)$ and $R(k)$.  It maps

\begin{equation} \label{eq:recipe-procedure}
    (h(i), A) \Rightarrow V(i)                                             
\end{equation}

with $h(i)$ signifying the hidden variables of state machine and $A$ the set of
auxiliary variables.  The \textit{snapshot map} associates a variable with the state
index where a snapshot of its value has been stored in $A(v)$, i.e.

\begin{equation}
    \label{eq:snapshot-map}
    S_m(i,k):  v \rightarrow \mbox{state} i, \mbox{where} A(v) = v \mbox{was applied.}.
\end{equation}

Let $R(i)$ indicate the recipe which appears to the successor states of
state $i$. Let $S_m(i)$ name the according snapshot map.

Let $R^v(i,k)$ signify the component of $R(i,k)$ which produces
$v\,\in\,V_r(i)$.  Respectively, $R^v(i)$ is the component of $R(i)$ that
produces $v\,\in\,V_r(i)$.

\end{definition}

Hidden variables are all variables of the state machine other than the 'state'.
A lexical analyzer state machine has, for example the lexeme start position,
the buffer limits, the stream position, etc. as hidden variable. The state
in which an auxiliary variable takes a 'snapshot' is crucial when comparing
two recipes. Even if they provide the same procedure, if they rely on stored
values at different places, then they cannot be equal.

\begin{statement}
   If the snapshot maps of two recipes are unequal, then the two recipes
   are unequal, that is
   \begin{equation} \label{eq:snapshot-map-difference}
       S_m(i) \neq S_m(k) \Rightarrow R(i) \neq R(k)
   \end{equation}
\end{statement}

The fundamental difference between $R(i)$ and $V(i)$ is that the former describes
a procedure and the latter represents the values which are produced.

The simplest form of a recipe is the setting with constant values.  For
example, at a state entered by the newline character the recipe for 'column
number' may be 'column number = 0', because a new line begins. The advantage of
recipes is demonstrated figure 5.  In figure 5.a operations are executed at
each transition step. They assign identifiers to the last acceptance variable
'accept'. This assignment happens even if states '1' and '2' are passed by and
later states may detect another acceptance. Upon drop-out from state 1 or 2 a
conditional goto to a terminal is applied based on the setting of 'accept'. 

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
    a)        
            'accept=10'        'accept=12'        
       ... ------------>( 1 )-------------->( 2 )----> ...
                          :                   :
                    goto T(accept)      goto T(accept)

    b) 
       ... ------------>( 1 )-------------->( 2 )----> ...
                          : 'accept=10'       : 'accept=12'              
                          :                   :
                      goto T10            goto T12

\end{verbatim}
\caption{Equivalent state sequences. a) Relying on operations along
transitions. b) $V_c$s determined by recipes.}
\end{figure}


In figure 5.b the operations along transitions are completely removed. The
recipes determined the acceptance a priori, so that a direct goto to the
correspondent terminal can be applied.  Clearly, the second approach requires
no computational effort during transitions and lesser effort upon drop-out.

Let the set of predecessors $Pred(i)$ contain all states that lie on a path
from the init state to state $i$. Let the set of successor states $Succ(i)$
contain all states that can be reached from state $i$.

With the concepts of this section, the overall goal can be formulated. The
analysis transforms the given single-entry state machine based on operations
into a multi-entry state machine based on recipes. Observing only the entry and
exit, the changes to the $V_c$ must comply to the nominal behavior. 

%==============================================================================
%
%==============================================================================
\section{Basics on Propagation of Recipes}

A recipe for one state is the basis for the development of the recipe of its
successor state. For a linear state, equation (1) described how $V(i)$ is
determined from the predecessor's $V(k)$ and the entry operation $op(i)$. If
$V(k)$ can be determined by a recipe $R(k)$, then $V(i)$ becomes

\begin{equation} \label{eq:accumulation2}
                     V(i) = op(i)(R(k))                                     
\end{equation}

Since, a recipe $R(k)$ is already independent of operations along transitions,
the recipe for $V(i)$ becomes nothing else than the expression that
determines it. That is,

\begin{equation} \label{eq:accumulation3}
                     R(i) = { op(i)(R(k)) }                                 
\end{equation}
                 
The above definition tells that recipes can only come from recipes. An
important step towards the answer where the first recipe comes from is the
concept of a 'historyless recipe'. This is introduced as follows. 

The components $op^v(i)(R(k))$ of an operation that compute a variable $v$
can be of two types. First, they may assign a *constant* to $v$. Second, they may
produce a value based on *auxiliary variables* $A$ that have been stored earlier.
A dependency on stored values is expressed by an entry in the snapshot map.

\begin{definition}
S(i) -- Set of snapshot states.

The set of snapshot states $S(i)$ related to a recipe $R(i)$ contains
all state indices present in the recipes snapshot map.
\end{definition}

If a recipe $R(i)$ does not depend on stored values then the set of snapshot
states $S(i)$ is empty. In that case, the state that outputs the recipe can 
be considered a starting point of analysis.

\begin{definition}
Spring

A state $i$ where all required variables $V_r(i)$ can be determined by 
$op(i)$ alone and ignoring the incoming recipe. That is, 
\end{definition}

\begin{equation}
                          S(i) = \emptyset
\end{equation}

The relates snapshot map is empty, since it does not rely on any value stored
at run-time.  In other words, for a spring there is no $v$ determined by $A(v)$
as shown in equation 8.  In equation 5 it is demonstrated how a recipe $R(i)$
is derived from a predecessor's recipe $R(k)$ and a state $i$-s operation
$op(i)$. This procedure is defined here as 'accumulation'.

\begin{definition}
Accumulation

Given a state $i$, its predecessor state $k$, the entry operation $op(i)$
the predecessor's recipe $R(k)$, the recipe to $R(i,k)$ is equivalent
to the concatenated operations of $op(i)$ and $R(k)$.

The snapshot map of $R(i)$ is equal to the snapshot map of $R(k)$.

A prerequisite for accumulation is that $R(k)$ of the predecessor is 
determined.
\end{definition}

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                  op(b)=        op(c) =      op(d) =
                    x=x+1         x=x+1         x=x+1        
            ( a )-------->( b )-------->( c )-------->( d )--------> ...


\end{verbatim}
\caption{A sequence of linear states.}
\end{figure}

\subsection{Example}

Figure 6 displays an example of an $V_c$ containing a single variable $x$. The
operations $op(i)$ upon transition are $x=x+1$ for all states. That is $x$ is
incremented by 1 at each step. Let the $A(x,a)$ signify $A(x)$ as it was
assigned upon entry into state $a$. This notation combines the recipe's
procedure with its snapshot map. In the above example, the recipe in state $a$
solely restores what has been stored.

\begin{equation}
\label{eq:}
               R(a) = { x := A(x,a) }                                     (6)
\end{equation}


The recipe 'R(b,a)' must be equivalent to the concatenated execution of 'op(b)'
and 'R(a)', i.e.

\begin{eqnarray}
    { x  :=  A(x,a) } \\
    { x  :=  x + 1 }
\end{eqnarray}
So, 
\begin{eqnarray}
    R(b)  =  \{ x := A(x,a) + 1 \}                                 (7)
\end{eqnarray}

This rule applied repeatedly for the states 'c' and 'd' leads to

\begin{eqnarray}
    R(c)  =  \{ x := A(x,a) + 2 \} \\
    R(d)  =  \{ x := A(x,a) + 3 \}                                 (8)
\end{eqnarray}

If the state machine exits at $a$, $b$, $c$, or $d$ the content of $x$ can be
determined without relying on the intermediate operations $\{ x:=x+1 \}$. This
is shown in figure 7.
 
\begin{figure}[htbp] \leavevmode
\begin{verbatim}
          ( a )-------->( b )-------->( c )-------->( d )--------> ...
                          :             :             :
                        x=A(x,a)+1    x=A(x,a)+2    x=A(x,a)+3


\end{verbatim}
\caption{Recipes upon exit replace transition operations.}
\end{figure}

The repeated accumulation of recipes along linear states comes to an end at
mouth states.  Equation (2) described the development of $V_c$ in mouth
state. Using the concept of a recipe, the equation can be rewritten as

\begin{eqnarray}
    V(i)  =  \begin{dcases*}
               R(i,p) &  if entry from state $p$ \\
               R(i,q) &  if entry from state $q$ \\
               R(i,n) &  if entry from state $n$
            \end{dcases*}
\end{eqnarray}

The applied recipe depends on the origin state of the transition which is only
determined at run-time.  For each variable $v$ in $V_r(i)$ there are two
possibilities:

\begin{description}
    \item[Homogeneity] All entry recipes apply the exact same process to
                       determine the variable's content. That is

    \begin{equation}
        \begin{aligned}
        \mbox{The computation of}\,v\,\mbox{is \textit{homogeneous} at entry to state $i$}\\
        \Leftrightarrow\,\forall\,q,\,e\,\in\,Pred(i):\,R^v(i,p)\,=\,R^v(i,q) 
        \end{aligned}
    \end{equation}

    \item[Inhomogeneity] Two or more entry recipes apply a different process
                         to determine the variable's content. That is
    \begin{equation}
        \begin{aligned}
        \mbox{The computation of}\,v\,\mbox{is \textit{inhomogeneous} at entry to state $i$}\\
        \Leftrightarrow\,\exists\,p,\,q\,\in\,Pred(i):\,R^v(i,p)\,\neq\,R^v(i,q)
        \end{aligned}
    \end{equation}
\end{description}

Note that $R(i,p) \neq R(i,q)$ is true if the snapshot maps differ. In other
words, two recipe procedures may rely in the same way on a stored value $A(v)$,
but if it has been stored stored in different states, they are still not
the same.

If a variable $v$ is determined homogeneously, then the part of the recipes
that determines it can be overtaken into $R(i)$. Otherwise, the value must be
computed upon entry and stored in an $A(v)$. The recipe $R(i)$ must then rely
on $A(v)$. Let this process be defined as 'interference'.

\begin{definition}
Interference

The process of 'interference' develops a recipe $R(i)$ for a mouth state
$i$ based on entry recipes 

\begin{equation}
              ER = { op(i)(R(k)): k = 1...N }. 
\end{equation}
              
Let the entry recipe $R(i,k)$ signify the concatenation of $op(i)(R(k))$
where $R(k)$ is the output recipe of predecessor state $k$. The output
recipe $R(i)$ depends on the determinacy of $v$, i.e. 
          
\begin{equation}
    R^v(i) = \begin{dcases*}
              R^v(i,p) & $R^v(i,p)$ is homogeneous \\
              A(v)     & else
             \end{dcases*}
\end{equation}

where $Pred(i)$ is the set of predecessor states of $i$. For each $v$ where
$A(v)$ is used an entry operation $EO(i,k)$ is required that stores the current
value of $v$ in $A(v)$, i.e.

\begin{equation}
    EO(i,k) = { \forall\,k\,\mbox{with}\,R^v(i,k)\,\mbox{is inhomogeneous}: A(v)\,=\,R^v(i,k) }
\end{equation}

\end{definition}

In the case of inhomogeneous entry recipes $A(v)$ requires that entry
operations are performed.  That is upon entry from each $k$ into $i$ the
computed value of $v$ is stored in $A(v)$.  It is the existence of the entry
operations $EO(i,k)$ that induces the necessity of multi-entry states.  

Before interference can be performed, all entry recipes must be determined.  As
long as this is not the case, $R(i)$ cannot be determined. In consequence, no
successor state's recipe can be determined through accumulation. In other
words,  a mouth state blocks any propagation of recipes as long as not all
entry recipes are determined. 

The next section treats the recursive propagation of recipes by accumulation.
It is conceivable, however, that at the begin of analysis all mouth states are
undetermined. Even the initial state may be an undetermined mouth state--so
there are no springs. In that case, the analysis directly starts with a so
called 'dead-lock analysis'. This is the subject of the next section but one.

%==============================================================================
%
%==============================================================================
\section{Recipe Propagation By Accumulation}

The recipes for states are determined by a 'walk' along linear states. While
linear states have only one entry, they may have transitions to more than one
state. So, the walk along linear states is a recursive 'tree-walk'. The
termination criteria for the walk along linear states is defined as follows.

\begin{definition}
Termination criteria for walk along linear states.

A recursive walk along linear states does not enter the
state ahead, if 

\begin{itemize}
    \item there is no state ahead (i.e. the current state is a terminal).
    \item the state ahead is a mouth state.
    \item the state ahead is a spring.
\end{itemize}
\end{definition}

The first condition comes natural. The second condition exists, because recipes
cannot be accumulated beyond mouth states. As a direct consequence, the walk
can never go along loops, since a loop requires a state with more than one
entry. The third condition tells that the walk stops where another walk begins
or began.  With these concepts, a first draft of an algorithm for the
determination of recipes can be defined.

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
          (*) Start.
          (1) springs = initial springs of state machine.
   .----->(2) perform linear walks starting from each spring.
   |          --> determine R(i) along linear states until terminal,
   |              mouth, or springs.
   |          --> entries of mouth states receive entry recipes.
   |      (3) interference in mouth states with complete sets of entry
   |          recipes.
   |      (4) springs = determined mouth states
   '- no -(5) springs empty?
          (*) Stop.
\end{verbatim}

\caption{Determination of recipes.}
\end{figure}

When this algorithm comes to an end, there might be still mouth states with
undetermined entries.  To this point in time, all behavior of the state
machine was investigated off-line. The following section discusses a solution 
for the remaining states where the deterministic propagation of recipes failed.

%==============================================================================
%
%==============================================================================
\section{Dead-Lock States}

Interference can only be performed, if all entry recipes of a mouth state are
determined. Loops in the state machine graph, however, may cause \textit{circular
dependencies} and unresolved mouth states.  Figure 8 shows an example, where the
two states 1 and 2 mutually block each other. The recipe $R(1)$ for state 1
cannot be determined because it requires $R(2)$ which is undetermined. However,
before $R(2)$ from state 2 can be determined, $R(1)$ must be present. Both
states, 1 and 2, cannot perform an interference, because they are missing an
entry recipe.  Circular dependencies as a condition for dead-lock states are
intuitive. The precise proof is provided in the subsequent paragraphs. What
follows describes a procedure to determine the behavior of those dead-lock
states and their dependent states.

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                                       R(1)
                          R(0)     .---->----.
                    ( 0 )------>( 1 )       ( 2 )
                                   '----<----'
                                       R(2)

\end{verbatim}
\caption{A dead-lock in mouth states 1 and 2.}
\end{figure}

\begin{definition} $U$ -- The Set of Dead-Lock States

A dead-lock state $i\,\in\,U$ is a mouth state that, after algorithm 1 has
ended. It has at least one undetermined entry which prevents it from performing
interference. $U$ is the set of all dead-lock states.

\end{definition}

Linear states do not contribute to the discussion of determinacy. A linear state's
output recipe is determined through accumulation if and only if its predecessor
is determined. On the other hand, if the predecessor is undetermined, then the 
state itself cannot be determined. Indeterminacy originates from interference 
that cannot be performed in mouth states. Thus, the strings of linear states
in between the mouth states can be omitted from consideration of determinacy.

An undetermined mouth state $i \in U$ must have at least one undetermined entry
recipe. Either the state from which it is entered is an undetermined mouth state, 
or the string of linear states backwards guides to an undetermined mouth state. 
Let the fact that a mouth state $i_0$ is undetermined because of another
undetermined mouth state $i_1$ be noted as $i_0 \vartriangleleft i_1$. Their might
be more than one dependency, but considering one is enough for this proof. Each
undetermined mouth state has at least one undetermined mouth state that feeds
an undetermined entry. Thus, the sequence 

\begin{equation}
    i_0\,\vartriangleleft\,i_1\,\vartriangleleft\,i_2\,\vartriangleleft\,\ldots
\end{equation}

has no end. But the set of undetermined states $U$ is finite. Thus, there must
be states appearing repeatedly in the sequence. Since the dependency relate to
transition paths, this proves that loops must be involved. Also, it proves that
the reason for the existence of dead-lock states are circular dependencies of
undetermined mouth states.

\begin{definition}
Horizon

Let the term 'horizon' $H$ indicate the subset of dead-lock states $\{ i\,\in\,U \}$
that have at least one determined entry.
\end{definition}

The name 'horizon' is chosen because it defines the border of determination.
Beyond that begins the realm of dead-locks. Figure 9 shows a horizon state
which contains one determined entry and another undetermined entry.

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                         R(a) -->--.
                                    \
                                     +---[ op(i) ]---( i )----> R(i)
                                    /
                     R(b) = ? -->--'

\end{verbatim}
\caption{A mouth state with a determined entry recipe $R(a)$ and 
an undetermined entry recipe $R(b)$.}
\end{figure}

The process of propagation of recipes ended with dead-lock states. In order
to understand the nature of dead-lock states better, it makes sense to briefly
review this process. 

The init state is the first state that is entered. It has at least one recipe
$R(outside)$, i.e. the recipe to be applied when coming from $outside$ the
state machine. If it has another entry that is undetermined, then the init
state becomes a horizon state. If the init state has no other entry, then it is
a spring and determined recipes are propagated through accumulation.
Accumulation ends with the determination of an entry into a mouth state. If the
reached mouth state ends up with determined entries, then a determined recipe
is propagated until a terminal or another mouth state is reached. If a mouth
state is reached where not all entries are determined, then its output recipe
is undetermined. Since by reaching it at least one entry is determined and,
thus,the state is a horizon state. The output recipe is undetermined and no
successor state is further reached with determined recipes. Consequently, all
successor states of that state are undetermined.  With the aforementioned
discussion, an important conclusion can be drawn.  Determined mouth states 
performed interference, and therefore must have all their entries determined. 
None of their entries can directly originate in a dead-lock mouth state.

\begin{statement}
A dead-lock state can only reached by a path that guides through a horizon
state. 

Paths from dead-lock states to non-dead-lock mouth states must contain a
spring.
\end{statement}
   
It has been mentioned, that two recipes are unequal if their snapshot map
differs.  Further, if their sets of snap shot states differ, then the snapshot
maps can never be the same. It follows that

\begin{equation}
    S(i) \neq S(k) \implies R(i) \neq R(k)
\end{equation}

The last statement allows to conclude, that for a given determined entry into a
horizon state no state from inside the dead-lock realm has been reached, i.e.

\begin{equation}
    S(i) \cap Succ(i) \neq \emptyset
\end{equation}

If at another entry appears a recipe $R(k)$ with an $S(k)$ and 

\begin{equation}
              S(k) \cap Succ(i) \neq \emptyset
\end{equation}

then \(S(i) \neq S(k)\) and consequently \(R(i) \neq R(k)\). Thus, if an the entry of
the horizon state a recipe depends on entry operations in one of the successor
states of $i$, it is inhomogeneous with the already determined entry recipe
$R(i)$ and therefore translates into a 'store/restore' procedure. The output
recipe will rely on $A(v)$ with a snapshot map that associates $v$ with the
state $i$ itself. That is, even if the input to state $i$ depends on later
operations, the to compute $v$ upon entry, store it in $A(v)$ and restore it in
the output recipe is always correct. Now, even for an undetermined mouth state
$i$, a recipe $R(i)$ can be propagated.  A feed-back influence on the entry
states does not require an alteration of $R(i)$.

A further simplification is possible. If the entry operation $op(i)$ dominates
the setting of a variable $v$ by setting it to a constant.  It will also be the
same whatever the other entries contribute, since it is executed after any
entry recipe. Thus the entry recipes are then automatically homogeneous for
that $v$. In this particular case the $R^v(i)$' can be set to $op^v(i)$.  The
universally correct output recipe of a horizon state becomes 

\begin{equation}
    R_{uni}(i) = \begin{dcases*}
                 R^v(i) & $S_m(i,k))\,=\,\emptyset\,\forall\,k\,\in\,Pred(i)$ \\
                 A(v)   & $else$
                 \end{dcases*}
\end{equation}

In the case, that $A(v)$ is used a storing entry operation is required, that is
the snapshot map $S_m(i)$ maps $v$ to the state $i$. It follows the definition of
'run-time interference'.

\begin{definition}
Run-Time Dependent Interference

The process of 'run-time dependent interference' develops a recipe $R(i)$
for a mouth state $i$ in the presence of undetermined entry recipes. The
set of entry recipes becomes

\begin{equation}
    ER = \begin{dcases*}
            op(i)(R(k)) & $\forall\,k$ with $R(k)$ is determined \\
            R_{uni}(i)  & $\forall\,k$ with $R(k)$ is not determined
        \end{dcases*}
\end{equation}

Based on this specification of the entry recipes 'ER' the interference
procedure as defined before is performed. For any snapshot map entry
containing $i$, the value $v$ must be stored in $A(v)$.
\end{definition}

The resulting output recipe $R(i)$ can now be used for propagation. Through
repeated accumulation, previously undetermined mouth state entries become
determined. With a determined entry they become a new horizon state. Other
mouth state may get all their entries determined--thus they are no longer
horizon states. This way, the horizon moves forward until all mouth states are
determined. 

%==============================================================================
%
%==============================================================================
\section{Fine Tuning of Dead-Lock States}

Can there be a better recipe than the one developed by run-time dependent
interference? If so, it should be possible that after propagation of the
run-time dependent recipes, at the entries of the state new entry recipes
appear which are homogeneous with the determined entry. It is clearly
impossible for components $R^v(p)$ with $p \in Pred(i)$ that rely on
$A(v)$ since in that case the interfered recipe stores and restores, such that
the snapshot map for $v$ contains the horizon state $i$. The determined entry,
though can only contain sets of snapshot states that come before $i$. Thus,
there snapshot maps differ and can never produce a homogeneous output. They
always remain on storing and restoring from $A(v)$.

If the components $R^v(p)$ with $p \in Pred(i)$ are assignments of
constants, then a new homogeneous interference is possible. During run-time
interference the operation $op(i)$ was requested to be constant in order to
propagate into the output recipe. At this point, a more relaxed condition
requires $op(i)(R(p))$ needs to result in a constant assignment. Consider the
example of 

\begin{equation}
                       op(i) = \{ x = x + 1 \}
\end{equation}

The operation is clearly not dependent on the previous value of $x$--thus not
constant. However, if the predecessors recipe $R(p)$ assigns a constant $5$ to
$x$, then the concatenation becomes

\begin{equation}
                       op(i)(R(p)) = \{ x = 6 \}
\end{equation}

which does not depend on any auxiliary variable. If all entry recipes result in
the same constant assignment the recipe can be used as output recipe. Again,
propagation of this recipe by accumulation may improve other recipes. The process
of fine-tuning is notably the same as the normal propagation of recipes, with 
the exception of the termination criteria.

It has been shown, that from the correctness point of view, there is no need to
modify the output recipe of a mouth state. Thus, the result of interference
does not need to be assigned to the output recipe. The following condition 
on interference ensures that the fine-tuning does not continue forever.

\begin{condition}
Condition for interference during dead-lock fine-tuning.

The result of interference is only to be taken into account, if the size of the
new recipe's snapshot map is smaller than the size of the old recipe's snapshot
map.  
\end{condition}

A recipes component $R^v(i)$' that is constant cannot become dependent on
$A(v)$ because this happens only during inhomogeneous interference. Thus, the
set of variables in the new recipe's snapshot map is a subset of the variables
of the old recipe's snapshot map.

With the mentioned requirement a mouth state $i$ can be passed at maximum a
restricted $N$ number of times, where $N$ is the number of variables in
$V_r(i)$. Since, number of states is restricted in general, the total number of
propagations is restricted. At that point, no new constant entry recipes could
be determined. Thus the fine-tuning has reached its optimum.

\end{document}

