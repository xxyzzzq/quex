\documentclass[12pt,a4paper]{scrartcl}

\usepackage{amsmath, amsthm, amssymb}
\usepackage{mathtools}  
\usepackage{graphicx}   % need for figures
\usepackage{verbatim}   % useful for program listings
\usepackage{color}      % use if color is used in text
\usepackage{subfigure}  % use for side-by-side figures
\usepackage{hyperref}   % use for hypertext links, including those to external documents and R_{uni}Ls

% don't need the following. simply use defaults
\setlength{\baselineskip}{16.0pt}    % 16 pt usual spacing between lines

\setlength{\parskip}{3pt plus 2pt}
\setlength{\parindent}{20pt}
\setlength{\oddsidemargin}{0.5cm}
\setlength{\evensidemargin}{0.5cm}
\setlength{\marginparsep}{0.75cm}
\setlength{\marginparwidth}{2.5cm}
\setlength{\marginparpush}{1.0cm}
\setlength{\textwidth}{150mm}

\newtheorem{definition}{Definition}
\newtheorem{statement}{Statement}
\newtheorem{condition}{Condition}

\begin{comment}
\pagestyle{empty} % use if page numbers not wanted
\end{comment}

% above is the preamble

\begin{document}

\begin{center}
{\large State Machine Optimization by Recipes} \\ 
\copyright 2015 by Frank-Rene Schaefer         \\
January, 2015
\end{center}


%==============================================================================
%
%==============================================================================
\section{Abstract}

This document describes a procedure to transform a state machine with the goal
of minimizing the number of operations along transitions.  From an outside
view, i.e. at entry and exit, the original and the resulting state machine
behave identically.  The analysis exploits deterministic behavior along state
transitions to remove redundant operations.  With the fewer operations in the
internal structure the resulting state machine is more time and memory efficient
than the original one.  

Figure \ref{fig:two-state-machines} shows a state machine consisting of four
states.  The dotted lines indicate the transition upon an event that causes the
state machine to exit.  In the original state machine, as shown in figure
\ref{fig:two-state-machines}.a, the content of $v$ is incremented at each
transition. When the state machine is left in state 3, for example, three such
increments must have taken place. In figure \ref{fig:two-state-machines}.b an
optimized representation of the state machine is shown.  There, value of $v$ is
only determined upon exit.  No increments happen during transitions. Only upon
exit $v$ is assigned the predetermined value. The balance of computational
effort is obvious.

\begin{figure}[htbp] \leavevmode \label{fig:two-state-machines}
a)
\begin{verbatim}
                     v:=v+1        v:=v+1        v:=v+1
              ( a )------->( b )------->( c )------->( d )
                : exit       : exit       : exit       : exit
                :            :            :            :
\end{verbatim}
    
b)
\begin{verbatim}
              ( a )------->( b )------->( c )------->( d )
                : exit       : exit       : exit       : exit
                :            :            :            :
              v:=0         v:=1         v:=2         v:=3
    
\end{verbatim}
\caption{Original and optimized state machine.}
\end{figure}
                 
%==============================================================================
%
%==============================================================================
\section{Basic Terminology}

For the present discussion the actual events that trigger state transitions are
of no concern. Moreover, the focus lies on the operations as consequence of
state transitions.  From a variety of operations, not all of them may relate to
the same subject.  Some operations determine the last accepted pattern, the
input position to be restored upon acceptance, the line and column numbers, the
checksum value of a lexeme, or the sum of character grapheme widths of the
lexeme's characters, and so on. Let $V_c$ name the specification of the set of
variables which are subject to such operations. $V_c$ may be any type of formal
description such as 'all variables related to input position storage' where the
number of variables remains arbitrary.  For brevity, let $V_c$ denote two
concepts according to the context of its usage: The description of concerned
values and the set of concerned variables. Let $op(i)$ name the operations
applied to $V_c$ upon entry into a state, independent from where the state is
entered. Let $op_E(i,k)$ name operations applied upon entry, depending on the
state from which it is  entered. Let a raised letter at operation, such as $v$
in $X^v$ denote the component of $X$ which develops variable $v$. For example,
$op^v(i)$ denotes the component of $op(i)$ which develops variable $v$. 

The original state machine must be composed of \textit{single-entry states}.
That is, upon entry into a state $i$ the same operations $op(i)$ are applied on
$V_c$ independently from which state it is entered.  A single-entry state is
shown in figure \ref{fig:se-vs-me}.a. The optimization transforms the
single-entry state machine into a \textit{multi-entry state machine}.  That is,
the operations $op_E(i,k)$ depends on the transition from which the state is
entered. A multi-entry state in shown in figure \ref{fig:se-vs-me}.b.

\begin{figure}[htbp] \leavevmode \label{fig:se-vs-me}
a)

\begin{verbatim}
                  .---.  
           ...   ( k_0 )------.
                  '---'        \                  .-.
           ...   ( k_1 )--------+---[ op(i) ]----( i )----->   
                  '---'        /                  '-'
           ...   ( k_3 )------'       
                  '---'
\end{verbatim}
     
b)
     
\begin{verbatim}
                  .---.
           ...   ( k_0 )------[ op_E(1, k_0) ]----.
                  '---'                            \         .-.
           ...   ( k_1 )------[ op_E(1, k_1) ]------+-------( i )----->  
                  '---'                            /         '-'
           ...   ( k_3 )------[ op_E(1, k_2) ]----'       
                  '---'
\end{verbatim}
\caption{Two types of state modelling: a) Single entry state. 
b) Multi-entry state.}
\end{figure}

Let \textit{initial state} denote the state where the state machine is entered.
Let the \textit{initial recipe} $R(init)$ be the recipe to be applied before
the state machine starts.  Let $Pred(i)$ and $Succ(i)$ indicate the set of
immediate predecessor and successor states of state $i$. Let $Pred^*(i)$
indicate all states that lie on a path from the initial state to state $i$.
Let $Succ^*(i)$ indicate all states which are reachable from state $i$. Not all
variables of $V_c$ may be required in all states. Let the set of required
variables be defined as follows.

\begin{definition}
$V(i)$ -- Set of Required Variables

$V(i)$ defines the variables which are potentially required in state $i$.  The
variables in $V(i)$ must be sufficient

\begin{itemize}
\item to implement the nominal behavior upon exit and
\item to develop the sets of required variables $V(k)\,\forall\,k\,\in\,Succ^*(i)$. 
\end{itemize}

For brevity, let $V(i)$ denote two concepts depending on the context where it
is used: the set of required variables as well as their settings.

\end{definition}

In contrast to $V_c$, the set of variables in $V(i)$ must be concrete.  Instead
of the loose statement such as 'all variables related to input position
storage', the specific variables with name and/or index must be specified.  As
said in the definition, $V(i)$ consists of the set of potentially required
variables. That is, it is sufficient for $V(i)$ be a superset of the actually
used variables. That actually used variables may depend on external conditions,
or even on the path taken along the state machine. This has an important
implication. 

\begin{statement} \label{stm:relevance-condition}
    The conditions for using a variable $v$ must be exactly the same as the
    conditions for $v$ receiving a valid setting. 
\end{statement}

If this was not the case, the procedure relying on $v$ would produce
indeterministic results. Consequently, a procedure may have a component for a
required variable $v$, which according to some conditions is not used.

\begin{statement}
    A procedure's component $X^v$ with respect to a variable $v$ may be irrelevant
    depending on the previous path, or external conditions. Let the expression
    \begin{equation}
        X^v \,=\,\eta
    \end{equation}
    signify, that the component that computes $v$ in $X$ is irrelevant.
\end{statement}

The configuration of $V(i)$ can be determined by a \textit{back-propagation} of
needs. A state which requires a specific variable tags all of its predecessor
states with this requirement. That is, for a variable named $v$, it holds

\begin{equation}
    v\,\in\,V(i)\,\Rightarrow\,\forall\,k\,\in\,Pred^*(i):\,v\,\in\,V(k)
\end{equation}

Assume, for example, that the lexeme length is not required in a terminal. Then
any operation contributing to the computation of the lexeme length is
redundant.  No state on a path to this terminal is required to perform lexeme
length related operations, except that another successor state requires it.  In
practical applications, it might be difficult to determine the precise set of
required variables $V(i)$. In such cases, a \textit{superset} of the set of
required variables suffices for correctness. The impact on performance of using
a superset instead of the precise set is discussed at the very end of this
document.  The aforementioned concepts allow to specify the frame of an
investigated behavior.  

\begin{definition} Investigated Behavior 

The investigated behavior determines the scope of analysis. It is
specified by a description of concerned variables $V_c$, the required
variables $V(i)$ for each state $i$, the related operations $op(i)$ and
their nominal behavior.
\end{definition}
    
A nominal behavior defines what needs to happen during the state machine
transitions.  For example, the nominal behavior for line number counting is
that the line number count should be increased upon each newline character
and remain the same upon the occurrence of any other character. 

%==============================================================================
%
%==============================================================================
\section{Linear States and Mouth States}

Two central concepts are required for the further discussion: 'linear states'
and 'mouth states'.  They are defined in the paragraphs to follow. 

\begin{definition}
Linear State

A state $i$ is a linear state, if the number of the immediate predecessor states is
1, i.e. 

\begin{equation}
                           size(Pred(i))\,=\,1
\end{equation}

The number of the immediate successor states is arbitrary, i.e.
$size(Succ(i))\,\ge\,0$.

\end{definition}

The concept of a linear state is shown in figure \eqref{fig:linear-state}. The
operation $op(i)$ takes the settings $V(k)$ of the previous state $k$
and derives $V(i)$, i.e.  the setting of variables in the current state. This
can be expressed as 

\begin{equation} \label{eq:accumulation}
            V(i) = op(i)(V(k))                                         
\end{equation}

with $k$ as the one and only predecessor state. If $V(k)$ is determined, then
$V(i)$ is determined purely from the consideration of the state machine. Such a
deterministic mapping is not possible for so called 'mouth states'.

\begin{figure}[htbp] \leavevmode \label{fig:linear-state}
\begin{verbatim}
                                                      .---> 
                                                     /
                                                   .-.
                      --------[ op(i) ]---------->( i )---> 
                         V(k)              V(i)    '-'

\end{verbatim}
\caption{The concept of a linear state in a single-entry state machine.}
\end{figure}

\begin{definition}
Mouth State

A mouth state is a state that is entered from more than one predecessor 
state, i.e.
\begin{equation}
                           size(Pred(i))\,>\,1
\end{equation}
The number of immediate successor states is arbitrary, i.e.
$size(Succ(i))\,\ge\,0$.

\end{definition}
    
\begin{figure}[htbp] \leavevmode \label{fig:mouth-state}
\begin{verbatim}
                  ------>--.  
                 V(a)       \ 
                             \                       .-.
                  ------>-----+---[ op(i) ]---------( i )---> 
                 V(b)        /                 V(i)  '-'
                            /
                  ------>--'
                 V(c)

\end{verbatim}
\caption{The concept of a mouth state in a single-entry state machine.}
\end{figure}

Figure \ref{fig:mouth-state} displays the concept of a mouth state and the
development of the $V(i)$ based on the $V(a),\,V(b)$ and $V(c)$, of the
predecessor states. In a mouth state $V(i)$ depends on the path taken at
run-time of the state machine.  $V(i)$ is determined as follows.

\begin{equation} \label{eq:interference}
    V(i) = \begin{dcases*}
            op(i)(V(k_0)) & if entry from state $k_0$ \\
            op(i)(V(k_1)) & if entry from state $k_1$ \\
            \ldots \\
            op(i)(V(k_n)) & if entry from state $k_n$ \\
            \end{dcases*}
\end{equation}


%==============================================================================
%
%==============================================================================
\section{Recipes}

The goal of all analysis is to exploit deterministic characteristics to omit some
redundant operations along transitions.  Only when exiting the state
machine, or at mouth states, operations shall be implemented. The key concept
for the underlying analysis is the 'recipe'. The definition of a recipe,
however, requires the term 'auxiliary variables' to be specified.

\begin{definition} $A$, $A(v)$ -- Auxiliary Variables

The term auxiliary variable $A(v)$ specifies a variable that may store the
'snapshot' of a variable $v$-s content upon entry into a mouth state. For each
variable $v\,\in\,V_c$ there is exactly one auxiliary variable $A(v)$.
   
Let $A$ name the set of all auxiliary variables.
\end{definition}

So called 'hidden variables' are variables inside the state machine other than
the current state.  For example, a lexical analyzer state machine has as hidden
variables the lexeme start position, the buffer limits, and the character
stream input position.

\begin{definition} $R_E(i,k),\,R(i)$ -- Recipe 

For a given state $i$, let $R(i)$ signify a procedure that is able to compute
$V(i)$ solely from the state machine's hidden variables $h$ and the auxiliary
variables $A$.  It performs the mapping

\begin{equation} \label{eq:recipe-procedure}
    (h, A) \rightarrow V(i)                                             
\end{equation}

Let $R_E(i,k)$ name the recipe upon entry into a state $i$ from a predecessor
state $k$. It corresponds to the \textit{function composition} of state $k$'s
output recipe $R(k)$ and state $i$'s operation $op(i)$, that is

\begin{equation} \label{eq:entry-recipe-concatenated}
    R_E(i,k) \,=\, op(i)\, \circ \, R(k)
\end{equation}

Let $R^v(i,k)$ and $R^v(i)$ signify the components of $R(i,k)$ and $R(i)$ which
produce $v\,\in\,V(i)$.  

\end{definition}

The fundamental difference between $R(i)$ and $V(i)$ is that the former
describes a procedure and the latter represents the values which are produced.
Operations $op(i)$ and $op_E(i,k)$ are functions that produce a setting of
variables \textit{based} on a previous setting of $V_c$.  Recipes are functions
that produce a setting of variables \textit{independent} of $V_c$, but may be
dependent on $h$ and $A$.

As soon as a recipe relies on an auxiliary variable $A(v)$ the action of
storing something in $A(v)$ becomes necessary. If the assignment of $A(v)$ was
not implemented, then recipe would refere to something void. In other words, a
recipe must be be associated with a set of states which are required to perform
$A(v)=v$ upon entry. Let the 'snapshot set' be defined as follows.

\begin{definition} $S^v(X)$ -- Snapshots Set.

    Let $X$ denote any procedure relying on an auxiliary variable $A(v)$.
    Then, the \textit{snapshot set} $S^v(X)$ is the set of states where the
    value of $v$ must be stored in $A(v)$ so that $X$ is correct. 

\end{definition}

Another important concept is that of a \textit{history-dependence}.

\begin{definition} History-Dependence/-Independence

    A procedure $op^v_H$ is history-independent with respect to a variable $v\in V_c$,
    if it computes $v$ independently of a previous setting of $V_c$.  The function
    composition of an arbitrary procedure $X$ with a procedure $op^v_H$ does not
    require any storing of auxiliary variables, i.e.

    \begin{equation}
        S^v(op^v\circ X) = \emptyset.
    \end{equation}
    
    The general term 'history-independent' is attributed to procedures which
    are history-independent for all variable that they produce.  A procedure
    that is not history-independent is history-dependent.

\end{definition}

The operation '$v\coloneqq x+3$', with some variable $x\notin V_c$, is
history-independent.  However, the operation '$v\coloneqq v+1$' is
history-dependent because the assignment depends on the previous setting of
'$v$. In that sense, the \textit{no operation} on variable $v$ is
history-dependent. Its implementation is $v\coloneqq v$ which clearly depends
on $v$.  A special history-independent procedure is the recipe from 'before
entry' $R(init)$. It is history-independent with respect to all $v\in V_c$, it
actually initialzes those. For example

\begin{eqnarray}
    R(init) & = & \{ line_n \coloneqq line_{n,before} \}
\end{eqnarray}

initializes the variable $line_n$ with a constant $line_{n,before}$. This
emphasizes the understanding of 'history' as something that evolves inside the
state machine during the current phase of state transitions. What happend
before, such as the operations to develop initial values in an earlier phase,
is not considered as part of history. 

It is conceivable, that a mouth state requires variable $v \in V(i)$, but the
predecessors did not actually assign anything to it. Let the 'indifference'
be defined as follows.

\begin{definition} Indifference

    An procedure $X$ is indifferent with respect to $v$, if it does not contain
    a component $X^v$ that computes $v$. 
    
\end{definition}

In consequence, $A(v)$ may contain meaningless data. Therefore, any access to
$v$ must be restricted to circumstances where it contains meaningful data.
Thus, the following condition must hold.

\begin{definition} Access-Lock Condition \label{cond:access-lock}

   If a recipe $R$ may exist wich is indifferent with respect to $v$, then
   the access to variable $v$ must be protected by an access-lock. 

   The lock must be initially locked.  No recipe shall access $v$ without the
   access-lock being open. It is unlocked upon the first assignment to $v$.
    
\end{definition}

This seems, at the first glance as an unnatural constraint. However, if the
nominal behavior does not automatically incorporate it, then the state machine
itself is not able to behave deterministically.  Consider, for example, figure
\ref{fig:access-lock}. In state 2, pattern 0 accepts the keyword 'if', but only
if a pre-context 'pre0' is true. Then, the position register $r[0]$ stores the
position where pattern 0 accepted, so that the next pattern match may continue
right after the recognized keyword. $r[0]$ is irrelevant, if 'pre0' is not
true. If in the states 2 and 3 a letter appears different from 'f' and 'y',
then the state machine exits and the input position must be reset to the
position where 'if' was accepted. But, $r[0]$ is only used, if pattern 0
accepted, and pattern 0 only accepts, if 'pre0' is true.  In this case, the
access lock to the potentially irrelevant $r[0]$ is provided by either 'pre0'
or the condition 'a=0'. While the access-lock condition should not require any
additional effort of implementation, it is necessary for the proof of
correctness.

\begin{figure}[htbp] \leavevmode \label{fig:access-lock}
\begin{verbatim}

          i               f            f            y         
    ( 0 )------->( 1 )------->( 2 )------->( 3 )------->( 4 )
                 ++i          ++i          ++i          ++i 
                        pre0=>a=0                       a=1
                           r[0]=i                    r[1]=i

\end{verbatim}
\caption{Access-lock to potentially irrelevant variable $r[0]$.}
\end{figure}

At this point, the overall goal can be formulated. The optimization transforms
the given single-entry state machine based on transition operations $op(i)$
into a multi-entry state machine based on entry operations $op_E(i,k)$ and exit
operations derived from recipes. Observing only the entry and exit, the changes
to $V_c$ must comply to the nominal behavior. 

%==============================================================================
%
%==============================================================================
\section{Accumulation and Interference}

Linear states change variables in a deterministic way. There is only one entry
into such a state $i$. If the predecessor state $k$'s recipe $R(k)$ is
determined, then the state's recipe $R(i)$ by equation \eqref{eq:entry-recipe-concatenated} 
is determined straight-forward.

\begin{equation} \label{eq:linear-state-recipe}
    R(i) \,=\,R_E(i,k) \,=\, op(i)\,\circ\,R(k)
\end{equation}

The above equation shows that recipes can be developed along linear states by
the plain concatenation of operations.  For a mouth state, the development of the
state's recipe is not so deterministic.  Instead, it depends on the path by
which the state is entered.  From equation \eqref{eq:entry-recipe-concatenated}
and \eqref{eq:interference}, it follows directly

\begin{equation} \label{eq:mouth-state-recipe}
    R(i) = \begin{dcases*}
             R_E(i,k_0) & if entry from state $k_0$ \\
             R_E(i,k_1) & if entry from state $k_1$ \\
             \ldots \\
             R_E(i,k_n) & if entry from state $k_n$ \\
            \end{dcases*}
\end{equation}

For the general case, this shows that recipes may not be developed across
mouth states, except if auxiliary variables are computed. That is if there
are entry operations in place which assign a value to an auxiliary variable $A(v)$
\begin{equation}
    A(v) \coloneqq   \begin{dcases*}
             R^v_E(i,k_0) & if entry from state $k_0$ \\
             R^v_E(i,k_1) & if entry from state $k_1$ \\
             \ldots \\
             R^v_E(i,k_n) & if entry from state $k_n$ \\
            \end{dcases*}
            \,\forall\,v\,\in\,V(i)
\end{equation}

Then, the output recipe $R(i)$ is determined by

\begin{equation}
    R^v(i) \,=\, \{ v \coloneqq A(v) \}\,\,\forall\,v\,\in\,V(i)
\end{equation}

and can be used for further development of recipes. Obviously, if all entry 
recipes $R^v_E(i,k)$ are the same, then no storage in $A(v)$ is required, instate
$R^v(i)$ could be chosen as the same as the entry recipes. The definition
of coherence, below, supports a precise condition for assigning the output
recipe with a prototype of the entry recipes.

\begin{definition} Coherence/Incoherence

    The expression '$v$ is coherent' at the entry into a mouth state $i$
    means, that three conditions hold. 

    \begin{enumerate}

    \item There must be an entry recipe $R_E(i,k_0)$ with $k\,\in Pred(i)$ 
          that is not indifferent with respect to $v$.

    \item All other entry recipes $R_E(i,k)$ are equal or indifferent, i.e. for 

        \begin{equation} \label{eq:definition-coherence}
            \begin{aligned}
                \forall\,k\,\in\,Pred(i)\,\,\mbox{with}\,\,k\,\neq\,k_0:\,R_E^v(i,k)\,=\,R_E^v(i,k_0)\,\,\vee\,\,R_E(i,k)\,=\,\eta
            \end{aligned}
        \end{equation}
        
    \item No snapshot set shall contain the state $i$ itself, i.e.

        \begin{equation} \label{eq:definition-coherence-2}
            \begin{aligned}
                i\,\notin\,S^v(R_E(i,k))\,\,\forall\,\,k,\,\in\,Pred(i)
            \end{aligned}
        \end{equation}

    \end{enumerate}
    
    The expression '$v$ is incoherent' means that the first condition is met.
    However, at least one of the last two conditions are not met.

\end{definition}

In the similar way as a heap of pebbles is not subject to investigations of
'peaceful behavior',  the term 'coherence' does not make sense in relation to 
entry recipes that are all indifferent. If all entry recipes are indifferent,
there is nothing that produces a setting for $v$ or could be incoherent with
each other. This is the reason for the first condition.

\begin{definition} Interference

    The process of 'interference' develops a recipe $R(i)$ for a mouth state $i$
    based on entry recipes $R_E(i,k) = op(i)\,\circ\,R(k)\,\mbox{with}\,k \in Pred(i)$.
    The output recipe $R(i)$ depends on the coherence of $v$, i.e. 

    \begin{equation} \label{eq:interference-output}
        R^v(i) = 
        \begin{dcases*}
            R_E^v(i,k_0) & if $v$ is coherent \\
            A(v)         & else
        \end{dcases*}
    \end{equation}

    for an arbitrary $R_E^v(i,k_0)\neq\eta$.  For the snapshot sets of the result
    recipe $R(i)$ it holds

    \begin{equation} \label{eq:interference-snapshot-sets}
        S^v(R(i)) = 
        \begin{dcases*}
            \bigcap_{k\in Pred(i)} S^v(R_E(i,k))            & if $v$ is coherent \\
            \{\,i\,\}\,\bigcap_{k\in Pred(i)} S^v(R_E(i,k)) & else \\
        \end{dcases*}
    \end{equation}

    A prerequisite for interference is that all $R_E(i,k)$ with $k\,\in\,Pred(i)$
    are determined.

\end{definition}

If $v$ is incoherent, an entry operation $op^v_E(i,k)$ must be implemented in
the resulting state machine that stores the computed value of $v$ in $A(v)$.
The existence of the entry operations $op_E(i,k)$ is the reason why the result
is expressed as a multi-entry state machine is required. 

The set of mouth states which must implement entry operations is simply the
union of all snapshot sets, i.e.

\begin{euqation}
    EOS \,=\, \Cup_{\forall i} S^v(R(i)) \, \cup \, \Cup_{\forall i,k} S^v(R_E(i,k))
    
\end{euqation}

Eventually, when all recipe analysis is done, the entry operations in the
resulting state machine may be implemented according the entry recipes, i.e.

\begin{equation} \label{eq:entry-operation-implementation}
      op_E^v(i,k) \,=\, \{ A(v) \,=\, R^v_E(i,k) \} \,\mbox{if $i\,\in\,EOS$}.
\end{equation}

Equation \eqref{eq:interference-snap-shot-sets} expresses the fact that
coherent recipes pass mouth states unchanged, and so are the related snapshot
sets unchanged. If the mouth state's operation $op^v(i)$ is
history-independent, then any dependency on $A$ is removed and
$S^v(R_E(i,k))=S^v(op^v(i)\circ R(k))=\emptyset$ for all $k \in Pred(i)$. 
In the incoherent case, when a snapshot of a variable $v$ is taken in state
$i$, then the set of snapshot states $S^v(R(i))$ must contain $i$.  

Applying interference to linear states ends up again with equation
\eqref{eq:linear-state-recipe}, because there is only one entry recipe.  One
single recipe is naturally coherent on all $v\,\in\,V(i)$. This guides to a
procedure to develop recipes across linear states.

\begin{definition} Accumulation

Given a state $i$, its predecessor state $k$, the entry operation $op(i)$
the predecessor's recipe $R(k)$, the recipe $R(i)$ is given by
\begin{equation}
       R(i)\,=\,op(i)\,\circ\,R(k)
\end{equation}
If auxiliary variables $A$ are involved, then the snapshot maps do not change,
except if $op^v(i)$ is history-independent
\begin{equation} \label{eq:accumulation-aux}
    S^v(R(i))\,=\,\begin{dcases*}
                  \varepsilon & if $op^v(i)$ is history-independent. \\
                  S^v(R(k))   & if $v$ is coherent.\\
                \end{dcases*}
\end{equation}
A prerequisite for accumulation is that $R(k)$ of the predecessor is 
determined.
\end{definition}

Accumulation and interference describe how recipes are developed from
determined recipes.  But, where does the first determined recipe come from?
The concatenation of a predecessor recipe $R(p)$ with history-independent
operation $op(k)$ (see definition \ref{def:history-independent-operation}) is
\textit{independent} of $R(p)$, i.e. the recipe $R(k)$ becomes

\begin{equation}
    R(k)\,=\,op^v(k)\,\circ\,R(p)\,=\,op^v(k)\,\,\mbox{where $p\in Pred(k)$}
\end{equation}

In a state where all operations $op^v(i)$ are history-independent, a recipe can
be determined \textit{independently} of other recipes. It is therefore suited
as starting point for the derivation of other recipes.

\begin{definition} Spring, Initial Spring \label{def:springs}

    A spring, in general, is a state $i$ where all components $R^v(i)$
    $\forall\,v\in\,V(i)$ are determined.
    
    An initial spring is a spring $i$ where the recipe $R(i)$ can be determined
    solely from $op(i)$ and, if it is the initial state, $R(init)$. 

\end{definition}

A state $v$ where $op^v(i)$ is history-independent for all $v\in V(i)$ is an initial
spring. For the initial state, it is sufficient that it has only one entry, the
entry from 'before entry'. Then, $R(i) = op(i)\circ R(init)$ which is well
determined.  Both, linear states and mouth states may be equally candidates for
being a spring.

\subsection{Examples}
                 
Figure \ref{fig:two-state-machines}.a displayed a state machine with a single
variable, i.e. $V_c=\{'v'\}$. The operations $op(i)$ upon transition are
$v\coloneqq v+1$ for all states. Let $A_a(v)$ hold the value of $v$ upon entry the
state $a$.  This notation combines the recipe's procedure with its snapshot
map.  In the above example, the recipe in state $a$ solely restores what has
been stored.

\begin{equation} 
    R(a) = \{ v \coloneqq  A_a(v) \} 
\end{equation}

The recipe $R(b)=R_E(b,a)$ must be equivalent to the concatenated execution of
$op(b)$ and $R(a)$, i.e.

\begin{eqnarray}
    R(b)&=&\{\,v\,\coloneqq \,A_a(v);\,v\,\coloneqq \,v + 1;\} \\
    R(b)&=&\{\,v\,\coloneqq \,A_a(v) + 1; \}                                 
\end{eqnarray}

This rule applied repeatedly to the states 'c' and 'd' leads to

\begin{eqnarray}
    R(c) &=&\{ v \coloneqq  A_a(v) + 2 \} \\
    R(d) &=&\{ v \coloneqq  A_a(v) + 3 \}                                 
\end{eqnarray}
%%
If the state machine exits at $a$, $b$, $c$, or $d$ the content of $v$ can be
determined without relying on the intermediate operations $\{ v\coloneqq v+1 \}$. This
was shown in figure \ref{fig:two-state-machines}.b. 
%%
The repeated accumulation of recipes along linear states comes to an end at
mouth states. State $e$ in figure \ref{fig:interference-example} is such a
mouth state. Its entry recipes $R_E(e,b)$ and $R_E(e,d)$ are an example of two
identical entry procedures. However, both rely on stored values for $v$ and the
place where those values where stored differ. That is $S^v(R_E(e,b))=a$ and
$S^v(R_E(e,d)=c)$. Thus, $v$ is incoherent upon entry into state $e$.  In
the resulting state machine the computed values of $v$ must be stored in an
auxiliary variable $A(v)$ as shown in figure \ref{fig:interference-example}.b.
%%
\begin{figure}[htbp] \leavevmode \label{fig:interference-example}
a)
\begin{verbatim}

  A(v) = v                       R_E(e,b) = A(v) + 2
  - - - ->( a )-------->( b )--------.
            |                         \
            | A(v) = v               ( e )--------->
            |                         /
  - - - ->( c )-------->( d )--------'
   A(v) = v                      R_E(e,d) = A(v) + 2

\end{verbatim}
b)
\begin{verbatim}
                                 
  - - - ->( b )---[ A_e(v) = A(v) + 2 ]-----.
                                             \     R(e) = A(v)
                                            ( e )---------------->
                                             /
  - - - ->( d )---[ A_e(v) = A(v) + 2 ]-----'
                                 

\end{verbatim}
\caption{Recipes upon exit replace transition operations.}
\end{figure}

The next section treats the recursive accumulation of recipes starting from
springs.  It is conceivable, however, that right from the beginning there is no
spring.  Even the initial state, if it has an entry other than from 'outside'
it may be an undetermined.  In that case, the analysis directly starts with a
so called 'dead-lock analysis' which is the subject of the next section but
one.

%==============================================================================
%
%==============================================================================
\section{Deterministic Propagation of Recipes}

If the recipe of a state $i$'s predecessor $k$ is determined, then the entry
recipe $R_E(i,k)$ can be determined. The same is true if the predecessor is an initial
spring, because then $R_E(i,k) = op(i)\circ\,op(k)$. Practically, this means
that recipes can be determined starting from a spring along linear states by
accumulation until the entry of a mouth state is reached. Linear states may
have multiple successor states, so this walk can be accomplished by a recursive
'tree walk'.  The termination criteria for the recursive accumulation walk is
defined as follows.

\begin{definition}
Termination criteria for accumulation walk.

A recursive accumulation walk does not enter the state ahead, if 

\begin{itemize}
    \item there is no state ahead.
    \item the state ahead is a mouth state.
    \item the state ahead is a spring.
\end{itemize}
\end{definition}

The first condition comes natural. The second condition exists, because recipes
cannot be accumulated beyond mouth states. As a direct consequence, the walk
can never go along loops, since a loop requires a state with more than one
entry. The third condition tells that the walk stops where another walk begins
or began.  

\begin{figure}[htbp] \leavevmode \label{fig:algo-1}
\begin{verbatim}
   
           (1) springs = initial springs of state machine.

   .- yes -(2) springs == empty set? <-----------------------------.
   |                                                               |
   |       (2) recursive accumulation starting at springs          |
   |                                                               |
   |       (3) interference on mouth states that are determined    |
   |        |                                                      |
   |        '--[ springs = determined mouth state ]----------------'
   |
   '------>(4) Stop.

\end{verbatim}

\caption{Deterministic propagation of recipes from springs.}
\end{figure}

The recipes resulting from deterministic propagation are shaped by the 
operations $op(i)$ of the original state machine and the spring recipes. No
new 'branch recipe' can influence any resulting recipe. This allows to 
statements to be made about correctness and determinacy.

\begin{statement} Correctness of Deterministic Propagation \label{stm:correctness-rule}
    
    Thus recipes derived from deterministic propagation are granted
    to be correct under the same conditions that springs are granted to be
    correct.

\end{statement}

\begin{statement} Determinacy of Deterministic Propagation \label{stm:determinacy-rule}

    For any recipe developed by deterministic propagation, it holds that it 
    will not change as long as the spring recipes do not change.

\end{statement}


The algorithm in figure \ref{fig:algo-1} implements the procedure to determine
recipes recursively through accumulation.  When this algorithm comes to an end,
there might be still mouth states with undetermined entries.  The following
section discusses a solution for the remaining states where the deterministic
recursive accumulation of recipes could not provide a solution.

%==============================================================================
%
%==============================================================================
\section{Dead-Lock Resolution}

Interference can only be performed, if all entry recipes of a mouth state are
determined. Loops in the state machine graph, however, may cause
\textit{circular dependencies} and undetermined mouth states.  Figure 8 shows
an example, where the two states 1 and 2 mutually block each other. The recipe
$R(1)$ for state 1 cannot be determined because it requires $R(2)$ which is
undetermined. However, before $R(2)$ from state 2 can be determined, $R(1)$
must be present. None of the states 1 and 2 is suitable for interference,
because they are missing an entry recipe.  Circular dependencies as an origin
of dead-lock states are intuitive. The precise proof is provided in the
subsequent paragraphs. What follows describes a procedure to determine the
behavior of those dead-lock states and their dependent states.

\begin{figure}[htbp] \leavevmode
\begin{verbatim}
                                       R(1)
                          R(0)     .---->----.
                    ( 0 )------>( 1 )       ( 2 )
                                   '----<----'
                                       R(2)

\end{verbatim}
\caption{A dead-lock in mouth states 1 and 2.}
\end{figure}

\begin{definition} $U$ -- The Set of Dead-Lock States

A dead-lock state $i\,\in\,U$ is a mouth state that, after algorithm 1 has
ended, is still undetermined. It has at least one undetermined entry which
prevents it from performing interference. $U$ is the set of all dead-lock
states.

\end{definition}


\begin{definition} $H(S)$ -- Horizon

    Let the term 'horizon of springs' indicate the set of mouth states that are
    reached by 'deterministic propagation' of a given set of springs $S$, but
    which cannot be determined by interference.

\end{definition}

Since horizon states are reached by deterministic propagation they have at least
one predecessor with a determined recipe.  The name 'horizon' is chosen because
it defines the border of determination.  Beyond that begins the realm of
dead-locked indeterminacy.  In particular, if the initial state is undetermined, it becomes
the one and only horizon state. The 'before begin state' with its recipe
$R(init)$ constitutes the predecessor with the determined recipe.  Figure
\ref{fig:horizon-state} shows a horizon state which contains one determined
entry and another undetermined entry. 

\begin{figure}[htbp] \leavevmode \label{fig:horizon-state}
\begin{verbatim}
                         R(a) -->--.
                                    \
                                     +---[ op(i) ]---( c )----> R(i)
                                    /
                     R(b) = ? -->--'

\end{verbatim}
\caption{A horizon state state with an entry from a determined state $a$ and 
    an undetermined state $b$.}
\end{figure}

Horizon states cannot produce a definite output recipe, because, not all of
their entry recipes are determined. However, a good guess can be made.  The
guess being made as a starting point for a horizon point is 'optimistic' in a sense
that it requires the least amount of store/restore operations. Let $P_d(h)$
denote the set of determined predecessor states of horizon state $h$ and
$P_u(h)$ the set of undetermined predecessor states. An optimistic guess is
that the output recipe does not contain more incoherence than the incoherence
inflicted by the already determined entry recipes.

\begin{definition} Optimistic Interference

    The process of 'optimistic interference' develops a recipe $R(i)$ for a
    horizon state $h$ based on determined entry recipes $R_E(h,k) =
    op(h)\,\circ\,R(k)\,\mbox{with}\,k \in P_d(h)$.  The output recipe $R(h)$
    depends on the coherence of $v$, i.e. 

    \begin{equation} \label{eq:opt-interference-output}
        R^v(h) = 
        \begin{dcases*}
            R_E^v(h,k_0) & if $v$ is coherent $\forall\,k\,\in\,P_d(h)$ \\
            A(v)         & else
        \end{dcases*}
    \end{equation}

    for an arbitrary $R_E^v(h,k_0)\neq\eta$. For the snapshot sets of the
    result recipe $R(h)$ it holds

    \begin{equation} \label{eq:interference-snapshot-sets}
        S^v(R(i)) = 
        \begin{dcases*}
            \bigcap_{k\in Pred(i)} S^v(R_E(i,k))            & if $v$ is coherent \\
            \{\,i\,\}\,\bigcap_{k\in Pred(i)} S^v(R_E(i,k)) & else \\
        \end{dcases*}
    \end{equation}

    A prerequisite for optimistic interference is that 
    $size(P_d(h)) \neq \emptset$.

\end{definition}

The path from the init state to a horizon state must pass initially through a
determined entry of the horizon state (TODO: proof). Thus, the optimistic
interference, actually, produces a correct recipe for transition sequences
where the horizon state is entered once (through a sequence from init state to
$P_d(h)$. A deterministic propagation of the optimistic recipes explores tails
of transition sequences that follow the horizon-reaching sequences. There are
three possible consequences as a result of deterministic propagation:

\begin{enumerate}
  \item A terminal is reached, i.e. the end of a transition string.

        In this case, no further action is required. 

  \item A mouth state is reached which has not yet determined its output
        recipe by optimistic inteference.

        A new stretch lies ahead which has not yet been explored. Using the
        results of optimistic interference allows to explore such stretches.
        Since any stretch in a state machine is adjacent to some other stretch,
        it is safe to assume that every such stretch in the state machine is
        eventually reached by analysis. 

        With the entry recipes that are now determined in the mouth state, 
        optimistic interference may be applied and subsequent states 
        may be explored.

  \item A mouth state is reached which has previously determined its
        output recipe by optimistic interference.
\end{enumerate}

The influence on $V_c$ is developped by accumulation, respectively, deterministic
propagation. It ends either in a terminal or at a mouth state where its 
setting influences interference. If the output recipe in such a mouth
state remains the same, then it can be stated, that it is general enough
to capture all incoming recipes. The influence of the stretch does not have
to be considered twice. If it changes, though, then the output recipe was
not general enough. The new recipe must be propagated along its paths ahead.
From this consideration, it is safe to assume that any influence along any
stretch is included into consideration for any of its successor states 
that may be influenced.

If a previous horizon state is reached through its undetermined predecessors
$R_u(h)$, then new entry recipes become available, and the guess can be
specified more precisely. First of all, it must be stated, that a component $v$
which is incoherent in $op^v(h)\circ\,R(k)$ for $k\in P_d(h)$ cannot become
coherent, because the cause of incoherence lies already in $P_d(h)$. An
inhomogeneous set cannot become more homogeneous by adding new elements. But,
it can become more inhomogeneous, if the new entries differ. 

If a new undetermined mouth state is reached, then it can be said, at least
that the transition sequence which reached it has been considered. If the mouth
state is reached the first time, then the stretch ahead gets on the 'todo-list'
for deterministic propagation. This implies, that upon termination every
stretche's impact on its mouth state ahead is considered.


For a horizon state, using the statements on correctness
\ref{stm:correctness-rule} and determinacy \label{stm:determinacy} of
deterministic propagation a key rule can be derived that will allow to resolve
the dead-lock states.

Given is a horizon state $h$ with a set of determined predecessor recipes $R_d$
and a set of undetermined predecessor recipes $R_u$. Let $R(i)=R^e(h)$ be an
estimated recipe. If deterministic propagation is applied based on a virtual
spring $h$ with a recipe $R(h)$ and all undetermined recipes $R_u$ are,
as a result, determined, then the undetermined recipes solely depend on the 
output recipe of $h$ (see determinacy \ref{stm:determinacy-rule}). As long
as the output recipe does not change, the recipes $R_u$ will be the same. 
If the interference in $h$ based on all recipes $R_d$ and $R_u$ result in the
same recipe $R^e(h)$, then the output recipe will never change, regardless how
many times the horizon state is repassed. 

According to the correctness rule \ref{stm:correctness-rule}, the developped
recipes are correct, if the springs are correct. Thus, $R^e(h)$ is chosen 
so that it fits the interference of all determined entries, then $R^e(h)$
is correct, as long as $h$ is entered by determined predecessors. Any path
from the initial state to the horizon state, though, goes through deterministic
recipes. Thus, it is primarily true for all transitions that pass through $h$
once but not twice. It follows, that

\begin{statement} Correctly Estimated Interference

    Let  $R^e(h)$ be an estimated output recipe with an estimated snapshot set
    $S^v(h)\forall v\in\,V(h)$. If deterministic propagation is applied with this
    state as spring and 

    \begin{enumerate}
        \item as a result, all previously undetermined predecessor states are
              determined, and
        \item the interference of all entry recipes $R_E(h,k)$ produces the 
              estimated recipe $R^e(h)$, 
    \end{enumerate}

    then $R^e(h)$ is the universally correct recipe for state $h$.
    
\end{statement}

How can a good estimate recipe $R^e(h)$ be found?  There are two extreme
assumptions that may be made with respect to $R(i)$ in the presence of
uncertainty on $R(b)$. The most daring statement is to assume that the
components of the determined entries which are coherent, will remain coherent
with the remaining entries, once they are known. 

do not enter the mouth state twice. directly after the horizon state. Or, more precisely it is true for
transition sequences that do not reach another dead-lock state after the
horizon.


The most cautious assumption is that all components are
incoherent, except for those where $op^v(i)$ is history independent. The latter
implements storing before and restoring after the mouth state, and is generally
correct.  For the former 'daring' approach precise conditions must be derived
before it can be applied.


\begin{definition} Cautious Interference

Cautious interference develops an output recipe for an undetermined mouth
state. The output recipe $R(i)$ is determined by its components for each $v$
          
\begin{equation} \label{eq:cautious-output-recipe}
    R^v(i) = \begin{dcases*}
              op^v(i) & if $op^v(i)$ is history-independent \\
              A(v)    & else
             \end{dcases*}
\end{equation}

The snapshot set for $R(i)$ is

\begin{equation} \label{eq:cautious-interference-snapshot}
    S^v(R(i)) = \{ \, i \, \}
\end{equation}

\end{definition}

The snapshot set cannot be empty, because if $op^v(i)$ has history-independent
for all $v$, then it was an initial spring--which can never be a dead-lock
state.  Thus, there is at least one case where state 'i' takes a snapshot. On
the other hand, if $op^v(i)$ is history-independent, then
$S^v(R(i))=S^v(op^v(i))=\emptyset$. When the union expression from equation
\eqref{eq:interference-snapshot-sets} is applied, the snapshot set consists of
one single element: the state $i$ itself. 

With the cautious interference, the deterministic propagation algorithm
receives new springs from which it can develop further recipes. Again, deterministic
propagation may end up with undetermined mouth states. Then, again, cautious
interference may derive intermediate recipes for the hew horizon states. This
loop continues until all recipes are found. 


\begin{figure}[htbp] \leavevmode \label{fig:algo-2}
\begin{verbatim}
   
           (1) springs = initial springs of state machine.

   .- yes -(2) springs == empty set? <-----------------------------.
   |                                                               |
   |       (2) recursive accumulation starting at springs          |
   |                                                               |
   |       (4) springs = by interference --------------------------+
   '-->---.                                                        |
   .- yes -(5) All states determined?                              |
   |                                                               |
   |       (5) springs = by cautious interferences ----------------'
   '------.
           (6) Stop 

\end{verbatim}

\caption{Complete algorith for determination of recipes.}
\end{figure}




Let the following two predecessor recipes of a horizon state be defined:
$k_d$ is the prototype of a determined predecessor recipe and $k_u$ is the
prototype of an undetermined predecessor recipe. For the \textit{determined}
entry, it holds that the path to it \textit{does not include a dead-lock state}
except via a spring. But, an accumulation over a spring state $s$ sets
$S(R(s))=\emptyset$. So, if there was a snapshot from a dead-lock state it must
pass the spring and from there $S(R(i)))=\emptyset$ for all states $i$ on the
path to the mouth's entry. It holds in general
%%
\begin{equation} \label{eq:before-horizon}
        S(R^v(k_d))\,\cap\,U\,=\,\emptyset
\end{equation}
%%
From equation \eqref{eq:cautious-interference-snapshot} it follows that no
snapshot before a horizon state remains in the output recipe.
%%
\begin{equation}
        S(R(i))\,\subseteq\,\{\,i\,\}
\end{equation}
%%
Undetermined entry recipes develop from the outputs of cautious interference 
recipes. Thus, their snapshots can only root back to horizons or their successor
states, i.e.
%%
\begin{equation} \label{eq:after-horizon}
        S(R^v(k_u))\,\subseteq\,\,U
\end{equation}
%%
For recipes to pass a mouth state they need to be the equal for all entries. Also
their snapshot maps must be equal. However, equations
\eqref{eq:before-horizon} and \eqref{eq:after-horizon} can only be true, if
%%
\begin{equation} \label{eq:coherence-condition}
    S(R^v(k_u))\,=\,S(R^v(k_d))\,=\,\emptyset 
\end{equation}

This in turn, is only true if $R^v(k_u)$ and $R^v(k_d)$ do not rely on stored
values at all, i.e. they are history-independent. This result is very important. When
$R^v(k_u)$ becomes determined, through subsequent accumulation, it is not
possible that it produces a new component $R^v(i)$ through interference except
that $S^v(R(i))=\varepsilon$.  For both cases, $op^v(i)$ being history-independent and
history-dependent, the combination of entry operations $op^v_E(i,k) = \{ A(v)
\coloneqq R_E(i,k) \}$ and the output recipe $R^v(i)=\{ v\coloneqq A(v) \}$
remains a correct solution $\blacksquare$.  

The output recipe $R(i)$, the coherence database $H^v(i)$, and the snapshot
maps $S^v(i)$ can be aquired based on existing procedures of accumulation and
interference. The key for that is a special definition for the undetermined
predecessor recipes. With such a 'cautious recipe' in place of undetermined
entry recipes ordinary interference may be applied to produce the exact same
result as defined in equation \eqref{eq:cautious-output-recipe}.  Let the
undetermined predecessor recipes be defined as

\begin{equation} \label{eq:undetermined-recipe}
    R^v(k_u) = \{ v \coloneqq A(v) \} \,\,\mbox{and}\,\, S^v(R(k_u)) = \sigma\,\,\forall\,v\,\in V(i)
\end{equation}

where $\sigma$ is a 'singular element'. Each $\sigma$ exists solely once. For
any two sets $B$ and $C$ it holds that if a $\sigma \in B$ it follows that
$\sigma \notin C$.  If $S^v(R_x)$ holds $\sigma$ no other snapshot map can hold
the same sigma.  With such a definition, the components of a \textit{cautious
entry recipe} $R_E(i,k_u)$ are determined by

\begin{eqnarray}
    R^v_E(i,k_u) & = & op^v(i) \circ R(k_u) \\
                 & = & \begin{dcases*}
                       op^v(i)         & if $op^v(i)$ is history-independent \\
                       x \coloneq A(v) & else
                       \end{dcases*}
\end{eqnarray}

Wherever $op^v(i)$ is history-independent, $R_E(i,k_u)$ is independent of $R(k_u)$ and is
therefore the same for all predecessors. It follows

\begin{equation} \label{eq:cautious-recipe-coherence}
    op^v(i) \,\mbox{is history-independent}\,\Rightarrow\,H^v(i, k_u) = true
\end{equation}

The snapshot maps develop to
\begin{eqnarray} \label{eq:cautious-repl-1}
    S^v(R_E(i,k_u)) & = & S^v(op(i) \circ R(k_u)) \\ 
                    & = & \begin{dcases*}
                          \varepsilon          & if $op^v(i)$ is history-independent \\
                          S^v(R(k_u)) = \sigma & else
                          \end{dcases*}
\end{eqnarray}

Since $\sigma$ appears in the expressions for history-independent components
$op^v(i)$, $S^v(R_E(i,k_u))$ can never be the same for all predecessors.
Ordinary interference, from definition \ref{def:interference}, imposes in that
case incoherence. Thus,

\begin{equation} \label{eq:cautious-recipe-incoherence}
    op^v(i) \,\mbox{is history-dependent}\,\Rightarrow\,H^v(i, k_u) = false
\end{equation}

Thus, the entry recipes are coherent if, and only if $op^v(i)$ is history-independent.
According to \eqref{eq:interference-output} applied interference delivers

\begin{equation} \label{eq:interference-output-2}
    R^v(i) = \begin{dcases*}
              R_E^v(i,k) & if $op^v(i)$ is history-independent.\\
              A(v)       & else
             \end{dcases*}
\end{equation}

which directly corresponds first equation \eqref{eq:cautious-output-recipe}
from the definition of cautious interference. The second equation
\eqref{eq:cautious-coherence} on coherence is fulfilled by equations
\eqref{eq:cautious-recipe-coherence} and
\eqref{eq:cautious-recipe-incoherence} . The last equation on snapshot maps
\eqref{eq:cautious-interference-snapshot} is maintained by
\eqref{eq:cautious-repl-1}.  Cautious interference can, therefore, be
implemented by the use of a special 'undetermined predecessor recipe' from
equation \eqref{eq:undetermined-recipe}.  When accumulated with the state's
$op(i)$ and passed through ordinary interference, exact the same expressions
result as they are required for cautious interference $\blacksquare$.

The output recipes $R(i)$ can be used for recursive accumulation of recipes so
that other dead-lock states receive determined entries and become part of the
horizon.  The horizon moves, the set of dead-lock states shrinks and a new
cycle begins.  This continues until no dead-lock state is left.  Eventually,
all entry recipes are determined. Then, it is possible that those entries which
are flagged with $H^v(i,k)=true$ implement the entry operation
$op_E^v(i)=R_E^v(i,k)$.  Before, however, another opportunity to optimize is
explored. 

%==============================================================================
%
%==============================================================================
\section{Fine Adjustment}

As mentioned in the previous section, the condition of coherence in the entry
recipes can be maintained, if they are history-independent--see equation
\ref{eq:coherence-condition}.  During cautious interference, $op^v(i)$ is
overtaken to the output recipe $R^v(i)$ if it is history-independent.  With equation
\ref{eq:coherence-condition} and determined entries $R_E(i,k)$ it is
sufficient to require 

\begin{equation} \label{eq:coherence-condition-2}
    op^v(i)\,\circ\,R(k)\,=\,C\,\,\mbox{for a constant $C$ and } \forall\,k\in\,Pred(i)
\end{equation}

That means, that all entry recipes produce the same constant value. Consider
the following example.

\begin{equation}
    op^v(i) = \{ v \coloneqq  v + 1 \}
\end{equation}

The operation is clearly dependent on the previous value of $v$--thus 
history-dependent. However, if the predecessors recipe $R(k)$ assigns a constant $5$ to
$v$, then the concatenation becomes

\begin{equation}
    op(i)\,\circ\,R(k)) = \{ v \coloneqq  6 \}
\end{equation}

which does not depend on any auxiliary variable. If all entry recipes of a
mouth state result in the same constant assignment, then the entry recipes for
$v$ are coherent.  The same constant may appear in the output recipe. Since
no storing and restoring is now required for $v$, the 'entry operation
implementation flag' can be turned of, that is

\begin{equation}
    H^v(i,k)\,=\,false\,\,\mbox{if}\,op^v(i)\,\circ\,R(k)\,=\,\mbox{const.}\,\forall\,k\,\in\,Pred(i)
\end{equation}

A recipe $R(i)$ that replaces some components by constants can now again be
propagated through accumulation. An entry is only constant if it is totally
independent of its predecessor states. The output of a successor mouth state
will only become constant, if all of its inputs are constant. Thus, constant
components are only propagated beyond mouth states if all entries are constant.
If all entries are constants they are all independent of their predecessors.
Thus, also the mouth's output recipe remains constant. It follows that through
constant propagation, recipes become constant but never change their value
further.  In particular, it is impossible that they become non-constant.
The repeated propagation of recipes may be applied with the difference of the
following termination criteria.

\begin{condition}
Condition for interference during dead-lock fine-tuning.

The result of interference is only to be taken into account, if the size of the
new recipe's set of snapshot states is smaller than the size of the old
recipe's set of snapshot states, i.e.

\begin{equation} 
    size(S(R_{new}(i)))\,<\,size(S(R_{old}(i)))
\end{equation}

\end{condition}

With the mentioned requirement a mouth state $i$ can be passed at maximum a
restricted $N$ number of times, where $N$ is the number of variables in $V(i)$.
Since, number of states is restricted, in general, the total number of
iterations is restricted. When no new interference is accomplished, no new
constant entry recipes can be determined and the process comes to an end.
Eventually, remaining entry operations $op_E^v(i)$ for which $H^v(i,k)=true$
must be implemented according to $A(v) \coloneqq  R_E^v(i,k)$.

\section{Superset of Required Variables}

In some cases, the precise set of required variables $V(i)$ cannot be
determined without an excessive path-analysis. Such path analysis is difficult
to tame with respect to computational effort and its correctness may be
difficult to proof.  A superset of $V(i)$ is often much easier to determine.
This implies that there might be variables in $V(i)$ which are actually not
necessary. This section investigates the impact of using a superset instead
of using the precise set with respect to correctness and performance. 

\begin{figure}[htbp] \leavevmode \label{fig:fork-states}
\begin{verbatim}
         
        ,---( 1 )---. .---( 4 )---.       
     ( 0 )         ( 3 )         ( 6 )  ...
        '---( 2 )---' '---( 5 )---'

\end{verbatim}
\caption{Sequence of forking states.}
\end{figure}

Consider a simple sequence of forking states as shown in figure
\ref{fig:fork-states}.  The first state where paths meet is state 3. For this
state there are two paths to consider: $0 \rightarrow 1 \rightarrow 3$ and $0
\rightarrow 2 \rightarrow 3$.  The second state where paths meet is state 6. To
reach this state four paths need to be considered: $0 \rightarrow 1 \rightarrow
3 \rightarrow 4 \rightarrow 6$, $0 \rightarrow 1 \rightarrow 3 \rightarrow 5
\rightarrow 6$, $0 \rightarrow 2 \rightarrow 3 \rightarrow 4 \rightarrow 6$,
and $0 \rightarrow 2 \rightarrow 3 \rightarrow 5 \rightarrow 6$. A sequence of
N meeting states with M forking paths in between each, requires to analyze
$M^N$ different paths.  It is therefore easy to find configurations that cannot
be analyzed even by the fastest machines.  Further, the influence of loops on
$V(i)$ may introduce complications which are difficult to overview.  Briefly
said, due restrictions of practical implementations it is impossible to
determine the precise set of $V(i)$ in the general case. 

What consequences arise if $V(i)$ contains unnecessary variables?  An operation
$op(i)$ that does not contain a component $op^v(i)$ must implement it by the
no-operation $v\coloneqq v$. With respect to the development of $v$ such
operations are indifferent. The set of required variables $V(i)$ influences the
optimization at the following stages:

\begin{description}
\item [Accumulation]

    The resulting recipe $R(i) = op(i)\circ R(k)$ may contain components
    $R^v(i)$ which are unnecessary, because of unnecessarily added components
    $op^v(i)$. $R^v(i)$ only plays a role in the theoretical investigations.

\item [Interference]

    If $op(i)$ or $R(k)$ contain a component for $v$, then the concatenation
    produces possibly incoherent entry recipes $R^v_E(i,k)$.  In this case,
    redundant entry operations $op_E^v(i,k)$ are added to the resulting state
    machine. Consequently, the resulting recipe $R(i)$ contains a redundant
    operation $v\coloneqq A(v)$ and the set of snapshot states $S(R(i))$ uust
    contain $i$.

    If neither $op(i)$ nor $R(k)$ contain a component for $v$, the $op^v(i)$ is
    assumed to be the no-operation. Thus $R_E^v(i,k)$ becomes the no-operation
    for all predecessors, and $v$ is coherent. No additional entry
    operations are added and the component $R^v(i)$ of the output recipe
    becomes the no-operation.

\item [Initial Springs]

    Since the no-operation is not constant, if added redundantly as a component
    to $op(i)$ a state may fail to be considered an initial spring--despite, of
    the constancy of its real components (see definition \ref{def:springs}).
    That means, that the propagation of recipes may start with fewer starting
    points. It is even conceivable, that there is no initial spring at all.
    Then, however, the optimization is done entirely in the frame of dead-lock
    analysis.

\item [Springs]

    A state $i$ is a spring if $R(i)$ is determined. Undetermined recipes,
    however, originate in missing entry recipes at mouth states. Redundant
    components $op^v(i)$ do not influence this behavior.

\item [Cautious Interference]

    Redundant non-constant entry operations cause redundant entry operations
    and no-operations in the output recipe. Some of them, might be removed
    during fine adjustment after dead-lock analysis.

\end{description}

In conclusion, if the optimization is applied on a superset of $V(i)$ instead
of $V(i)$ then redundant entry operations at mouth states may occur. It is
assumed that from the composition of the recipe, the exit operations can filter
out settings which are unnecessarily mentioned in $V(i)$. The consideration of
a superset is appropriate. In order to judge the impact of this simplification,
it is necessary to provide a \textit{overhead analysis} for the particular
investigated behavior. That is, it must be clear under what circumstances what
redundant operations are redundantly added to the resulting state machine.
Based on that, decisions may be made about the effort to be put into a
fine-tuning of the superset selection.

______________________________________________________________________________
PROOF THAT THERE ARE LOOPS IN DEAD LOCK STATES _______________________________

The end of a string of linear states is only undetermined, if the begin of the
string is undetermined. The begin of such a string must be a mouth state. Thus,
a string of linear states is only undetermined, if at its beginning there is an
undetermined mouth state. Consequently, the strings of linear states in between
mouth states may be omitted from considerations on indeterminacy.

An undetermined mouth state $i \in U$ must have at least one undetermined entry
recipe. Either the state from which it is entered is an undetermined mouth state, 
or the string of linear states backwards guides to an undetermined mouth state. 
Let the fact that a mouth state $i_0$ is undetermined because of another
undetermined mouth state $i_1$ be noted as $i_0 \vartriangleleft i_1$. Their might
be more than one dependency, but considering one is enough for this proof. Each
undetermined mouth state has at least one undetermined mouth state that feeds
an undetermined entry. Thus, the sequence 

\begin{equation}
    i_0\,\vartriangleleft\,i_1\,\vartriangleleft\,i_2\,\vartriangleleft\,\ldots
\end{equation}

has no end. But the set of undetermined states $U$ is finite. Thus, there must
be states appearing repeatedly in the sequence. Since the dependencies relate
to transition paths, this proves that loops must be involved. Loops, or circular
dependencies, are therefore a necessary condition for the existence of
dead-lock states $\blacksquare$. 
_______________________________________________________________________________

In order to understand the nature of dead-lock states better, it makes sense to
briefly review the recursive accumulation of recipes. The initial state $i_0$
is the first state that is entered. It has at least one entry recipe
$R_E(i_0,outside)$, i.e. the recipe to be executed when coming from $outside$
the state machine. If it has another entry that is undetermined and $op(i_0)$
is history-dependent, then the initial state becomes a horizon state.  Otherwise, it
is a spring and starting from $i_0$ determined recipes are propagated through
accumulation.  Accumulation ends with the determination of an entry into a
mouth state. If the reached mouth state ends up with determined entries, then a
determined recipe is propagated until a terminal or another mouth state is
reached. If a mouth state is reached where not all entries are determined, then
its output recipe is undetermined. Since by reaching it at least one entry is
determined and, thus,the state is a horizon state. The output recipe is
undetermined and no successor state is further reached with determined recipes.
Consequently, all successor states of that state are undetermined.  Determined
mouth states performed interference, and therefore must have all their entries
determined.  None of their entries can directly originate in a dead-lock mouth
state. From this discussion, an important conclusion can be drawn.  

\begin{statement} \label{stm:dead-lock-horizon}
A dead-lock state can only be reached by a path that guides through a horizon
state.  Paths from dead-lock states to non-dead-lock mouth states must contain
an initial spring.  
\end{statement}

\end{document}

