\documentclass[12pt,a4paper]{scrartcl}

\usepackage{amsmath, amsthm, amssymb}
\usepackage{mathtools}  
\usepackage{graphicx}   % need for figures
\usepackage{verbatim}   % useful for program listings
\usepackage{color}      % use if color is used in text
\usepackage{subfigure}  % use for side-by-side figures
\usepackage{hyperref}   % use for hypertext links, including those to external documents and R_{uni}Ls

% don't need the following. simply use defaults
\setlength{\baselineskip}{16.0pt}    % 16 pt usual spacing between lines

\setlength{\parskip}{3pt plus 2pt}
\setlength{\parindent}{20pt}
\setlength{\oddsidemargin}{0.5cm}
\setlength{\evensidemargin}{0.5cm}
\setlength{\marginparsep}{0.75cm}
\setlength{\marginparwidth}{2.5cm}
\setlength{\marginparpush}{1.0cm}
\setlength{\textwidth}{150mm}

\newtheorem{definition}{Definition}
\newtheorem{statement}{Statement}
\newtheorem{condition}{Condition}

\begin{comment}
\pagestyle{empty} % use if page numbers not wanted
\end{comment}

% above is the preamble

\begin{document}

\begin{center}
{\large State Machine Optimization by Recipes} \\ 
\copyright 2015 by Frank-Rene Schaefer         \\
January, 2015
\end{center}


%==============================================================================
%
%==============================================================================
\section{Abstract}

This document describes a procedure to transform a state machine with the goal
of minimizing the number of operations along transitions.  From an outside
view, i.e. at entry and exit, the original and the resulting state machine
behave identically.  The analysis exploits deterministic behavior along state
transitions to remove redundant operations.  With the fewer operations in the
internal structure the resulting state machine is more time and memory efficient
than the original one.  

Figure \ref{fig:two-state-machines} shows a state machine consisting of four
states.  The dotted lines indicate the transition upon an event that causes the
state machine to exit.  In the original state machine, as shown in figure
\ref{fig:two-state-machines}.a, the content of $v$ is incremented at each
transition. When the state machine is left in state 3, for example, three such
increments must have taken place. In figure \ref{fig:two-state-machines}.b an
optimized representation of the state machine is shown.  There, value of $v$ is
only determined upon exit.  No increments happen during transitions. Only upon
exit $v$ is assigned the predetermined value. The balance of computational
effort is obvious.

\begin{figure}[htbp] \leavevmode \label{fig:two-state-machines}
a)
\begin{verbatim}
                     v:=v+1        v:=v+1        v:=v+1
              ( a )------->( b )------->( c )------->( d )
                : exit       : exit       : exit       : exit
                :            :            :            :
\end{verbatim}
    
b)
\begin{verbatim}
              ( a )------->( b )------->( c )------->( d )
                : exit       : exit       : exit       : exit
                :            :            :            :
              v:=0         v:=1         v:=2         v:=3
    
\end{verbatim}
\caption{Original and optimized state machine.}
\end{figure}
                 
%==============================================================================
%
%==============================================================================
\section{Basic}

For the present discussion the actual events that trigger state transitions are
of no concern. Moreover, the focus lies on the operations as consequence of
state transitions. In the frame of this discussion, the original state machine
must be described in terms of \textit{single-entry states}. That is,
independently from where a state $i$ is entered, the same modification to a
variable $v$ is applied. The modification of a variable $v$ upon entry into a
state $i$ is called 'operation' and denoted as $op^v_i$. The operation may
depend on $v$ itself and produces the subsequent $v$. In the original state
machine no exit operation are necessary The development of variables solely
depends on the operations applied along state transitions. 

The resulting state machine is described in terms of \textit{multi-entry
states}. The computation of a variable's value is postponed to the exit of the
state machine. So called 'recipes' describe how a variable $v$ can be computed
without iteratively depending on its previous value.  For a state $i$ an 'exit
recipe' $R^v(i)$ is provided that tells how $v$ could be computed.  So, it is
actually used to determine subsequent recipes. For this reason, the exit recipe
is refered to as 'recipe'.  While recipes do not relate to $v$ itself, they may
relate to reference variables $v_r$ which are assigned upon entry into states.
An 'entry recipe' $R^v_E(i,k)$ computes what $v$ would be.  If necessary, this
value can be stored in a reference variable.

Figure \ref{fig:se-vs-me}.a) shows an example of a state of an original state
machine where the transitions from all predecessor states pass the same
operation $op_i$ when entering state $i$. The operation $op_i$ is physically
implemented and produce $v$ and may also use $v$ as input. In the resulting
state machine, as in the example of figure \ref{fig_se-vs-me}.b), a state may
apply multiple entry recipes. These entry recipes are physically implemented,
but produce reference variables $v_r$ not $v$.  They rely on reference values,
but not directly on $v$. The recipe $R(i)$ is only physically implemted for the
exit of the state machine from state $i$.  

\begin{figure}[htbp] \leavevmode \label{fig:se-vs-me}
a)

\begin{verbatim}
                  .---.  
           ...   ( k_0 )------.
                  '---'        \                     .-.
           ...   ( k_1 )--------+---[ v = op_i ]--->( i )----->   
                  '---'        /                     '-'
           ...   ( k_3 )------'       
                  '---'
\end{verbatim}
     
b)
     
\begin{verbatim}
                  .---.
           ...   ( k_0 )------[ v_r = R_E(1, k_0) ]----.
                  '---'                                 \         .-.   R(i)
           ...   ( k_1 )------[ v_r = R_E(1, k_1) ]------+-------( i )-------->  
                  '---'                                 /         '-'
           ...   ( k_3 )------[ v_r = R_E(1, k_2) ]----'           : exit
                  '---'                                       [ v = R(i) ]
                                                                   :
\end{verbatim}
\caption{Two types of state modelling: a) Single entry state. 
b) Multi-entry state.}
\end{figure}

The variable $v$ refers to a value that is developed through transitions along
the state machine. Upon exit from the state machine $v$ contains a value that
corresponds to the event sequence that triggered all state transitions. For
example, in pattern matching $v$ is the identifier of the winning pattern, when
counting line or column numbers $v$ may contain the according numerical values,
or $v$ may contain the hash value of the incoming characters. In recipes,
deterministic behavior is captured in terms of constants. The path dependent
behavior is captured relying on reference variables.

\begin{definition} $v_r$ -- Reference Variable

    A reference variable $v_r$ may store the 'snapshot' of a variable $v$-s
    content. For each variable $v\,\in\,V_c$ there is exactly one reference
    variable $v_r$.

\end{definition}

Let \textit{initial state} 0 denote the state where the state machine is entered.
The operation $op_0$ is the operation applied upon entry into the init state.
Let the hidden variables $h$ refer to any accessible variable that does not
directly relate to the state machine's state. Now, the term 'recipe' can 
be defined.

\begin{definition} Recipe 

    A recipe consists of a procedure to compute a variable $v$ and a data
    structure $d$ that configures the procedure. It possibly applies hidden
    variables $h$ and the reference values $v_r$. That is, it performs the
    mapping

    \begin{equation} \label{eq:recipe-procedure}
        (h, v_r) \rightarrow v 
    \end{equation}

    The entry recipe $R^v_E(i,k)$ describes how to compute the value of $v$ upon
    entry into a state $i$ from a predecessor state $k$. The exit recipe 
    $R^v(i)$ describes how to compute $v$ upon exit from the state.

    For each recipe it must be described how composition of operations and
    recipes $op_i\circ R(k)$ produce a new recipe. 

    An initial recipe $R_{init}$ is required, which determines $d$ when the
    state machine is entered. 

    A reference value based recipe $R_{ref}$ is required, which determines
    a recipe that solely depends on a stored reference variable $v_r$.

\end{definition}

An example of a recipe is the line number counting recipe:

\begin{description}
    \item[The procedure's data structure $d$:] The data structure that configures
        the procedure holds the line number offset. A binary flag indicates whether
        the value of the reference variable has to be added or not. That is, $d$
        has two members::

        \begin{verbatim}
                d.line_number_offset
                d.use_reference_variable
        \end{verbatim}
        
    \item[Procedure:] The procedure to determine the current line number
        consists of adding the line number offset to the line number
        counters value (which is a 'hidden variable'), if it is not zero.::

        \begin{verbatim}
               if d.use_reference_variable:
                   counter.line_number += reference.line_number_offset 
                   if d.line_number_offset != 0:
                       counter.line_number += d.line_number_offset 
               else if d.line_number_offset != 0:
                   counter.line_number += d.line_number_offset
        \end{verbatim}

        The 'if' statements expresses conditions under which the required
        additions need to be implemented.

   \item[Composition:] Let \verb/delta/ be the value by which an operation increments
       the line number and \verb/dk/ the '$d$' of the recipe $R(k)$.
       Then the line number of the composition $op_i\circ R(k)$ is the sum of
       both. That is the '$d$' if the resulting recipe is given by::

        \begin{verbatim}
                 d.line_number_offset     = dk.line_number_offset + delta
                 d.use_reference_variable = dk.use_reference_variable
        \end{verbatim}

   \item[$R_{init}$:] Before entering the state machine the line number offset
        is assumed to be zero and no reference variable is used, i.e $d$ is
        initialized to::

        \begin{verbatim}
                d.line_number_offset     = 0
                d.use_reference_variable = false
        \end{verbatim}

   \item[$R_{ref}$:] The recipe that solely depends on the content of the
       reference variable has the settings of $d$ given by::

        \begin{verbatim}
                d.line_number_offset     = 0
                d.use_reference_variable = true
        \end{verbatim}

\end{description}

The subsequent section separates states into two categories.  Using this
categorization deterministic behavior along state transitions is then explored
and described in terms of recipes.

%==============================================================================
%
%==============================================================================
\section{Linear States and Mouth States}

There are two types of states in a state machine. One type of states where the
setting of a variable is distinctly determined by its setting in the last step.
In a second type of states a, variables value depends on the state from where the
last step originated.  The two state types are defined below as linear and
mouth states.

\begin{definition} Linear State

    A state $i$ is a linear state, if the number of the immediate predecessor 
    states is 1, i.e. 

    \begin{equation}
                               size(Pred(i))\,=\,1
    \end{equation}

    The number of the immediate successor states is arbitrary, i.e.
    $size(Succ(i))\,\ge\,0$.

\end{definition}

\begin{figure}[htbp] \leavevmode \label{fig:linear-state}
\begin{verbatim}
                                                     .---> 
                                                    /
                                                  .-.
                      --------[ op_i ]---------->( i )---> 
                        v@k                v@i    '-'

\end{verbatim}
\caption{The concept of a linear state in a single-entry state machine.}
\end{figure}

The concept of a linear state is shown in figure \eqref{fig:linear-state}. The
operation $op_i$ takes the variable $v$ in the predecessor's state $k$ and
derives $v$ in state current state $i$. This can be expressed as 

\begin{equation} \label{eq:composition}
            v @ i = op_i(v @ k)                                         
\end{equation}

If there is a recipe to determine $v@k$, then the recipe
to determine $v$ upon entry into $i$ is given by function composition. 
The exit recipe is exactly the same as the entry recipe, thus

\begin{equation} \label{eq:composition}
    R(i) = R_E(i,k) = op_i \circ R(k)
\end{equation}

If $v$ of the last step is known, then $v@i$ is determined without
consideration of the last state.  Such a direct relationship is not given for
so called 'mouth states'.

\begin{definition} Mouth State

    A mouth state is a state that is entered from more than one predecessor
    state, i.e.

    \begin{equation}
                               size(Pred(i))\,>\,1
    \end{equation}

    The number of immediate successor states is arbitrary, i.e.
    $size(Succ(i))\,\ge\,0$.

\end{definition}
    
\begin{figure}[htbp] \leavevmode \label{fig:mouth-state}
\begin{verbatim}
                  ------>--.  
                 v@a        \ 
                             \                      .-.
                  ------>-----+---[ op_i ]---------( i )---> 
                 v@b         /                 v@i  '-'
                            /
                  ------>--'
                 v@c 

\end{verbatim}
\caption{The concept of a mouth state in a single-entry state machine.}
\end{figure}

Figure \ref{fig:mouth-state} displays the concept of a mouth state and the
development of the $v@i$. The previous transition step may have originated in
state $a$, $b$, or $c$. Each one of these states is reached by its own path from
the initial state. Each one has potentially developed another value for $v$. 
To determine $v$ based on the last step, it must be known \textit{from where}
this last step originated. The value of $v@i$ computes conditionally to

\begin{equation} \label{eq:interference}
    v@i = \begin{dcases*}
            op_i(v@k_0) & if entry from state $k_0$ \\
            op_i(v@k_1) & if entry from state $k_1$ \\
            \ldots \\
            op_i(v@k_n) & if entry from state $k_n$ \\
        \end{dcases*}
\end{equation}

The entry recipes are determined by composition as they are for linear
states, but here for each predecessor state separately.

\begin{equation} \label{eq:mouth-composition}
    R_E(i,k) = op_i \circ R(k),\,\forall\,\,k\,\in\,Pred(i)
\end{equation}

It is generally correct to store the computed value for $v$ at runtime in a
reference variable $v_r$. Then,  the exit recipe of the mouth state is plainly
'take $v_r$' expressed as $R_{ref}$.

\begin{figure}[htbp] \leavevmode \label{fig:mouth-state}
    \begin{verbatim}

         ( a )---->--[ v_r = R_E(i,a) ]---.
                                           \ 
                                            \          .-.    R_{ref}
         ( b )---->--[ v_r = R_E(i,b) ]------+--------( i )-------------> 
                                            /          '-'
                                           /
         ( c )---->--[ v_r = R_E(i,c) ]---'
             

    \end{verbatim}
    \caption{Reliance on a reference variable in a mouth state.}
\end{figure}

\section{Linear Transition Chains}

The setting of a variable along a chain of linear states can be computed as the
function composition of the entry operations along the states. Let the term 'linear
transition chain' be defined as follows. 

\begin{definition} Linear Transition Chain

    A linear transition chain consists of a start state followed by a, possibly
    empty, set of adjacent linear states and a end state. Transitions lead
    from the start state to the end state.  The development of a variable
    along a linear transition chain is deterministic.

    Let $k*$ denote the last state in the linear transition chain which starts
    at state $k$.
    
\end{definition}

The end state of a linear transition chain may be a mouth state or a terminal
state, i.e. a state that has no transition to another state. 

With the notations above a first algorithm can be defined that transforms a
operation-based state machine into a recipe-based state machine. The initial
state and all mouth state builds the set of start states of linear transition
chains. The exit recipe of the initial state is $op_0\circ R(init)$ if it is
not a mouth state. The exit recipe of all mouth states is $R_{ref}$. Starting from
those states with the given recipes, the recipes along the linear transition
chains can be determined by composition. Linear states may transit to multiple
successor states, so a tree-search algorithm needs to be applied.  The
termination criteria for the tree search is the arrival at the end state of the
linear chain of transitions.  The last action is the determination of the entry
recipe of the end state. 

Let the term 'correct configuration' be name a state machine that is
functionally equivalent to the original operation-based state machine. In this
sense, the recipe-based state machine achieved by the above algorithm
constitutes a correct configuration.  There might be other configurations,
though, which are more efficient in terms of computational effort.

\section{Coherence and Incoherence}

In equation \eqref{eq:mouth-composition} entry recipes for a mouth state are
developed. Computing the value of $v$, storing it in $v_r$, continuing with an
exit recipe $R_{ref}$ that restores $v$ is a general solution. It is correct if
some or all input recipes differ and it is correct if they are all equal.  A
recipe is determined by its procedure describing data structure $d$. Thus,
equality of two recipes can be linked to the equality of their $d$-s. Now, it
is seductive to replace $R(i)$ by $R_{new}(i)=R_E(i,k)$ for an arbitrary $k\in
Pred(i)$.  A mouth state may be setup in two ways.

\begin{description}

    \item[Incoherent setup:] The exit recipe is $R_{ref}$ which restores $v_r$.
        $v_r$ contains the value of $v$ as it is computed upon entry by
        $R_E(i,k)$.  This setup is \textit{mandatory} if their are two or more
        entry recipes that differ.

    \item[Coherent setup:] The exit recipe is set to $R_{new}(i)=R_E(i,k)$ for
        an arbitrary $k\in Pred(i)$. This setup is \textit{optional} but
        requires that all input recipes are equal.

\end{description}

%% IDEA: incoherent --> coherent setup seems locally advantegeous
%%       but implications on state machine may result in lesser quality.
%% IDEA: 'propagation' must be explained.
%% IDEA: logical implications --> set of possible configurations
%% IDEA: configurations may 'block' other configurations from being reached
%% IDEA: one coherent setup may be exclude another or more coherent setup.
%% IDEA: recipe must be correct upon for any number of transitions
%% IDEA: when state not in loop --> no consistency issues, but issues
%%                                  of blocking other recipes
%% IDEA: root configuration --> can all configurations be reached?
%% IDEA: horizon, the determined entry determines coherence.
The coherent setup requires less storing and restoring at run-time and is
therefore superior to the incoherent setup--when considering only the state
itself. The logical implications on the state machine must be considered,
though.  That is the recipe must be propagated along the branching linear
transition chains.  When mouth states are reached possible outcomes must be
considered. The resulting configuration may, actually, contain more storing and
restoring than before the coherent setup was applied.  Thus, it cannot be
assumed that a transition from an incoherent to a coherent setup is generally
advantageous.

A coherent setup for a state $i$ is correct if the state's entry recipes are
all the same and equal to the exit recipe $R_{new}(i)$. If all possible logical implications
of $R_{new}(i)$ result in entry recipes of state $i$ that result in an exit
recipe different from $R_{new}(i)$, then the coherent setup is not consistent.
It cannot be applied. On the other hand, if there is a logical implication that
does not change the exit recipe, then the recipe is consistent.  It correct
under the provision that the logical implications are applied on the state
machine.

Let a coherent setup for a state $i$ be correct and the state
machine be a correct configuration. Then the coherent setup is correct, if and
only if the implicated changes to the state machine are consistent. The
resulting state machine may require more storing and restoring then the one
before state $i$ changed its setup. 


Successive function composition of a recipe along linear transition chains are
deterministic. There is no source of possible inconsistency. In mouth states
with equal entry recipes there is a choice whether a coherent or an incoherent
setup is implemented. Choice also does not expose contradictions.  The sole
contradiction which may occur is the contradiction of a recipe with itself. If
the consequences of an exit recipe of state $i$ result in a change of state
$i$'s entry recipes and all possibly resulting exit recipes differ from the
postulated one, then this is a contradiction. There is no correct configuration
that could incorporate the recipe. On the other hand, if there is a
configuration where the exit recipe of $i$ does not have to change, then the
recipe is consistent and the given configuration is correct. Obviously,
only states with exits that connect to their entries can possibly 
be subject to such inconsistencies. Such states are part of a loop, i.e.
$k\in Pred*(k)$.

Propagation is the search for the set of correct configurations which
are consistent with an exit recipe in a state. The result is a set of
correct configurations. If the resulting set is empty, the recipe on
which it is based is inconsistent within the state machine. 

At each mouth state with equal entry recipes, propagation has the choice to
continue with a coherent or an incoherent setup. Consequently, the product of
propagation is not a single configuration, but a set of correct configurations
depending on what choices are made in the mouth states capable of coherent
setups. If the set of correct configurations that result from propagation
is empty, then the original state is incorrect.

\begin{definition} Propagation of a recipe.
    
    If $R(i)$ is the exit recipe of start state $i$, then 'propagation'
    of $R(i)$ means that the effect of this recipe on all successor states of
    $i$ is successively determined. A minimum of changes is applied that could
    effect a change of entry recipes of $i$.

    The recipe $R(i)$ is the basis for successive functional composition along
    all linear transition chains branching from state $i$. When a mouth state
    $k$ is reached its exit recipe is left as is, except 

    \begin{enumerate}
       \item if a coherent setup must be changed to an incoherent setup.
       \item if an incoherent setup can be replaced by a coherent setup, 
             and $k\notin Pred*(k)$.
    \end{enumerate}
    
    If the exit recipe of a  mouth state $k$ changes, then the propagation of
    $R(i)$ nests the propagation of the changed exit recipe $R(k)$. 

    A propagation of $R(i)$ results in a correct configuration if it does not
    result in a change of the $R(i)$ itself and if the propagations of the
    recipes $R(k)$ of the reached mouths states results in correct
    configurations.

\end{definition}

Functional composition along linear transition chains are deterministic
and can freely be reset, as long as the starting recipe is correct. 
In mouth states choices about coherent 
Whenever entry recipes are equal their are the two opportunities where
either coherent or incoherent setup may be applied. The coherent setup of
one state may obstruct the coherent setup of many others. The overal 
efficiency of a configuration 


.  However the propagation of the
recipe $R_{new}(i)$ might result in an incorrect configuration.  Before the
conditions for correctness are stated the term 'propagation' needs to be
specified. At first, a cautious version is proposed.

\begin{definition} Cautious Propagation of a recipe.
    
    If $R(i)$ is the exit recipe of start state $i$, then 'cautious propagation'
    of $R(i)$ means that the effect of this recipe on all successor states of
    $i$ is successively determined. It is tried to apply a minimum of changes
    to the state machine.

    The recipe $R(i)$ is the basis for successive functional composition along
    all linear transition chains branching from state $i$. When a mouth state
    $k$ is reached its exit recipe is left as is, except if a coherent
    setup must be changed to an incoherent setup.
    
    If the exit recipe of a  mouth state $k$ changes, then the propagation of
    $R(i)$ nests the propagation of the changed exit recipe $R(k)$. 
    
\end{definition}

Let the term 'nesting propagation' name the propagation that triggers the
propagation of a mouth state's recipe by changing its exit recipe.

For the development of $v$ the coherent setup is equivalent to the incoherent
setup, if the entry recipes are all the same and equal to $R(i)$. However, it
can only be replaced if it is logically consistent in the context of the state
machine. The minimal logical impact of a changed recipe is captured by cautious
propagation. It is deterministic, since it applies successive functional
composition. It applies a minimum amount of changes in mouth state recipes,
namely only when correctness requires an incoherent setup where a coherent
setup is found. Thus, if cautious propagation results in an entry recipe at
state $i$ different from what it was when the coherent setup produced $R(i)$,
then the recipe is inconsistent with itself in the frame of the state machine.
Otherwise, the recipe is logically consistent and the change can be applied.

If the propagation of $R_{new}(i)$ changes an entry recipe of state $i$ itself,
then $R_{new}(i)$ is not stable.  It holds for a tansition sequence that passes
state $i$ once, but not for an arbitrary transition sequence that passes more
than once.  It is not a general solution and, therefore, the resulting
configuration is incorrect.  

The propagation of a recipe $R(i)$ can only change an entry recipe of $i$ if
there is a path from the exit of $i$ to the entry of $i$. In that cases,s $i$
is part of a loop, i.e it belongs to the set of its own predecessor $i\in
Pred*(i)$. Trivially, any mouth state $k$ on the path of $i$ to itself is
equally part of that loop. Therefore $k\in Pred*(k)$ if $k$ is on a loop path
of $i$. Conversely, if $k\notin Pred*(k)$  then $R(k)$ cannot produce a changed
entry recipe of $k$, but also it does not lie on a path from a nesting
propagation's start state to itself. 

Thus, if $k\notin Pred*(k)$  then the change of an incoherent setup by a
coherent setup in state $k$ cannot possibly cause any changed entry recipe
of $k$ or any start state of its nesting propagations. The cautious propagation
can now be modified into a general definition of propagation that also
determines the conditions of its correctness.

An incoherent setup is generally correct. However, a coherent setup is requires
the proof of consistency within the state machine. The correctness of a
coherent setup can now be expressed in terms of its propagation.

\begin{statement} Correctness of a Coherent Setup

    A coherent setup is correct, if it is based on a correct configuration and 
    the propagation of its recipe results in a correct configuration.
    
\end{statement}



\section{Optimization}

As soon as a mouth state $i$ is the successor of another mouth state $k$, it is
conceivable that their coherent setup is excludes another coherent setup. That
is, if a coherent setup is implemented in a state $i$ the propagation of $R(i)$
implies that an incoherent setup must be implemented in state $k$.  In
foresight of the optimization strategy, let the transition of an incoherent
setup into a correct coherent setup be called a 'move'.  The former findings
have some major implications:

\begin{itemize}
    \item The order of chosen moves is decissive for the final configuration.

    \item Moves may cause configurations from where previously available 
          moves are obstructed.

    \item The quality of a move cannot be determined from the move alone, but
          must be seen in the context of the possible final configuration.

    \item There are different possible final configurations.
          
\end{itemize}

This situation can be specified as an extensive-form game (ref) with one single
player, i.e. their is no chance player. The decision points are the correct
configurations of the state machine, the choices are the moves that transform a
correct configuration into another correct configuration, and the payoff is the
quality attributed to a configuration. The game ends when there is no new
configuration that can be reached. When all possible combinations of moves are
done, the optimal configuration is determined as the one with the greatest
payoff. The shortest sequence of moves that guides from the starting
configuration to the optimal configuration determines the sequence of
propagation.


\section{-----}


\end{document}

