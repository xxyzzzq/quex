Customized Buffer Filling Procedures.
=====================================


A generated lexical analyzer runs its analysis on data located in 
a buffer. In general, this buffer is filled automatically by the
underlying buffer management which relies on some type of input
stream. It is, however, possible to access the buffer directly which,
in some cases may be advantegous. The following methods can be 
supplied to setup the analyzer's character buffer. The term 'framework'
is used to refer to some kind of entity that delivers the data.

#. *Copying* content into the buffer.

   The framework provides its data in chunks and specifies itself the data's
   memory location. The location is possibly different for each received frame.

   **Example**: ``demo/010/copy.cpp``.

#. *Immediate Filling* of the buffer.

   The framework writes its data in chunks into a memory location which is
   specified by the user.

   **Example**: ``demo/010/fill.cpp``.

#. *Pointing* to a memory address where the buffer shall analyze data.

   The (hardware level) framework writes data into some
   pre-defined address space which is the same for each received frame.

   **Example**: ``demo/010/point.cpp``.

#. Via an *input policy*, so that the buffer management may rely on it.

   Same as for *Copying* and *Immediate Filling*.  The advantage of this method
   is that it is for the engine and the user seemingless. With this method,
   there is no complexity to be added 'outside'.

In this section all processes are described. The first three methods can be
implemented using the member functions of the lexical analyzer object. The last
method, i.e. providing a customized input policy requires some extra coding.

.. note:: 

   With the methods *Immediate Filling*, and *Pointing* no implicit
   character code converters can be applied. If this is required, the users
   needs to call them explicitly. A so called 'buffer filler' can be created
   ouside the quex engine.

   The method *Copying* performs the conversion internally, if a filler 
   is specified.

In case of interrupted character streams, there is no direct way for the
analyzer engine to determine wether a stream is terminated or not. Thus,
either a 'end of analyzis' pattern must be introduced, or the analyzis
is to be supervised by another thread which may end the analyzis based 
on time-out conditions. In the following description it is assumed that
there exists a pattern that tells the analyzer that the stream is ended.
It produces a ``BYE`` token.


Direct Buffer Access
--------------------

Direct buffer access can be performed by means of the following member functions:

    QUEX_TYPE_CHARACTER*  buffer_fill_region_append(QUEX_TYPE_CHARACTER* TerminatedContent);
    QUEX_TYPE_CHARACTER*  buffer_fill_region_append(QUEX_TYPE_CHARACTER* ContentBegin, ContentEnd);
    QUEX_TYPE_CHARACTER*  buffer_fill_region_prepare();
    QUEX_TYPE_CHARACTER*  buffer_fill_region_begin();
    QUEX_TYPE_CHARACTER*  buffer_fill_region_end();
    size_t                buffer_fill_region_size();
    void                  buffer_fill_region_finish(const size_t FilledCharacterN);

-- pre-conditions / fall back region
-- calling constructor with no argument == raw buffer handling

Copying Content
...............

The method of copying content into the analyzer's buffer can be used
for the 'syntactically chunked input' (see :ref:`syntax-chunks`) and
the 'arbitrarily chunked input' (see :ref:`arbitrary-chunks`). Copying
of content implies two steps:

  #. Copy 'used' content to the front of the buffer so that space
     becomes free for new content.

  #. Copy the new content to the end of the current content of the
     buffer.

First, let us treat the case that the incoming frames are considered to be be
*syntactically complete* entities--such as a command line, for example. This case
is less complicated than the case where frame borders appear arbitrarily, because
any trailing lexeme can be considered terminated and the analyzer does not need
to wait for the next frame to possibly complete what started at the end of the last
frame. 

Syntactically Chunked Input Frames
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,


The following paragraphs discuss the implementation of this use case. First,
two pointers are required that keep track of the memory positions which
are copied to the buffer.

.. code-block:: cpp

    typedef struct {
        QUEX_TYPE_CHARACTER* begin;
        QUEX_TYPE_CHARACTER* end;
    } MemoryChunk;

A ``chunk`` of type ``MemoryChunk`` later contains information about the
current content to be copied into the analyzer's buffer. ``.begin`` designates
the beginning of the remaining content to be copied into the analyzer's buffer.
``.end`` points to the end of the currently available content as received from
the messaging framework. The following segment shows which variables are
required for the analyzis process.

.. code-block:: cpp

    int
    main(int argc, char** argv)
    {
        quex::tiny_lexer      qlex;            // No args to constructor --> raw memory 
        quex::Token           token;           // Two tokens required, one for look-ahead
        QUEX_TYPE_CHARACTER*  rx_buffer = 0x0; // A pointer to the receive buffer that
        MemoryChunk           chunk;

The analyzis start with the following:

.. code-block:: cpp

        // -- trigger reload at loop start
        chunk.end = chunk.begin;

        // LOOP
        while( 1 + 1 == 2 ) {
            // -- Receive content from a messaging framework
            if( chunk.begin == chunk.end ) {
                // -- If the receive buffer has been read, it can be released.
                if( rx_buffer != 0x0 ) messaging_framework_release(rx_buffer);
                // -- Setup the pointers 
                const size_t Size  = messaging_framework_receive_syntax_chunk(&rx_buffer);
                chunk.begin = rx_buffer;
                chunk.end   = chunk.begin + Size;
            }

            // -- Loop until the 'termination' token arrives
            while( 1 + 1 == 2 ) {
                qlex.receive(&token);

                if( token.type_id() == QUEX_TKN_TERMINATION ) break;
                if( token.type_id() == QUEX_TKN_BYE )         return 0;

                cout << "Consider: " << string(token) << endl;
            }
        }

At the beginning of the loop it is checked wether it is necessary to get
new content from the messaging framework. If so, the previously received
'receive buffer' may be released for ulterior use. Then the messaging
framework is called and it returns information about the memory position
and the size where the received data has been stored. Now, the content
needs to be copied into the analyzer's buffer.

.. code-block:: cpp

           chunk.begin = qlex.buffer_fill_region_append(chunk.begin, chunk.end);

This function call ensures that 'old content' is moved out of the buffer. Then,
it tries to copy as much content as possible from ``chunk.begin`` to ``chunk.end``.
If there is not enough space to copy all of it, it returns the pointer to the
end of the copied region. This value is stored in ``chunk.begin`` so that it
triggers the copying of the remainder the next time of this function call.
Now, the buffer is filled and the real analyzis can start. 

.. code-block:: cpp

            // -- Loop until the 'termination' token arrives
            while( 1 + 1 == 2 ) {
                qlex.receive(&token);

                if( token.type_id() == QUEX_TKN_TERMINATION ) break;
                if( token.type_id() == QUEX_TKN_BYE )         return 0;

                cout << "Consider: " << string(token) << endl;
            }

When a ``TERMINATION`` token is detected a new frame must be loaded. The
inner analyzis loop is left and the outer loop loads new content. If the
``BYE`` token appears the analyzis is done. Any token that is not one
of the two abovementioned ones is a token to be considered by the parser.
It follows the complete code of the analyzer for syntactically chunked
input frames:

.. code-block:: cpp

    #include "tiny_lexer"
    #include "messaging-framework.h"

    typedef struct {
        QUEX_TYPE_CHARACTER* begin;
        QUEX_TYPE_CHARACTER* end;
    } MemoryChunk;

    int 
    main(int argc, char** argv) 
    {        
        using namespace std;

        quex::tiny_lexer      qlex;            // No args to constructor --> raw memory 
        quex::Token           token;           // Two tokens required, one for look-ahead
        QUEX_TYPE_CHARACTER*  rx_buffer = 0x0; // A pointer to the receive buffer that
        MemoryChunk           chunk;

        // -- trigger reload of memory
        chunk.begin = chunk.end;

        // -- LOOP until 'bye' token arrives
        while( 1 + 1 == 2 ) {
            // -- Receive content from a messaging framework
            if( chunk.begin == chunk.end ) {
                // -- If the receive buffer has been read, it can be released.
                if( rx_buffer != 0x0 ) messaging_framework_release(rx_buffer);
                // -- Setup the pointers 
                const size_t Size  = messaging_framework_receive_syntax_chunk(&rx_buffer);
                chunk.begin = rx_buffer;
                chunk.end   = chunk.begin + Size;
            } else {
                // If chunk.begin != chunk.end, this means that there are still
                // some characters in the pipeline. Let us use them first.
            }

            // -- Copy buffer content into the analyzer's buffer
            chunk.begin = qlex.buffer_fill_region_append(chunk.begin, chunk.end);

            // -- Loop until the 'termination' token arrives
            while( 1 + 1 == 2 ) {
                qlex.receive(&token);

                // TERMINATION => possible reload
                // BYE         => end of game
                if( token.type_id() == QUEX_TKN_TERMINATION ) break;
                if( token.type_id() == QUEX_TKN_BYE )         return 0;

                cout << "Consider: " << string(token) << endl;
            }
        }

        return 0;
    }


Arbitrarily Chunked Input Frames
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,

In case that frames can be broken *in between* syntactical entities, more
consideration is required. The fact that a pattern is matched does not
necessarily mean, that it is the 'winning' pattern. For example, the frame
at time '0'::

    frame[time=0]  [for name in print]

matches at the end ``print`` which might be a keyword. The lexical analyzer
will return a KEYWORD token followed by a TERMINATION token. The TERMINATION
token tells the the end of a frame is reached, and thus, the previous token 
is not reliable. Let the above frame be continued by::

    frame[time=0]  [for name in print]
    frame[time=0]  [er_list: send file to name;]

which makes clear the actually the lexeme ``printer_list`` is to be matched.
To deal with such cases one look-ahead token is required. A token is only to be
considered, if the following token is not the TERMINATION token. If a
TERMINATION token is returned by the ``receive()`` function, then the border of
a frame has been reached. To match the last lexeme again after the appended
content, the input pointer must be reset to the beginning of the previous
lexeme. The procedure is demonstrated in detail in the following paragrpahs.
The following code fragment shows all required variables and their initialization.

.. code-block:: cpp

    int
    main(int argc, char**) {
    
        quex::tiny_lexer      qlex;       // No args to constructor --> raw memory 

        quex::Token    token_bank[2];     // Two tokens required, one for look-ahead
        quex::Token*   prev_token;        // Use pointers to swap quickly.
        quex::Token*   current_token;     // 

        QUEX_TYPE_CHARACTER*  rx_buffer = 0x0;  // A pointer to the receive buffer that
        //                                      // the messaging framework provides.

        MemoryChunk           chunk;      // Pointers to the memory positions under
        //                                // consideration.

        QUEX_TYPE_CHARACTER*  prev_lexeme_start_p = 0x0; // Store the start of the 
        //                                               // lexeme for possible 
        //                                               // backup.

        // -- initialize the token pointers
        prev_token    = &(token_bank[1]);
        current_token = &(token_bank[0]);
        current_token->set(QUEX_TKN_TERMINATION);
        //
        // -- trigger reload of memory
        chunk.begin = chunk.end;

Two token pointers are used to play the role of look-ahead alternatingly. The
tokens to which these pointers point are in the ``token_array``. The
current token id is set to ``TERMINATION`` to indicate that a reload
happend. The loading of new frame content happens exactly the same way
as for syntactically chunked input frames.

.. code-block:: cpp
    
    while( 1 + 1 == 2 ) {
        if( chunk.begin == chunk.end ) {
            if( rx_buffer != 0x0 ) messaging_framework_release(rx_buffer);
            const size_t  Size = messaging_framework_receive(&rx_buffer);
            chunk.begin = rx_buffer;
            chunk.end   = chunk.begin + Size;
        } 

The inner analyzis loop, though, differs because a look-ahead token
must be considered.

.. code-block:: cpp

        while( 1 + 1 == 2 ) {
            prev_lexeme_start_p = qlex.buffer_lexeme_start_pointer_get();
            
            // Let the previous token be the current token of the previous run.
            swap(&prev_token, &current_token);

            qlex.receive(current_token);

            if( current_token->type_id() == QUEX_TKN_TERMINATION ) break;
            if( current_token->type_id() == QUEX_TKN_BYE )         return 0;

            // If the previous token was not a TERMINATION, it can be considered
            // by the syntactical analyzer (parser).
            if( prev_token->type_id() != QUEX_TKN_TERMINATION )
                cout << "Consider: " << string(*prev_token) << endl;
        }

At the beginning of the loop the lexeme position is stored, because it might be
needed to backup if a frame border is reached. The ``swap`` lets the
current token become the look-ahead token and the previous token becomes
the token to which the current token is to be stored. The end of the frame
is detected with the ``TERMINATION`` token. The end of the analyzis is
triggered by some ``BYE`` token which must appear in the stream. Both
trigger a loop exit. If the current token (the 'look-ahead' token) is not a
``TERMINATION`` token, then the previous token can be considered by the parser.

The loop is exited either on 'end of frame' or 'end of analysis' as shown above.
If the end of a frame was reached, the position of the last lexeme needs to be 
setup. The handling of the loop exit is shown below.

.. code-block:: cpp

        // -- If the 'bye' token appeared, leave!
        if( current_token->type_id() == QUEX_TKN_BYE ) break;

        // -- Reset the input pointer, so that the last lexeme before TERMINATION
        //    enters the matching game again.
        qlex.buffer_input_pointer_set(prev_lexeme_start_p);
    }

.. warning::

    The procedure with one look-ahead token might fail in case of very small memory
    chunks. This is possible if a pattern contains potentially a sequence of 
    other patterns. Consider the mode

.. code-block:: cpp

        mode {
            "le"       => QUEX_TKN_ARTICLE;
            "monde"    => QUEX_TKN_WORLD;
            " "        => QUEX_TKN_SPACE;
            "le monde" => QUEX_TKN_NEWSPAPER;
        }

    which is fed with the frames::

        frame[time=0] [le]
        frame[time=0] [ ]
        frame[time=0] [monde]

    In this case the program waits propperly after ``le`` has arrived, but when
    the white space arrives, the content of the buffer is::

         [... le ]

    When the terminating token arrives the longest match holds which is ``le``
    and the analysis continues with the whitespace. The whitespace again is a
    valid token and thus no TERMINATING token is sent immediately which would
    trigger a re-consideration of what started with ``le``. Eventually, the
    token sequence will be: ``ARTICLE``, ``SPACE``, ``WORLD`` instead of
    a single token ``NEWSPAPER`` which matches ``le monde``.
    
    If frame are this small, two things can be done. Either copy as much frames
    into the buffer as possible before starting the analyzis, or apply more
    than one look-ahead. The first solution is, of course, simpler. However, in
    case of a blocking receive function, it might be not as efficient as the
    second solution.

The complete code to do the analyzis of arbitrarily chunked input frames is
shown below.

.. code-block:: cpp

    #include "tiny_lexer"
    #include "messaging-framework.h"

    typedef struct {
        QUEX_TYPE_CHARACTER* begin;
        QUEX_TYPE_CHARACTER* end;
    } MemoryChunk;

    void swap(QUEX_TYPE_TOKEN** A, QUEX_TYPE_TOKEN** B)
    { QUEX_TYPE_TOKEN* tmp = *A; *A = *B; *B = tmp; }

    int 
    main(int argc, char** argv) 
    {        
        using namespace std;

        quex::tiny_lexer      qlex;       // No args to constructor --> raw memory 
        quex::Token    token_bank[2];     // Two tokens required, one for look-ahead
        quex::Token*   prev_token;        // Use pointers to swap quickly.
        quex::Token*   current_token;     // 
        QUEX_TYPE_CHARACTER*  rx_buffer = 0x0;  // A pointer to the receive buffer that
        //                                      // the messaging framework provides.
        MemoryChunk           chunk;      // Pointers to the memory positions under
        //                                // consideration.
        QUEX_TYPE_CHARACTER*  prev_lexeme_start_p = 0x0; // Store the start of the 
        //                                               // lexeme for possible 
        //                                               // backup.

        // -- initialize the token pointers
        prev_token    = &(token_bank[1]);
        current_token = &(token_bank[0]);
        current_token->set(QUEX_TKN_TERMINATION);
        // -- trigger reload of memory
        chunk.begin = chunk.end;

        // -- LOOP until 'bye' token arrives
        while( 1 + 1 == 2 ) {
            // -- Receive content from a messaging framework
            if( chunk.begin == chunk.end ) {
                // -- If the receive buffer has been read, it can be released.
                if( rx_buffer != 0x0 ) messaging_framework_release(rx_buffer);
                // -- Setup the pointers 
                const size_t Size  = messaging_framework_receive(&rx_buffer);
                chunk.begin = rx_buffer;
                chunk.end   = chunk.begin + Size;
            }

            // -- Copy buffer content into the analyzer's buffer
            chunk.begin = qlex.buffer_fill_region_append(chunk.begin, chunk.end);

            // -- Loop until the 'termination' token arrives
            while( 1 + 1 == 2 ) {
                prev_lexeme_start_p = qlex.buffer_lexeme_start_pointer_get();
                
                // Let the previous token be the current token of the previous run.
                swap(&prev_token, &current_token);

                qlex.receive(current_token);

                // TERMINATION => possible reload
                // BYE         => end of game
                if( current_token->type_id() == QUEX_TKN_TERMINATION ) break;
                if( current_token->type_id() == QUEX_TKN_BYE )         return 0;

                // If the previous token was not a TERMINATION, it can be considered
                // by the syntactical analyzer (parser).
                if( prev_token->type_id() != QUEX_TKN_TERMINATION )
                    cout << "Consider: " << string(*prev_token) << endl;
            }

            // -- If the 'bye' token appeared, leave!
            if( current_token->type_id() == QUEX_TKN_BYE ) break;

            // -- Reset the input pointer, so that the last lexeme before TERMINATION
            //    enters the matching game again.
            qlex.buffer_input_pointer_set(prev_lexeme_start_p);
        }

        return 0;
    }


Direct Filling
..............

The method of direct buffer filling is the most memory and calculation time
efficient. In this case, the analyzer provides a pointer to an address where
new content can be filled in. Additionally, it provides the maximum fill
size and/or the end address of the space to be filled. This information
can be passed to some low level driver that fills the buffer. This way
no extra copying is required. Instead, the low level driver works directly
on the lexical analyzer's buffer. The following code fragment implements 
this approach:

.. code-block:: cpp
    
    while( 1 + 1 == 2 ) {
        // Initialize the filling of the fill region
        qlex.buffer_fill_region_prepare();

        // Call the low lever driver to fill the fill region
        int count_n = receive_transmission(qlex.buffer_fill_region_begin(), 
                                           qlex.buffer_fill_region_size());

        // Inform the buffer about the number of loaded characters NOT NUMBER OF BYTES!
        qlex.buffer_fill_region_finish(count_n);

        cout << "[[Received " << count_n << " characters in chunk.]]\n";

        // Loop until the 'termination' token arrives
        do {
            qlex.receive(&Token);
            cout << string(Token) << endl;
        } while( Token.type_id() != QUEX_TKN_TERMINATION && Token.type_id() != QUEX_TKN_BYE );

        if( Token.type_id() == QUEX_TKN_BYE ) break;
    }


