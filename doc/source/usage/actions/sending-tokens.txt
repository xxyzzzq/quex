.. _sec:usage-sending-tokens:

Sending Tokens
===============

The operator to send a token together with its token-id is ``=>``. It has
already appeared in some examples in preceeding sections. The meaning of
a code fragment like

.. code-block:: cpp

   mode MINE {
     ...
         "while"  => QUEX_TKN_KEYWORD_WHILE;
     ...
   }

is straight forward: When the pattern ``while`` matches, then return the
token-id ``QUEX_TKN_KEYWORD_WHILE``. Note, that quex takes the fuss of the
user's shoulders to define numerical values for the tokens. Technically, in the
generated code the token constructor is called and the token-id is set to the
specified value. Now, the token constructor may allow other arguments. Those
additional arguments may be specified in brackets, such as

.. code-block:: cpp

   mode MINE {
     ...
         [0-9]+  => QUEX_TKN_KEYWORD_WHILE(atoi(Lexeme));
         [a-z]+  => QUEX_TKN_KEYWORD_WHILE(Lexeme);
     ...
   }

where the former line calls the token constructor with a numeric argument, and
the second one calls it with the lexeme itself.  Additional arguments are
conceivable, but they would require a user defined token class.

Note, that information about the lexeme is available via the following 
'variables' [#f1]_.

.. data:: Lexeme

   A pointer to the first character of the matched lexeme. The lexeme itself is
   temporarily zero-terminated for during the pattern action. 
   
   .. note:: If the lexeme is to be referred to longer outside the action or event 
             handler, then the length the end pointer has to be stored along with 
             the lexeme. No such operations are not necessary, if the default 
             token class is used because it copies the string into a ``string`` object.

.. data:: LexemeBegin

   This is identical to ``Lexeme``.

.. data:: LexemeEnd

   A pointer to the first character after the lexeme which matches the current pattern.

.. data:: LexemeL

   The length of the lexeme.

.. data:: LexemeNull

   This is a pseudo-lexeme of length zero. It is useful in cases that 
   it is required to set some string inside a token[#f2]_.

Instead of relying on a named constand definition for a token-id, quex can
directly use character codes as token-ids. This comes handy when using
in conjunction with the parser generators like bison or yacc. The syntax
is simply the character written in single quotes. Quex uses UTF-8 as input
coding for the source files. Character of code ranges beyond can seeminglessly
be specified in the same manner, if your editor is setup in UTF-8 mode. The
following shows an example:

.. code-block:: cpp

    "="          => '=';
    "+"          => '+';
    "-"          => '-';
    ε            => 'ε';
    ∞|infinity   => '∞';

As the last line points out, this type of token-id specification is not
restricted to patterns of length one--they can be as any other pattern.  The
character code of the token-id can as well be specified numerically. Numeric
specifications of token ids can be done in decimal (without any prefix), 
hexadecimal with a '0x' prefix, octal with a '0o' prefix, or binary with a '0b'
prefix. This is shown in the following example:

.. code-block:: cpp

    Z      => 27;
    honey  => 0x1000;             // decimal: 4069
    butter => 0o456;              // decimal: 302 hex: 12E
    bread  => 0b1000011010100101; // decimal: 34469 hex: 86A5

Finally, the token-id can be specified via the name of a character from the
unicode character by using 'UC' plus whitespace as a prefix. The unicode
character name must have the spaces inside replaced with underscores. An
example is shown here:

.. code-block:: cpp

    X         => UC LATIN_CAPITAL_LETTER_X;
    \U010455  => UC SHAVIAN_LETTER_MEASURE;
    \x23      => UC NUMBER_SIGN;

.. note::

   When using the token policies ``queue`` or ``users_queue`` while the asserts
   are active, the engine **might** throw an exception if the user tries to
   send a token after a ``TERMINATION`` token.  There is a scenario where
   cannot detect it: if a ``TERMINATION`` is sent, then the queue is cleared,
   and then new tokens are sent. Then the engine has no reference to the last sent
   token. At the moment of token sending it cannot tell whether the last token
   was a ``TERMINATION`` token or not.
   
   There are no worries when including other files. The include stack handler
   re-initializes the token queues, though, as soon as the lexer returns from
   an included file.

   The behavior is there to help the user, not to bother him. It is to 
   prevent subtle errors where the token queue contains tokens beyond the
   terminating token that signified the end of a file.


.. rubric:: Footnotes

.. [#f1] They are actually defined as C-preprocessor macros and they are only
         active arround the generated code segments. If they are not used, no
         computation time is consumed.

.. [#f2] For performance reasons, the token objects are not initialized before
         content is written to to them. Thus, if only the token-id is written
         to them the rest of the content inherited from previous usage.
