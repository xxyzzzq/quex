Command Line Options
====================

This section lists the command line options to control the behavior of the
generated lexical analyzer.  Numbers following these options can be either
decimal, without any prefix, hexadecimal with a '0x' prefix or octal with a
'0o' prefix.  

.. cmdoption:: -i, --mode-files file-list
        
        ``file-list`` = list of files of the file containing mode definitions
        (see sections <<sec-practical-modes>>, <<sec-practical-pattern-action-pairs>>, and <<sec-formal-generated-class-mode-handling>>). 
        
        DEFAULT = ``<empty>``

.. cmdoption:: --token-prefix name
    
        ``name`` = Name prefix to prepend to the name
        given in the token-id files. For example, if a token section contains
        the name ``COMPLEX`` and the token-prefix is ``TOKEN\_PRE_``
        then the token-id inside the code will be ``TOKEN_PRE_COMPLEX``. 
        
        DEFAULT = ``QUEX_TKN_``

.. cmdoption:: --token-offset number
        
        ``number`` = Number where the numeric values for the token-ids start
        to count. 
        
        DEFAULT = ``10000``

.. cmdoption:: --token-policy, --tp [queue, single]

        Determines the policy for passing tokens from the analyzer to the user.

        DEFAULT = ``queue``

.. cmdoption:: --token-memory-management-by-user, --tmmbu

        Enables the token memory management by the user. This command line
        option is equivalent to the compile option::

             QUEX_OPTION_USER_MANAGED_TOKEN_MEMORY

        It provides the functions ``token_queue_memory_switch(...)`` for
        token policy 'queue' and ``token_p_switch(...)`` for token policy
        'single' (section :ref:`sec-token-policies`).

.. cmdoption:: --token-queue-size number

        In conjunction with token passing policy 'queue', ``number`` specifies
        the number of tokens in the token queue. This determines the maximum
        number of tokens that can be send without returning from the analyzer
        function.

        DEFAULT = ``64``.

.. cmdoption:: --token-queue-safety-border number

        Specifies the number of tokens that can be sent at maximum as reaction to
        one single pattern match.

        DEFAULT = ``16``

.. cmdoption:: --token-id-termination number
        
        ``number`` = Token identifier for the event of 'end of token stream'.
        Note, that the termination token id can always be referred to 
        via `__QUEX_SETTING_TOKEN_ID_TERMINATION`. One does not have to specify it just in order
        to be able to know its value. Consider also the comments on the token for 
        'uninitialized'. 
        
        DEFAULT = ``0`` 

.. cmdoption:: --token-id-uninitialized number
        
        ``number`` = Token identifier of a token that has not yet been
        initialized.  Any token that arrives to the user 'on purpose' should not
        contain this identifier.  It is basically a means for debugging in order
        to check whether tokens slip through due to any erroneous behavior.

        DEFAULT = ``1`` 
        
        This option is close to meaningless under normal conditions. One can always
        refer to the unitiliazed token id via `__QUEX_SETTING_TOKEN_ID_UNINITIALIZED`. In
        certain cases, though, it might make sense to ensure this id to have a certain
        value. This would be the case, if someone would like to code more than just the
        token id in the token id variable.

.. cmdoption:: --version-id name

       ``name`` = arbitrary name of the version that was generated. This string
        is reported by the `version()` member function of the lexical analyser. 

        DEFAULT = `"0.0.0-pre-release"`

.. cmdoption:: --foreign-token-id-file filename
        
        ``filename`` = Name of the file that contains an alternative definition
        of the numerical values for the token-ids (see also section
        <<sec-formal-macro>>). 
        
        DEFAULT = <empty>

.. cmdoption:: `-o`, `--engine`, `--analyzer-class` name
        
        ``name`` = Name of the lexical analyser class that is to be created
        inside the namespace`quex`. This name also determines the
        filestem of the output files generated by quex. At the same time, the
        namespace of the analyzer class can be specified by means of a sequence
        separated by '::' specifiers, e.g.::

           > quex ... --analyzer-class MySpace::MySubSpace::MySubSubSpace::Lexer

        specifies that the lexical analyzer class is ``Lexer`` and that it is located
        in the namespace ``MySubSubSpace`` which in turn is located ``MySubSpace`` which
        it located in ``MySpace``.
        
        DEFAULT = ``lexer``

.. cmdoption:: `--debug`

        If provided, then code fragments are created to
        activate the output of every pattern match. Then defining the macro
        `QUEX\_OPTION\_DEBUG\_QUEX\_PATTERN\_MATCHES` activates those printouts in the
        standard error output. Note, that this options produces considerable
        code overhead. 
        
        DEFAULT = `<disabled>`

.. cmdoption:: `--no-mode-transition-check` 

        Turns off the mode transition check and makes the engine a little faster.
        During development this option should not be used. But the final lexical
        analyzer should be created with this option set. 
        
        By default, the mode transition check is enabled.

.. cmdoption:: `--no-string-accumulator`, `--nsacc`

        Turns the string accumulator option off. This disables the use of the string 
        accumulator to accumulate lexemes. See class 'quex::Accumulator'.

        By default, the string-accumulator is implemented.

.. cmdoption:: `--no-include-stack`, `--nois`

        Disables the support of include stacks where the state of the lexical 
        analyzer can be saved and restored before diving into included files.
        Setting this flag may speed up a bit compile time

        By default, the include stack handler is implemented.

.. cmdoption:: `--post-categorizer`

        Turns the post categorizer option on. This allows a 'secondary'
        mapping from lexemes to token ids based on their name. See class
        'quex::PostCategorizer'.

For the support of derivation from the generated lexical analyzer class the
following command line options can be used.

.. cmdoption:: `--derived-class`, `--dc` name
        
       ``name`` = If specified, the name of the derived class that the user intends to provide
        (see section <<sec-formal-derivation>>). Note, specifying this option
         signalizes that the user wants to derive from the generated class. If this
         is not desired, this option, and the following, have to be left out. The 
         namespace of the derived analyzer class is specified analgously to the
         specification for `--analyzer-class`, as mentioned above.
         
         DEFAULT = <empty>
        
.. cmdoption:: `--derived-class-file` filename
        
        ``filename`` = If specified, the name of the file where the derived class is
        defined.  This option only makes sense in the context of optioin
        --derived-class`. 
        
        DEFAULT = <empty>

The following options support the definition of a independently customized token class:

.. cmdoption:: `--token-class-file` filename
        
        ``filename`` = Name of file that contains the definition of the
        token class. Note, that the setting provided here is possibly 
        overwritten if the ``token_type`` section defines a file name
        explicity (see :ref:`sec-customized-token-class`).
        
        DEFAULT = ``$(QUEX_PATH)/code_base/Token``

.. cmdoption:: `--token-class`, `--tc` name

        ``name`` is the name of the token class. Using '::'-separators it is possible
        to defined the exact namespace as mentioned for the `--analyzer-class` command
        line option.

.. cmpoption:: `--token-id-type` type-name

        ``type-name`` defines the type of the token id. This defines internally the 
        macro ``QUEX_TYPE_TOKEN_ID``. This macro is to be used when a customized
        token class is defined. The types of Standard C99 'inttypes.h' are encouraged.

        DEFAULT = ``uint32_t``

.. cmdoption:: `--token-type-no-stringless-check`, `--ttnsc`

        Disable the 'stringless check' for customized token types. If the user
        defines a token type that cannot take a ``QUEX_TYPE_CHARACTER*`` then
        quex posts a warning. By means of this flag the warning is disabled.

.. cmdoption:: --odir, --output-dir directory

        ``directory`` = name of the output directory where generated files are 
        to be written.

There may be cases where the characters used to indicate buffer limit needs to
be redefined, because the default value appear in a pattern footnote:[As for
'normal' ASCII or Unicode based lexical analyzers, this would most probably not
be a good design decision. But, when other, alien, non-unicode codings are to
be used, this case is conceivable.].  The following option allows modification
of the buffer limit code:
      
.. cmdoption:: --buffer-limit number

      DEFAULT = ``0x0``

If the trivial end-of-line pre-condition (i.e. the '\$' at the end of a regular
expression) is used, by default quex produces code that runs on both Unix
and DOS-like systems. Practically, this means that it matches against 'newline' 0x0A 
and 'carriage return/newline' 0x0D 0x0A. For the case that the resulting analyzer
only runs on a Unix machine some tiny performance improvements might be achieved
by disabling the 0x0D 0x0A sequence and only triggering on 0x0A. In this case,
the following flag may be specified:

.. cmdoption:: --no-DOS

For unicode support it is essential to allow character conversion. Currently
quex can interact with GNU IConv and IBM's ICU library. For this 
the correspondent library must be installed on your system. On Unix systems, the iconv library
is usually present. If a coding other than ASCII is required, specify the following
options:

.. cmdoption:: --iconv
        
        Enable the use of the iconv library for character stream decoding.
        This is equivalent to defining '-DQUEX_OPTION_ENABLE_ICONV'
        as a compiler flag. Depending on your compiler setup, you might have
        to set the '-liconv' flag explicitly in order to link against the IConv
        library. DEFAULT = `<disabled>` 

.. cmdoption:: --icu
        
        Enable the use of IBM's ICU library for character stream decoding.
        This is equivalent to defining '-DQUEX_OPTION_ENABLE_ICU'
        as a compiler flag. There are a couple of libraries that are required
        for ICU. You can query those using the ICU tool 'icu-config'. A command 
        line call to this tool with '--ldflags' delivers all libraries that need
        to be linked. A typical list is '-lpthread -lm -L/usr/lib -licui18n -licuuc 
        -licudata'. DEFAULT = `<disabled>` 

.. cmdoption:: -b, --bytes-per-trigger [1, 2, 4, wchar_t]

        With this option the number of bytes are specified that carry a trigger
        element of the generated state machine. As long fixed size encodings
        are used, or as long as the used coding is converted (using ``--icu``
        or ``--iconv``), the trigger elements are characters encoded in Unicode. 
        Thus, the byte number should at least suffice to cover all characters of 
        the desired input coding space. 

        If ``--codec`` is used so that the internal engine runs on a different
        codec then Unicode, then ``-b`` specifies the the number of bytes
        occupied by a code element, e.g it should be '2' for UTF16. 

        You can only specify ``1`` byte, ``2`` byte or ``4`` byte per
        character. If ``wchar_t`` is specified quex automatically adapts to the
        correspondent type of the operating system environment where the target
        code is compiled.  Use this, if option ``--iconv`` or ``--icu`` is used
        and you are in doubt. 
        
        DEFAULT = ``1``

        .. warning:: If a character size different from one byte is used, the 
                     ``.get_text()`` member of the token class does contain an array
                     that particular type. This means, that ``.text().c_str()``
                     does not result in a nicely printable UTF8 string. Use
                     the member ``.utf8_text()`` instead.

.. cmdoption:: --endian  [little, big, <system>]
        
        There are two types of byte ordering for integer number for different CPUs.
        For creating a lexical analyzer engine on the same CPU type as quex runs
        then this option is not required, since quex finds this out by its own.
        If you create an engine for a different plattform, you must know its byte ordering
        scheme, i.e. little endian or big endian, and specify it after ``--endian``. 

        According to the setting of this option one of the three macros is defined 
        in the header files:

            * ``__QUEX_OPTION_SYSTEM_ENDIAN`` 
            * ``__QUEX_OPTION_LITTLE_ENDIAN``
            * ``__QUEX_OPTION_BIG_ENDIAN``

        Those macros are of primary use for character code converters. The
        converters need to know what the analyser engines number representation
        is. However, the user might want to use them for his own special
        purposes (using ``#ifdef __QUEX_OPTION_BIG_ENDIAN ... #endif``).
        
        DEFAULT=`"<system>"`

.. cmdoption:: --converter-new String

        Section :ref:`sec-customized-converters` explains how to implement
        customized converters. With the command line option above the
        user may specify his own converter. The string that follows the
        option is the name of the converter's ``_New`` function. When this
        option is set, automatically customized user conversion is turned
        on.

.. cmdoption:: --codec String

        Specifies a codec for the generated engine. By default the internal
        engine runs on unicode code points, i.e. ASCII for characters below
        0x7F. When ``--codec`` specifies a codec 'X', for example, is specified, 
        the internal engine triggers on code elements of 'X'. It does not need
        character conversion (neither ``--iconv`` nor ``--icu``). Codec
        based analyzers are explained in section :ref:`sec-engine-codec`.

        .. note::

        When ``--codec`` is specified the command line flag ``-b`` or
        ``--bytes-per-trigger`` does not represent the number of bytes
        per character, but *the number of bytes per code element*. The
        codec UTF8, for example, is of dynamic length and its code elements
        are bytes, thus only ``-b 1`` makes sense. UTF16 triggers on elements
        of two bytes, while the length of an encoding for a character varries.
        For UTF16, only ``-b 2`` makes sense.

Template and Path Compression can be controlled with the following command line options:

.. cmdoption:: --template-compression

   If this option is set, then template compression is activated.

.. cmdoption:: --template-compression-coefficient 'number'

   The number following this option specifies the template compression coefficient.
   It indicates the relative cost of routing to a target state compared to a simple
   'goto' statement. The optimal value may vary from processor platform to processor
   platform, and from compiler to compiler.

   DEFAULT = 1

.. cmdoption:: --path-compression

   This flag activates path compression. By default, it compresses any sequence
   of states that allow to be lined up as a 'path'. This includes states of 
   different acceptance values, store input positions, etc.

.. cmdoption:: --path-compression-uniform

   This flag enables path compression. In contrast to the previous flag it 
   compresses such states into a path which are uniform. This simplifies
   the structure of the correspondent pathwalkers. In some cases this might
   result in smaller code size and faster execution speed.

For version information pass option `--version`' or `-v`'. The options `--help`
and `-h`' are reserved for requesting a help text.  Those are the options for
using quex in the 'normal' mode where it creates lexical analyzers. However,
quex provides some services to query and test character sets. If one of
those options is called, then quex does not create a lexical analyzer but
responds with some information requested by the user. Those options are
the following.

.. cmdoption:: --codec-info [name]

   Displays the characters that are covered by the given codec's name. If the
   name is omitted, a list of all supported codecs is printed. Engine internal
   character encoding is discussed in section :ref:`sec-engine-internal-coding`.

.. cmdoption:: --codec-for-language [language]

   Displays the codecs that quex supports for the given human language. If the
   language argument is omitted, all available languages are listed.

.. cmdoption:: --property name

   If ``name`` is specified, then information about the property with the given
   name is displayed. Note, that ``name`` can also be a property alias. If ``name``
   is not specified, then brief information about all available unicode
   properties is displayed.

.. cmdoption:: --set-by-property setting

   For binary properties only the property name has to be specified. All other
   properties require a term of the form ``property-name = value``. Quex then
   displays the set of character that has this particular property.

.. cmdoption:: --set-by-expression expression

   Character set expressions that are ususally specified in ``[: ... :]`` brackets
   can be specified as expression. Quex then displays the set of characters that results
   from it.

.. cmdoption:: --property-match wildcard-expression

   Quex allows the use of wildcards in property values. Using this option allows
   display of the list of values to which the given wildcard expression 
   expands. Example: The wildcard-expression ``Name=*LATIN*`` gives all settings of property ``Name`` that
   contain the string ``LATIN``.

.. cmdoption:: --numeric

   If this option is specified the numeric character codes are displayed rather
   then the utf8 characters.

.. cmdoption:: --intervals

   This option disables the display of single character or single character codes.
   In this case sets of adjacent characters are displayed as intervals. This provides
   a somewhat more abbreviated display.

Additionally, quex provides the ability to display transition diagrams of
produced state machines graphically. The following command line options support
this feature:

.. cmdoption:: --plot graphic-format

        Runs quex in the plotting mode. Rather than producing source code, quex
        produces transition diagrams of the defined modes. For querying possible graphic
        formats, run quex with the ``--plot-format-list`` command line option.
        Note, for this option to work, the graphviz package needs to be installed 
        (see www.graphviz.org).

.. cmdoption:: --plot-character-display, --pcd  ['hex', 'utf8']

        Specifies how the character of the state transition are to be displayed. When ``hex``
        is specified then character will be displayed with the Unicode code point in 
        hexidecimal. If ``utf8`` is specified the character will be displayed 'as is' 
        in UTF8 notation. 

        DEFAULT=`"utf8"`

.. cmdoption:: --plot-format-list

        Lists all possible graphic formats for which quex can produce transition
        graphs.
