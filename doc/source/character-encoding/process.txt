This section discusses how a generated lexical analyzer reads data from a file or, more
generally, from a stream. Figure :ref:`Process of loading data from a data stream<fig-load-data>` 
shows an overview over the process.  It all starts with a character stream. The content
is read via an input policy which basically abstracts the interface of the stream for the *buffer
filler*. For the buffer filler, there is no difference between a stream coming from a ``FILE``
handle, and ``ifstream`` or an ``istringstream``. The buffer filler has the following two
tasks:

* Optionally convert incoming data appropriate for the character encoding of the lexical
  analyzer engine (Unicode).

* Fill the buffer with characters that are of *fixed* size.

Some character encodings, such as UTF-8, use a different number of bytes for the
encoding of different characters. For the performance of the lexical analyzer engine
it is essential that the characters have *constant* width. Iteration over
elements of constant size is faster than over elements of dynamic size. Also
the detection of content borders is very simple, fast, and not error-prone.

It becomes clear that the transfer of streaming data to the buffer memory can
happen in different ways. This is reflected in the existence of multiple types
of buffer fillers.

.. _fig-load-data::

.. figure:: ../figures/character-converting-process.*
   
   Loading data from a stream into the buffer memory.

Currently, some efforts are made to enhance lexical analyzer engines with character
encodings. With this approach, fast plain buffer fillers could be used even for
non-unicode encodings. The following parameters are to be kept in mind

* Character Width

  This determines the fixed number of bytes that each single character occupies
  in the buffer memory. It can be set via the command-line options ``-b`` or 
  ``--bytes-per-ucs-codepoint``. Directly related to it the the *character type*,
  i.e. the real C-type that is used to represent this entity. For example, ``uint8_t``
  would be used to setup a buffer with one byte characters. 

  .. note::

     The character type is a C-type and does not make any assumptions of the
     encoding which is used. It is a means to specify the number of bytes
     that are used for a character in the buffer memory--not more.

* Data Stream Codec

  This is the character encoding of the input data stream. If non-unicode (or ASCII)
  streams are to be used, then a string must be passed to the buffer filler that
  tells from what encoding it has to convert.

* Lexical Analyzer Codec

  This is the character encoding of the analyzer engine. The engine triggers on
  numeric values from state to state. Those numeric values are the character
  codes in the buffer memory. Currently, only unicode or ASCII is supported as
  lexical analyzer codec. The coding is determined by quex.


