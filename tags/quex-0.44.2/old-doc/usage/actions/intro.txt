A lexical analyzer has to box lexemes and stamp them with a token identifier.
In the following sections the details are discussed how actions are related to
patterns. First it is discussed how token identifiers can be defined. Second,
it is discussed how the 'boxing' and 'stamping' of lexemes works and what
convenient features quex provides to specify this process. Third, it is
explained how C/C++ code may be applied to do more sophisticated actions as
response to a pattern match. Finally, the feature of the token stack is
introduced and how it may help to send implicit tokens beyond the
pattern-match mechanisms.

