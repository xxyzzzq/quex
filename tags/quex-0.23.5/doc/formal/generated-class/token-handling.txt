Section \ref{sec:basics/token-queue} elaborated on the idea that the lexical
analyser communicates tokens to the user. In the quex generated lexical
analyser the tokens are stored in a token-queue before they are delivered to
the caller of `get\_token()`. Inside the pattern-action the `send`
function group allows to send tokens:

[cpp]
source~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
        void        send(const token& That);                             
        void        send(const token::id_type TokenID);                 
        void        send_n(const int N, const token::id_type TokenID);   
        void        send(const token::id_type TokenID, const char* Text);
        void        send(const token::id_type TokenID, const int Number1);
source~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

As mentioned before, the author of quex is in favor for the idea that the
lexical analyzer should only find out for what a string in the input stream
stands for. It should not interpret it, but leave the interpretation to the
user or the parser.

Figure <<fig:token-queue, style=ref>>, page \pageref{fig:token-queue},
displayed a sequence diagram depicting the communication of tokens.
Using the `send` function group the writer of pattern-action pairs does
not need to care about the `get\_token()` function call. He sends tokens
and leaves the responsibility of delivery to the engine.

