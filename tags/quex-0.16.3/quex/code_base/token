// -*- C++ -*-    :vim set syntax=cpp:
//
// Token handling is **very** time critical ! We have two types of tokens:
//
//   class Token_intern: a token that is not reference counted, it can be
//                       efficiently used for 'bunch stacks', i.e. stacks
//                       consisting of a bunch of objects, rather than
//                       pointers to these objects.
//
//   class Token: a token as presented to the 'parser' for example.
//                such tokens are reference counted. they can therefore
//                be copied arround very efficiently and speedy.
//
//   Both classes share the Token_data_core, i.e. the content of a token
//   is in both cases the same and defined in the base class of both
//   token classes.
//
//
//   (C) 1425 AH Frank R. Schaefer
//   (C) 2006-2007 Frank R. Schaefer
//////////////////////////////////////////////////////////////////////////////////////////
#ifndef __INCLUDE_GUARD__QUEX__TOKEN__
#define __INCLUDE_GUARD__QUEX__TOKEN__

// Depends on 'QUEX_CHARACTER_TYPE' being defined!

#include<iostream>
#include<string>

namespace quex {
    
    class token {
    public:
	// Quex Token Policy: _____________________________________________________
	typedef int      id_type;                // type of the token-id
	static const int ID_UNINITIALIZED = -1;  // token-id for 'uninitialized'	
	static const int ID_TERMINATION   = 0;   // token-id for 'termination'	
	// NOTE: Returning '0' is almost standard for this token! Think trice,
	//       before choosing a difrent value! You might run into trouble with
	//       your parser generator.
	static const std::string&  map_id_to_name(token::id_type);
	//_________________________________________________________________________

    private:
	typedef std::basic_string<QUEX_LEXEME_CHARACTER_TYPE> __string;

	token::id_type     _id;
	__string           _text;
	int                _number;

#ifdef ___TOKEN_DIGESTION_HAS_BEEN_IMPLEMENTED___
/* TODO: Using the extreme speed of the circular token queue. Let the tokens
         live inside the queue, at deletion only set the 'digested' flag.

	bool _digested_f;   // == true:  Token has been digested by the parser.
	//                  //           It is no longer being used and can be 
	//                  //           overwritten.
	//                  // == false: I has not been digested yet. It cannot
	//                  //           be overwritten.
*/
#endif

    public:
	token() {} 
	token(const token& That) { __copy(That); }     

	// note, that tokens are created in a bunch on the token stack and only
	// set with the .set(..) functions when pushed.
	//
	token(token::id_type ID, const QUEX_LEXEME_CHARACTER_TYPE* Text) { set(ID, Text); }
	
	// (*) convert data to string
	const __string   type_string() const;
	operator         const std::string() const;
	__string         xml(const int Depth) const;

      
	// (*) member acces
	//     -- read
	const token::id_type type_id() const      { return _id; }
	const std::string&   type_id_name() const { return map_id_to_name(_id); }
	const __string&      text() const         { return _text; }
	const int            number()             { return _number; }

	//     -- status
	bool                 is_unitialized() const { return _id == token::ID_UNINITIALIZED; }

	//     -- write 
	void    set(token::id_type ID);
	void    set(token::id_type ID, const QUEX_LEXEME_CHARACTER_TYPE* Text);
	void    set(token::id_type ID, const int   Number1);

    private:
	void __copy(const token& That);
    };


    inline void 
    token::__copy(const token& That) {
	_id     = That._id;
	_text   = That._text;
	_number = That._number;
    }

    inline void    
    token::set(token::id_type Type, const QUEX_LEXEME_CHARACTER_TYPE* Text)
    { _id = Type; _text = __string(Text); }

    inline void    
    token::set(token::id_type Type, const int Number1)
    { _id = Type; _number = Number1; }

    inline void    
    token::set(token::id_type Type) 
    { _id = Type; }

    inline std::ostream&
    operator<<(std::ostream& ostr, const token& Tok)
    { ostr << std::string(Tok); return ostr; }

    inline
    token::operator const std::string() const
    {
	std::string             tmp;
	__string                tmp2 = _text;
	std::string::size_type  pos  = 0;
	// const char   dummy[64];

	tmp = map_id_to_name(this->_id);

	if( tmp2.length() > 32 ) tmp2 = tmp2.substr(0, 32);

	// maybe, later on we will do a real conversion to utf-8, since most terminals understand that
	tmp += " '";
	for(__string::iterator it = tmp2.begin(); it != tmp2.end() ; ++it)
	    tmp += std::string::value_type(*it & 0x7F);        // simply cut it down to a 7bit char
	tmp += "' ";

	while( (pos = tmp.find("\n") ) != __string::npos )
	    tmp.replace(pos, 1, std::string("\\n"));
	while( (pos = tmp.find("\t") ) != __string::npos ) 
	    tmp.replace(pos, 1, std::string("\\t"));

	return tmp;
    }

}

#endif // #define __INCLUDE_GUARD__QUEX__TOKEN__
